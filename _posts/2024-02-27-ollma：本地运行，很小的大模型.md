---
title: ollma：本地运行，很小的大模型.md
author: 老章 mlpy
date: 2024-02-27 14:10:00 +0800
categories: [AIGC]
tags: [aigc]
render_with_liquid: false
---

---
title: ollma：本地运行，很小的大模型.md
author: 老章 mlpy
date: 2024-02-27 14:10:00 +0800
categories: [AIGC]
tags: [aigc]
render_with_liquid: false
---

---
title: ollma：本地运行，很小的大模型.md
author: 老章 mlpy
date: 2024-02-27 14:10:00 +0800
categories: [AIGC]
tags: [aigc]
render_with_liquid: false
---



### Ollama简介

一句话概括：Ollama 是一个允许您在计算机上本地运行开源大语言模型（LLM）的工具

### 极简安装并运行大模型

安装客户端：https://ollama.com/download

下载后安装即可

![](https://r2.zhanglearning.com/blog/2024/02/991a703c16eefca614d9e2095efe9bc6.png)

然后就可以在Terminal中下载大模型，比如最近大火的mistral，4G左右。

![](https://r2.zhanglearning.com/blog/2024/02/2de10d6f8b5d4fa7aba04374698f306e.png)



模型下载完成后就可以直接在Terminal中聊天了

我的电脑是丐版MacBook Air M1，推理时巨卡无比

![](https://r2.zhanglearning.com/blog/2024/02/6bd59b50bcdce453e3bb58ee1868c026.png)



### Olamma支持大模型列表

https://ollama.com/library

| Model              | Parameters | Size  | Download                       |
| ------------------ | ---------- | ----- | ------------------------------ |
| Llama 2            | 7B         | 3.8GB | `ollama run llama2`            |
| Mistral            | 7B         | 4.1GB | `ollama run mistral`           |
| Dolphin Phi        | 2.7B       | 1.6GB | `ollama run dolphin-phi`       |
| Phi-2              | 2.7B       | 1.7GB | `ollama run phi`               |
| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`       |
| Starling           | 7B         | 4.1GB | `ollama run starling-lm`       |
| Code Llama         | 7B         | 3.8GB | `ollama run codellama`         |
| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored` |
| Llama 2 13B        | 13B        | 7.3GB | `ollama run llama2:13b`        |
| Llama 2 70B        | 70B        | 39GB  | `ollama run llama2:70b`        |
| Orca Mini          | 3B         | 1.9GB | `ollama run orca-mini`         |
| Vicuna             | 7B         | 3.8GB | `ollama run vicuna`            |
| LLaVA              | 7B         | 4.5GB | `ollama run llava`             |
| Gemma              | 2B         | 1.4GB | `ollama run gemma:2b`          |
| Gemma              | 7B         | 4.8GB | `ollama run gemma:7b`          |

Gemma是由Google DeepMind构建的一系列轻量级、最先进的开放模型。

Llama 2是一系列基础语言模型，参数范围从7B到70B。

Mistral发布的7B模型，更新至版本0.2。

Mixtral是Mistral AI提供的一款高质量的专家混合（MoE）模型，开放权重。

LLaVA是一个全新的大型多模态模型，结合了视觉编码器和Vicuna，用于通用的视觉和语言理解。更新至版本1.6。

[neural-chat](https://ollama.com/library/neural-chat)是基于Mistral的经过微调的模型，覆盖了良好的领域和语言范围。

Codellama是一个可以使用文本提示生成和讨论代码的大型语言模型。

Dolphin-mixtral是基于Mixtral的专家混合模型的未经审查、经过微调的模型，在编码任务上表现出色。由Eric Hartford创建。

Mistral OpenOrca是一个7亿参数的模型，在Mistral 7B模型的基础上使用OpenOrca数据集进行了微调。

未经审查的Llama 2模型，由George Sung和Jarrad Hope创建。

Orca-mini是一个通用模型，参数范围从30亿到70亿，适合入门级硬件。

Phi-2：由微软研究院开发的2.7B语言模型，展示了出色的推理和语言理解能力。

DeepSeek Coder是一个强大的编码模型，经过两万亿代码和自然语言标记的训练。

基于Mistral的未经审查的Dolphin模型，在编码任务上表现出色。更新至版本2.6。

Vicuna是基于Llama和Llama 2的通用聊天模型，上下文大小从2K到16K不等。

Wizard Vicuna Uncensored是一个基于Llama 2的未经审查的7B、13B和30B参数模型，由Eric Hartford创建。

Zephyr beta是Mistral的7B版本的微调版本，训练涵盖了公开可用的、合成的数据集混合。

OpenHermes 2.5是一个7B模型，由Teknium在Mistral的基础上使用完全开放的数据集进行了微调。

State-of-the-art的代码生成模型。

Qwen 1.5是阿里巴巴云提供的一系列大型语言模型，参数范围从0.5B到72B。

Llama 2基础上的模型，经过微调以提升中文对话能力。

基于Code Llama的代码生成模型。

TinyLlama项目是一个开放的尝试，旨在训练一个紧凑的1.1B Llama模型，使用了3万亿标记。

OpenChat是一系列在多种数据上训练的开源模型，超越了ChatGPT在各种基准测试上的表现。更新至版本3.5-0106。

Orca 2由微软研究院构建，是Meta的Llama 2模型的微调版本。该模型特别擅长推理。

由技术创新研究所（TII）构建的大型语言模型，用于摘要、文本生成和聊天机器人。

专注于数学和逻辑问题的模型。

Nous Research提供的基于Llama和Llama 2的通用使用模型。

一个高性能的、双语的语言模型。

由Eric Hartford创建的2.7B未经审查的Dolphin模型，基于微软研究院的Phi语言模型。

TinyDolphin是一个实验性的1.1B参数模型，基于Eric Hartford的新Dolphin 2.8数据集并基于TinyLlama训练。

Starling是一个通过AI反馈的强化学习训练的大型语言模型，专注于提高聊天机器人的帮助性。

基于Llama2的优秀代码生成模型。

StarCoder是一个在80多种编程语言上训练的代码生成模型。

微调的Llama 2模型，基于一个开源医疗数据集回答医疗问题。

未经审查的Wizard LM模型版本。

BakLLaVA是一个多模态模型，由Mistral 7B基础模型与LLaVA架构增强而成。

未经审查的基于Llama2的模型，支持16K上下文窗口。

Stable Code 3B是一个模型，提供准确且响应迅速的代码完成，与如CodeLLaMA 7B这样体积是其2.5倍的模型相当。

Solar是一个紧凑但强大的10.7B大型语言模型，专为单轮对话设计。

基于Llama 2的模型，经过微调，适用于Orca风格的数据集。最初被称为Free Willy。

SQLCoder是一个在StarCoder的基础上针对SQL生成任务微调的代码完成模型。

Mistral的扩展，支持64K或128K的上下文窗口。

Nous Research的Nous Hermes 2模型，现在在Mixtral上进行训练。

Samantha-Mistral是一个在哲学、心理学和个人关系方面接受训练的伴侣助手。基于Mistral。

StableLM-Zephyr是一个轻量级聊天模型，允许在不需要高端硬件的情况下提供准确且响应迅速的输出。

Meditron是一个开源的医疗大型语言模型，从

Llama 2适应到医疗领域。

Wizard Vicuna是一个基于Llama 2的13B参数模型，由MelodysDreamj训练。

Magicoder是一个家族，包括7B参数模型，使用OSS-Instruct的75K合成指令数据训练，这是一种用开源代码片段启发LLM的新方法。

Stable LM 2 1.6B是一个最先进的1.6亿参数的小型语言模型，训练涵盖了英语、西班牙语、德语、意大利语、法语、葡萄牙语和荷兰语的多语言数据。

Llama 2的扩展，支持高达128k标记的上下文。

Nous Research提供的强大的模型家族，在科学讨论和编码任务上表现出色。

DeepSeek LLM是一个先进的语言模型，使用2万亿双语标记制作。

Llama 2的扩展，专门整合了通用语言理解和特定领域知识，特别是在编程和数学方面。

Open Orca OpenChat模型和Garage-bAInd Platypus 2模型的融合。设计用于聊天和代码生成。

Codebooga是通过合并两个现有代码模型创建的高性能代码指导模型。

Nexus Raven是一个为函数调用任务调优的13B指令模型。

MistralLite是基于Mistral的经过微调的模型，增强了处理长上下文的能力。

Goliath是通过将两个微调的Llama 2 70B模型结合成一个而创建的语言模型。

Notux是一个顶级表现的专家混合模型，经过高质量数据微调。

Alfred是一个强大的会话模型，设计用于聊天和指导用例。

MegaDolphin-2.2-120b是通过将Dolphin-2.2-70b模型与自身交错而创建的转换。

Nomic-embed-text是一个高性能的开放嵌入模型，具有8192标记的上下文窗口。

Wizardlm是基于Llama 2的70亿参数的通用使用模型。

Xwinlm是基于Llama 2的会话模型，在各种基准测试上表现竞争力。

Notus是一个基于Zephyr的7B聊天模型，经过高质量数据微调。

Duckdb-nsql是由MotherDuck和Numbers Station制作的7B参数文本到SQL模型。

All-minilm是在非常大的句子级数据集上的嵌入模型。
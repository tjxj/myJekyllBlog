---
title: 全方位拥抱DeepSeek.md
author: 老章 mlpy
date: 2025-02-02 14:10:00 +0800
categories: [AIGC]
tags: [aigc]
render_with_liquid: false
---



DeepSeek 最近的火热不言而喻

其实较早之前，我就写过 N 篇 DeepSeek 能力的文章

比如我用它做[自动数据分析](https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&mid=2648988669&idx=2&sn=5a70e77b78f5ac51b8aa9c3454f785c3&chksm=8793c9d7b0e440c1aacad500347342910cb2a90c2762d33e8a15ae6696e1e7f6a8ff4c001c28&token=1471641045&lang=zh_CN#rd)、[做一键AI总结网页保存本地的快捷指令](https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&mid=2648989202&idx=1&sn=89837da2887dfb0099655c6badbca5db&chksm=8793cc38b0e4452ef0a79ec69fba4d79b73e424017ad65645afa1324bf51a323f6ab975242aa&token=1471641045&lang=zh_CN#rd)、[全文翻译吴恩达的《如何打造 AI 职业生涯》](https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&mid=2648989164&idx=1&sn=9c76181771e01a1b8763e9b891233cec&chksm=8793cfc6b0e446d0ef85770770028a65f4524cb59e80bead71e026d945f10bf894d4161d213c&token=1471641045&lang=zh_CN#rd)、[AI英语陪练](https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&mid=2648988086&idx=2&sn=2e4fa672f83b21b1076083975decff98&chksm=8793cb9cb0e4428a2f1966e9a037529573f4a564c1313285f78041b1676c591e0163faf69d3d&token=1471641045&lang=zh_CN#rd)等等


这里老章用极简洁的方式介绍如何将 DeepSeek 融入到写作、编程、翻译、总结等各场景。

## DeepSeek 能力获取

### **方式 1:在线使用**
![](https://r2.zhanglearning.com/blog/2025/02/67a836ee8d0a3079fc55f623b2f58b88.png)

https://chat.deepseek.com/

### **方式 2:本地部署**

![](https://r2.zhanglearning.com/blog/2025/02/d442e50262040f36a5e25bfe47ccd264.png)

本地安装 Ollama：`https://ollama.com`

然后命令行运行

`ollama run deepseek-r1:7b`

![](https://r2.zhanglearning.com/blog/2025/02/8f88c36a9c09dd93de7c1e8cd0ac4e93.png)

请视自己电脑/显卡性能情况选择对应参数，从 1.5b 到 671b

![](https://r2.zhanglearning.com/blog/2025/02/4136a51c68a5be9f23296a93bfbfc4ac.png)

具体请参考：https://ollama.com/library/deepseek-r1

### **方式 3:官方 API**

申请：https://platform.deepseek.com/api_keys

![](https://r2.zhanglearning.com/blog/2025/02/e99a45812e58a828e1f25706f8ef2dde.png)


copy 一下申请好的 api_key

记一下 base_url：`https://api.deepseek.com/v1`


最近太火热，官方 api 时常挂掉
![](https://r2.zhanglearning.com/blog/2025/02/02bf35fcd2c49c727a795c0e0ce255c5.png)

使用参考 API 手册：`https://api-docs.deepseek.com/guides/reasoning_model`

```python
from openai import OpenAI

client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False
)

print(response.choices[0].message.content)
```

### **方式 4:第三方 API**

想要更省钱的话，可以不用官方 api，转投 siliconflow

注册后免费赠送 14 元（够用很久很久，用 deepseek 翻译了一本 40 页的 pdf，只花了几分钱）

注册地址：https://cloud.siliconflow.cn/i/YefhGWlT

它不但完美支持`OpenAI API`调用，还可以免费使用`Qwen、GLM、Yi `等模型。
![支持的模型列表：https://cloud.siliconflow.cn/models](https://r2.zhanglearning.com/blog/2025/02/b89b8e48c917c95a6cef8422235795d9.png)

api 获取地址：https://cloud.siliconflow.cn/account/ak

![](https://r2.zhanglearning.com/blog/2025/02/31257cfb26aa8f80021b2f45610b1361.png)


用法：

当前大语言模型部分支持以 openai 库进行调用，安装 Python3.7.1 或更高版本并设置虚拟环境后，即可安装 OpenAI Python 库。

从终端/命令行运行：

```shell
pip install --upgrade openai
```

完成此操作后，running 将显示您在当前环境中安装的 Python 库，确认 OpenAI Python 库已成功安装。 

之后可以直接通过 OpenAI 的相关接口进行调用，目前平台支持 OpenAI 相关的大多数参数。

```python
from openai import OpenAI

client = OpenAI(api_key="这里填写你的 api key", base_url="https://api.siliconflow.cn/v1")
response = client.chat.completions.create(
    model='deepseek-ai/DeepSeek-R1',
    messages=[
        {'role': 'user', 
        'content': "机器学习算法与 Python 实战这个号值的关注吗？"}
    ],
    stream=True
)

for chunk in response:
    print(chunk.choices[0].delta.content, end='')
```


这里需要修改的只有 api_key（上面申请后复制到的）、model（名称要遵循 siliconflow 的规范）和 messages（定义了 role 和 prompt）

## DeepSeek + Cursor AI 辅助编程

有了 DeepSeek 能力，一系列的事儿就可以搞起来了，比如编程

在`Cursor Settings-Models`中关闭其他模型，添加上面复制好的模型，点击`Add model`

API 地址和 API Key 可以填写 DeepSeek 官方，也可以填 Siliconflow 的。

点击`Verify`，看到绿色开关即为`OK`了

![](https://r2.zhanglearning.com/blog/2025/02/786346d7ce0155a766d1bc273ce2bd99.png)


然后就可以正常使用 Cursor + DeepSeek 了

![](https://r2.zhanglearning.com/blog/2025/02/e73fa7fd1cc2b24c76495c12dcced778.png)


## DeepSeek + Obsidian 辅助写作


首先需要下载 Obsidian：https://obsidian.md/

安装后，点击左下角设置，在【第三方插件】选择浏览【社区插件市场】
![](https://r2.zhanglearning.com/blog/2025/02/7aeef747c5806a257b10d433849e1d2b.png)

搜索 Copilot，安装，然后启用后进入【选项】

![](https://r2.zhanglearning.com/blog/2025/02/ae98f5801f340e6fd9853da37be7f706.png)

这个插件是支持 ChatGPT Claude 等 api 的，网络畅通的富哥们直接把 api 填进去即可。

Copilot 支持添加其他模型

点击 **Add Model**

![](https://r2.zhanglearning.com/blog/2025/02/0ffe13bfff5fe6f42eee829dfec1b2b2.png)


设置页面往上托，把 deepseek-ai/DeepSeek-R1 设置为默认，点击上面的 **Save and Reload**

![](https://r2.zhanglearning.com/blog/2025/02/203926089bbb8635cd202578cc7db898.png)

![](https://r2.zhanglearning.com/blog/2025/02/f646d9fb3b8cc2be476fc53094e6f048.png)


回到 Obsidian，点击侧边栏的对话图标，右侧即会出现大模型对话框了
![](https://r2.zhanglearning.com/blog/2025/02/17864555c68516109dbede1598154c29.png)

相对详细的介绍请移步：[Obsidian AI 写作神器：一键配置 DeepSeek，写作效率飙升 1000%！](http://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&mid=2648990755&idx=1&sn=3721f784a6db1d7fb14df0be6e9df0e1&chksm=8793f609b0e47f1fbc1b175c159a819646ea6fa014899cfa39b9d38e24493af70bc6b96f2e50&scene=21#wechat_redirect)

## DeepSeek + 沉浸式翻译/总结

安装沉浸式翻译插件

https://immersivetranslate.com/manual-chrome-extension

![](https://r2.zhanglearning.com/blog/2024/07/a4a3ac06f7c8f2d3b4ecbafcaf2095fa.png)


按教程安装好插件之后，chrome 左上角就能看到这个插件

右键点击这个图标

![](https://r2.zhanglearning.com/blog/2025/02/8d644b9bd60e8dacb8e506c9c36632cf.png)

点击设置 - 翻译服务

这里面翻译服务有很多，支持各种大模型，这里我们选择 DeepSeek 或 Siliconflow，当然你可以选别的，这里我选的是 Silicon

![](https://r2.zhanglearning.com/blog/2025/02/4571b47879e4acf24d92e009fae84567.png)


点击**去修改**，把前面申请到的 apikey 粘贴进去，模型名称使用自定义

![](https://r2.zhanglearning.com/blog/2025/02/4e75b68cc3cddf30c01810eea3e2902a.png)

现在访问英文网站，你就可以一键沉浸式翻译了

![](https://r2.zhanglearning.com/blog/2025/02/3d95cff4648ba1a8abc24e9c9e0b6bfc.png)

不过用 R1 做翻译有点大材小用了

我之前我写过 PDF 全文翻译的文章，设置方法类似，感兴趣可以移步

[[240729 翻译了吴恩达的《如何打造AI职业生涯》，花了3分钱，附教程]]

## DeepSeek + JupyterHub 辅助编程



>Jupyter AI 是一个扩展包，旨在将人工智能工具和功能集成到 Jupyter Notebook 环境中。通过 Jupyter AI，用户可以在 Jupyter Notebook 中直接使用各种 AI 服务和模型，如自然语言处理、机器学习和深度学习等，从而简化数据科学和机器学习项目的开发流程。

安装一定要完全安装：

`pip install jupyter-ai[all]`

不然大概率会出现以下报错：

There seems to be a problem with the Chat backend, please look at the JupyterLab server logs or contact your administrator to correct this problem.

![](https://r2blog.zhanglearning.com/2025/01/cb2fde78d8498aa0ad1aa0b66f57ed88.png)


正常情况下，安装完成后的juputerhub是这样，点击右上角小齿轮就可以配置模型了

![](https://r2blog.zhanglearning.com/2025/01/8fe99ef9f5aedb67b4c43ccc7e976164.png)




## DeepSeek + openwebui 聊天助手

OpenWebUI 旨在为 AI 和 LLMs 构建最佳用户界面，为那些互联网访问受限的人提供利用 AI 技术的机会。 OpenWebUI 通过 Web 界面本地运行 LLMs，使 AI 和 LLMs 更安全、更私密。 

安装openwebui是我见过所有chatbot中最简单的了
```shell
# 安装
pip install open-webui

# 启动
open-webui serve
```

然后浏览器打开 `http://localhost:8080`

加号这里填入ollama拉起的模型名称即可
![](https://r2.zhanglearning.com/blog/2025/02/69ae0c290a3f51559b60a8e50c2128bb.png)

也可以配置siliconflow的模型

![Google Chrome 2025-02-05 22.53.30.png](https://r2.zhanglearning.com/blog/2025/02/fedf2de5fda8745a145b50e4ab8dafd6.png)


## DeepSeek + 知识库&Agent

克隆 Dify 源代码至本地环境。

```
git clone https://github.com/langgenius/dify.git
```

启动 Dify

1. 进入 Dify 源代码的 Docker 目录
    ```
    cd dify/docker
    ```
    
2. 复制环境配置文件
    ```
    cp .env.example .env
    ```
    
3. 启动 Docker 容器
    
    根据你系统上的 Docker Compose 版本，选择合适的命令来启动容器。你可以通过 `$ docker compose version` 命令检查版本：
    - 如果版本是 Docker Compose V2，使用以下命令：
    ```
    docker compose up -d
    ```
    - 如果版本是 Docker Compose V1，使用以下命令：
    ```
    docker-compose up -d
    ```
    

运行命令后，你应该会看到类似以下的输出，显示所有容器的状态和端口映射：
```
[+] Running 11/11
 ✔ Network docker_ssrf_proxy_network  Created                                                                 0.1s 
 ✔ Network docker_default             Created                                                                 0.0s 
 ✔ Container docker-redis-1           Started                                                                 2.4s 
 ✔ Container docker-ssrf_proxy-1      Started                                                                 2.8s 
 ✔ Container docker-sandbox-1         Started                                                                 2.7s 
 ✔ Container docker-web-1             Started                                                                 2.7s 
 ✔ Container docker-weaviate-1        Started                                                                 2.4s 
 ✔ Container docker-db-1              Started                                                                 2.7s 
 ✔ Container docker-api-1             Started                                                                 6.5s 
 ✔ Container docker-worker-1          Started                                                                 6.4s 
 ✔ Container docker-nginx-1           Started                                                                 7.1s
```

最后检查是否所有容器都正常运行：
```
docker compose ps
```

在这个输出中，你应该可以看到包括 3 个业务服务 `api / worker / web`，以及 6 个基础组件 `weaviate / db / redis / nginx / ssrf_proxy / sandbox` 。
```
NAME                  IMAGE                              COMMAND                   SERVICE      CREATED              STATUS                        PORTS
docker-api-1          langgenius/dify-api:0.6.13         "/bin/bash /entrypoi…"   api          About a minute ago   Up About a minute             5001/tcp
docker-db-1           postgres:15-alpine                 "docker-entrypoint.s…"   db           About a minute ago   Up About a minute (healthy)   5432/tcp
docker-nginx-1        nginx:latest                       "sh -c 'cp /docker-e…"   nginx        About a minute ago   Up About a minute             0.0.0.0:80->80/tcp, :::80->80/tcp, 0.0.0.0:443->443/tcp, :::443->443/tcp
docker-redis-1        redis:6-alpine                     "docker-entrypoint.s…"   redis        About a minute ago   Up About a minute (healthy)   6379/tcp
docker-sandbox-1      langgenius/dify-sandbox:0.2.1      "/main"                   sandbox      About a minute ago   Up About a minute             
docker-ssrf_proxy-1   ubuntu/squid:latest                "sh -c 'cp /docker-e…"   ssrf_proxy   About a minute ago   Up About a minute             3128/tcp
docker-weaviate-1     semitechnologies/weaviate:1.19.0   "/bin/weaviate --hos…"   weaviate     About a minute ago   Up About a minute             
docker-web-1          langgenius/dify-web:0.6.13         "/bin/sh ./entrypoin…"   web          About a minute ago   Up About a minute             3000/tcp
docker-worker-1       langgenius/dify-api:0.6.13         "/bin/bash /entrypoi…"   worker       About a minute ago   Up About a minute             5001/tcp
```

通过这些步骤，你应该可以成功在本地安装 Dify。

在 Dify 中接入 Ollama

在 `设置 > 模型供应商 > Ollama` 中填入：


![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252Fgit-blob-d7b9e34b03490d63140cfb0aa9cf85ca988f71e2%252Follama-config-zh.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=80498396&sv=2)

- 模型名称：`deepseek-r1:7b`
    
- 基础 URL：`http://<your-ollama-endpoint-domain>:11434`


使用 Ollama 模型

![](https://docs.dify.ai/~gitbook/image?url=https%3A%2F%2F1288284732-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252FCdDIVDY6AtAz028MFT4d%252Fuploads%252Fgit-blob-8ee0e898b27e6fea336e00777f924153677b2f0b%252Follama-use-model.png%3Falt%3Dmedia&width=768&dpr=4&quality=100&sign=299f80fe&sv=2)

进入需要配置的 App 提示词编排页面，选择 Ollama 供应商下的 `llava` 模型，配置模型参数后即可使用。
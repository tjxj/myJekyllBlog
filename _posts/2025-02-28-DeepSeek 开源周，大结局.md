---
title: DeepSeek 开源周，大结局.md
author: 老章 mlpy
date: 2025-02-28 14:10:00 +0800
categories: [AIGC]
tags: [aigc]
render_with_liquid: false
---


![image.png](https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9XFMBXsrZE4shTW4MMEEMBIELXyqAmPZlGictCHnb4S37oKRRvOosice5ol0uXmleDbicV7PBm2zIaw/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)


省流版：


大家好，我是Ai学习的老章

DeepSeek 5天开源大联播拉下帷幕

本文梳理总结一下都发布了哪些黑科技

尽量极简，感兴趣可以去附的项目地址学习。

### 第一天：FlashMLA
![](https://r2blog.zhanglearning.com/2025/02/6f568b2082c0d3ffdd9f5422f71437dc.png)

>为 Hopper 架构 GPU（如H800）设计的高效解码内核

这个项目属于工程优化，**极限压榨硬件性能**。

项目地址：`https://github.com/deepseek-ai/FlashMLA`

**核心亮点：**

通过优化可变长序列的多头潜在注意力计算，在解码阶段实现 3000GB/s 内存带宽和 580TFLOPS 算力的极限性能，显著提升大模型长上下文推理效率。

经实测，FlashMLA在H800 SXM5平台上（CUDA 12.6），在内存受限配置下可达最高3000GB/s，在计算受限配置下可达峰值580 TFLOPS。

![Image](https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjZjBAGCXweh3oJzGRPSDMAgcDJLLD3iaAK7IhZpGUT2B65s0A5SgH0QmmMw3OF1ZdBj2NfSKk3CdQ/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)


### 🚀 第二天：DeepEP  
![](https://r2blog.zhanglearning.com/2025/02/949d24b9b61e41d0ab946288763abe83.png)

>专为MoE模型训练与推理打造的开源EP通信库

**项目地址**: `https://github.com/deepseek-ai/DeepEP`

核心亮点：

✅ 高效优化的All-to-All通信  
✅ 支持NVLink和RDMA的节点内/跨节点通信  
✅ 训练及推理预填充阶段的高吞吐量计算核心  
✅ 推理解码阶段的低延迟计算核心  
✅ 原生支持FP8数据分发  
✅ 灵活控制GPU资源，实现计算与通信的高效重叠  

### 第三天：DeepGEMM
![](https://r2blog.zhanglearning.com/2025/02/314f2cccde4556f3574599bb2c91f73f.png)

>一个专注于FP8精度通用矩阵乘法的高性能库

**项目地址**：`https://github.com/deepseek-ai/DeepGEMM`

**核心亮点：**

不仅支持常规的密集矩阵乘法，还特别优化了混合专家模型(MoE)场景下的分组GEMM计算，成为DeepSeek-V3/R1训练和推理的核心动力。采用细粒度缩放的FP8计算，在Hopper GPU上可达到惊人的1350+ TFLOPS。相比 CUTLASS 等主流库提速最高达 **2.7 倍**，适用于训练和推理阶段。

![Image](https://mmbiz.qpic.cn/mmbiz_png/1FD1x61uYVfIicia0ekq8LITQnNvQhqY4pzfIIbJt8ia38zeyf3DFXwKsfbw7Jj1W6QrXoXfic1OfV4EyQ3wu2KdZQ/640?from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1&wx_co=1)

### 第四天：DualPipe、EPLB、profile-data
![](https://r2blog.zhanglearning.com/2025/02/62f909cae32f86d5920521dd12fb0599.png)

• DualPipe让计算和通信高效协同，显著提升了训练速度。  
• EPLB让每个GPU的负载更加均衡，提高了GPU利用率。  
• profile-data提供了详细的性能分析数据，帮助开发者学习优化经验。

DualPipe：一种双向流水线并行算法，通过计算与通信的完全重叠，显著减少流水线气泡。

核心亮点：
• 支持8个流水线并行节点和20个微批次的混合调度。
• 提升GPU利用率，减少训练周期。

项目地址： https://github.com/deepseek-ai/DualPipe

EPLB：专家并行负载均衡器，用于优化专家模型在GPU间的分配。

项目地址： https://github.com/deepseek-ai/eplb

核心亮点：
• 提供分层和全局负载均衡策略，减少跨节点通信。
• 动态调整专家复制，优化资源分配。


profile-data ：训练和推理框架的性能分析数据，旨在帮助开发者深入了解并行策略的优化。

项目地址： https://github.com/deepseek-ai/profile-data

核心亮点：
• 提供详细的训练、预填充和解码阶段的性能数据。
• 支持通过PyTorch Profiler采集数据，并在浏览器中可视化。


### 第五天：3FS
![](https://r2blog.zhanglearning.com/2025/02/0beef6f7c7aa08fa6925a31bccd1dd97.png)


>3FS，全深度搜索数据访问推进器，火蝇文件系统（3FS）


 项目地址：https://github.com/deepseek-ai/3FS

核心亮点：

3FS是一种并行文件系统，利用了现代固态硬盘和远程直接内存访问（RDMA）网络的全带宽。
- 在 180 节点集群中实现 6.6 TiB/s 的总读取吞吐量。
- 在 25 节点集群中的 GraySort 基准测试中实现 3.66 TiB / 分钟的吞吐量。
- 每个客户端节点对 KVCache 查找实现 40+GiB/s 的峰值吞吐量。
- 具有强一致性语义的解聚架构。
- 在 V3/R1 中进行推理的训练数据预处理、数据集加载、检查点保存 / 重新加载、嵌入向量搜索和 KVCache 查找。

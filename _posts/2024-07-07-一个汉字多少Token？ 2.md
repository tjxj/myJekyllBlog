---
title: 一个汉字多少Token？ 2.md
author: 老章 mlpy
date: 2024-07-07 14:10:00 +0800
categories: [AIGC]
tags: [aigc]
render_with_liquid: false
---



Token是大模型世界最基础、最常见的概念，如何翻译没有定论，“标记”“词”“令牌”都有，复旦大学计算机学院邱锡鹏教授将其翻译为“词元”，个人认为比较恰当。

众所周知，大语言模型训练语料数量、上下文的限制、生成速度都用Token表示。

比如
- 通义千问-7B使用超过2.4万亿tokens的数据进行预训练，
- 模型后面带着8k、32k，就是指在生成响应或进行预测时最大文本长度
- 评估大模型生成速度的TPS，指的是每秒输出token数


Token是指语言模型中用来表示中文汉字、英文单词、或中英文短语的符号。

Token可以是单个字符，也可以是多个字符组成的序列。

网上各种资料，关于一个 token是多少汉字说法不一。

最为知名的大模型ChatGPT，模型使用**Byte Pair Encoding** (BPE)进行文本编码，这种编码方式在处理不同语言时的效率可能会有所不同。

>GPT-3：每词输出最高上限为2049个Token，大约可以写出1000字的中文文章、1720字的英文文章​
>GPT-4：每词输出最高上限为32768个Token,约是16056个中文字、25000个英文字

BPE是一种子词分词方法，可以将词语进一步划分为更小的可重复部分。

**对于汉语等字形语言，一个token可能只包含一个字符**，但对于英语等词素语言，**一个token可能包含一个或多个单词**。

OpenAI官方文档中介绍:“1000个token通常代表750个英文单词或500个汉字。1 个token大约为 4 个字符或 0.75 个单词。”

>1个字母=1个字符，举例，hello=5字符
  1个汉字=1个字符，举例，你好=2字符

这里有OpenAI官方的token计算工具 : https://platform.openai.com/tokenizer  

![](https://r2.zhanglearning.com/blog/2024/07/88d40e0e195b012323f169f350e339af.png)

就如刚才所说，不同模型可能有自己的切分方法，对应地，一个Token对应地汉字数也不一样。一个Token对应汉字，0.75到1.8个汉字不等。

百度文心一言也提供了token计算器来在线计算文心大模型的字符转token数。

网址：https://console.bce.baidu.com/support/#/tokenizer

![](https://r2.zhanglearning.com/blog/2024/07/3578e06dbcfa9ae7c3de529582b9fa13.png)

阿里通义千问也有：https://dashscope.console.aliyun.com/tokenizer

![](https://r2.zhanglearning.com/blog/2024/07/52a53162500dbfc168f5b167a3a7b4f6.png)


所以一个Token有多少个汉字，具体取决于分词器的设计。

目前的各种tokenization技术，涉及到将文本分割成有意义的单元，以捕捉其语义和句法结构，如字级、子字级(例如，使用字节对编码或 WordPiece)或字符级。

根据特定语言和特定任务的需求，每种技术都有自己的优势和权衡。比如Qwen-7B采用UTF-8字节级别的BPE tokenization方式，并依赖OpenAI开源的[`tiktoken`](https://github.com/openai/tiktoken)软件包执行分词。 

- 字节对编码（BPE）：为AI模型构建子词词汇，用于合并出现频繁的字符/子字对。
- 子词级tokenization：为复杂语言和词汇划分单词。将单词拆分成更小的单元，这对于复杂的语言很重要。
- 单词级tokenization：用于语言处理的基本文本tokenization。每个单词都被用作一个不同的token，它很简单，但受到限制。
- 句子片段：用习得的子词片段分割文本，基于所学子单词片段的分段。
- 分词tokenization：采用不同合并方法的子词单元。
- 字节级tokenization：使用字节级token处理文本多样性，将每个字节视为令牌，这对于多语言任务非常重要。
- 混合tokenization：平衡精细细节和可解释性，结合词级和子词级tokenization。


最后再推荐一个网站，可以一目了然地查看大模型性能：https://llmbenchmark.liduos.com/?r=cdr。

这个网站会实时展示不同大模型的：TTFT、TPS 和 Total，表头支持排序和筛选。

![](https://r2.zhanglearning.com/blog/2024/07/3dedcaa993fc8667aed25249299aa1be.png)



llmbenchmark.liduos.com是@juberti的团队发布thefastest.ai的国内版

大家如果对国外大模型API性能感兴趣可以访问：https://thefastest.ai

这个项目还是开源的：https://github.com/fixie-ai/thefastest.ai

![](https://r2.zhanglearning.com/blog/2024/07/dab0f0f16a56805c77db8d460609548b.png)



[
  
  {
    "title": "亚马逊云注册及Bedrock开发教程",
    "url": "/posts/%E4%BA%9A%E9%A9%AC%E9%80%8A%E4%BA%91%E6%B3%A8%E5%86%8C%E5%8F%8ABedrock%E5%BC%80%E5%8F%91%E6%95%99%E7%A8%8B/",
    "categories": "AIGC",
    "tags": "AIGC",
    "date": "2024-01-12 14:10:00 +0800",
    





    
    "snippet": "BedRock 本地开发环境搭建亚马逊云的Bedrock（https://aws.amazon.com/cn/bedrock/）是一个用于聊天、文本和图像的生成人工智能工具包， 它可以访问 AI21 (Jurassic-2)、Anthropic (Claude)、Stability AI (Stable Diffusion) 和 Amazon (Titan) 等基础模型。Amazon Bed...",
    "content": "BedRock 本地开发环境搭建亚马逊云的Bedrock（https://aws.amazon.com/cn/bedrock/）是一个用于聊天、文本和图像的生成人工智能工具包， 它可以访问 AI21 (Jurassic-2)、Anthropic (Claude)、Stability AI (Stable Diffusion) 和 Amazon (Titan) 等基础模型。Amazon Bedrock 是一项全托管服务，提供了一系列高性能的基础模型，这些模型来自 AI21 Labs、Anthropic、Cohere、Meta、Stability AI 以及 Amazon 等领先 AI 企业，通过统一的 API 提供服务。此外，Amazon Bedrock 还包括了一整套功能，这些功能旨在构建具备安全性、隐私保护以及负责任的 AI 特色的生成式 AI应用程序。借助 Amazon Bedrock，可以轻松实验和评估各种顶尖基础模型以满足应用场景，还可以通过微调（fine-tuning）和检索增强生成（Retrieval Augmented Generation, RAG）等技术，使用私有数据对这些模型进行定制。如果想要基于BedRock，可以完全使用Amazon提供的云服务，也可以在本地完成开发。本文就重点介绍一下本地环境搭建过程1、Python环境Python环境是必须的，不过多介绍了，相信大家都非常熟悉。我们只需要额外安装两个必备的库：Boto3和Langchain      Boto3 是一个面向 Python 的 Amazon Web Services (AWS) 软件开发工具包（SDK）。它允许 Python 开发者从他们的 Python 脚本中创建、更新和删除 AWS 资源。        LangChain是一个基于大语言模型开发应用程序的框架，它提供了各种易于使用的组件。  亚马逊提供了Boto3的相关文档、API参考、代码示例，感兴趣可以深入学习一下：https://docs.aws.amazon.com/pythonsdk/2、安装 AWS CLI下载AWS CLI：http://aws.amazon.com/cli/大家下载对应系统的AWS CLI即可，安装就是一路下一步打开系统自带Terminal，执行aws help命令 测试是否安装成功3、创建 IAM 用户为了设置 AWS 会话，需要使用 AWS CLI v2 和 SSO 登录并获取访问 AWS 服务所需的凭证。官方教程：https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console想省事的话，可以直接看我这个，我选择的是从控制台创建IAM用户https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/users  在控制台主页上，选择 IAM 服务。  在导航窗格中，选择用户，然后选择 添加用户。  在“指定用户详细信息”页面上的“用户详细信息”下的“用户名”中，输入新用户的名称。这是他们的 AWS 登录名。  选择提供用户访问 – AWS 管理控制台 *可选*这将为新用户生成 AWS 管理控制台登录凭证。  我选择的是我想创建 IAM 用户 并继续执行此过程。下一步将用户添加到组- 如果您要将用户分配到一个或多个已拥有权限策略的组，请选择此选项。IAM 显示您账户中的组列表及其附加的策略。您可以选择一个或多个现有组，或选择“创建组”来创建新组。  在检索密码页面上，获取分配给用户的密码：          选择密码旁边的显示可查看用户的密码，以便您可以手动记录。      选择下载 .csv将用户的登录凭据下载为 .csv 文件，您可以将其保存到安全位置。      4、管理访问密钥回到首页，点击右上角自己的用户名-安全凭证创建访问密钥根据提示往下点击即可创建完成之后回到Terminal，执行aws configure命令，把刚才创建的密钥粘贴进去可以在系统根目录下.aws目录下看到5、测试环境是否搭建成功现在让我们导入所需的模块并使用“amazon.titan”模型创建 Bedrock 的实例：bingo 完美！"
  },
  
  {
    "title": "机器学习周刊05-看见统计看见概率",
    "url": "/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%88%8A05-%E7%9C%8B%E8%A7%81%E7%BB%9F%E8%AE%A1%E7%9C%8B%E8%A7%81%E6%A6%82%E7%8E%87/",
    "categories": "机器学习周刊",
    "tags": "机器学习周刊",
    "date": "2024-01-07 10:10:00 +0800",
    





    
    "snippet": "这个网站用可视化的方式讲解概率和统计基础知识，很多内容还是可交互的，非常生动形象。大家好，欢迎收看第五期机器学习周刊本期介绍7个内容，涉及Python、概率统计、机器学习、大模型等,目录如下：  一个离谱的Python库  看见概率，看见统计  2024机器学习最强文档  Gradio  顶级程序员如何使用LLM  TinyLlama  微软宣布利用大型语言模型改进文本嵌入1、一个离谱的Py...",
    "content": "这个网站用可视化的方式讲解概率和统计基础知识，很多内容还是可交互的，非常生动形象。大家好，欢迎收看第五期机器学习周刊本期介绍7个内容，涉及Python、概率统计、机器学习、大模型等,目录如下：  一个离谱的Python库  看见概率，看见统计  2024机器学习最强文档  Gradio  顶级程序员如何使用LLM  TinyLlama  微软宣布利用大型语言模型改进文本嵌入1、一个离谱的Python库地址：https://www.visidata.org/docs/  pip3 install visidataVisiData是一款免费的开源工具，可让您在计算机终端中快速打开、探索、汇总和分析数据集。VisiData 可处理 CSV 文件、Excel 电子表格、SQL 数据库和许多其他数据源。界面如下所示：甚至还能在命令行中做可视化，酷是真酷，就是看了半天不清楚有什么使用场景。2、看见概率，看见统计地址：https://seeing-theory.brown.edu/basic-probability/cn.html这个网站用可视化的方式讲解概率和统计基础知识，很多内容还是可交互的，非常生动形象。章节目录如下：  基础概率论  进阶概率论  概率分布  统计推断：频率学派  统计推断：贝叶斯学派  回归分析3、2024机器学习最强文档地址：https://huggingface.co/tasksHuggingFace这个页面我愿称之为机器学习最强文档，囊括了各种机器学习任务，比如表格数据预测、NLP、机器视觉、音频、多模态、强化学习等任务所需的全部内容（演示、用例、模型、数据集等等）4、G𝚛𝚊𝚍𝚒𝚘地址：https://www.gradio.app/Gradio是一个可以快速部署机器学习应用的开源项目，我用它做过很多小工具。如果你第一次听说gradio，强烈建议赶快用起来。最近它更新到了4.13版，完美兼容Python 3.12 。5、Redis 之父的最新文章地址：http://antirez.com/news/140翻译：https://blog.zhanglearning.com/posts/2024%E5%B9%B4%E5%88%9D%E7%9A%84LLMs%E4%B8%8E%E7%BC%96%E7%A8%8B/Redis 作者写了篇文章，非常详细地分享他在工作中使用 LLM 编程的体验，我们可以一窥顶级程序员是如何使用大模型的。这篇文章很我让ChatGPT提取了摘要，用Claude-2-100K完成了翻译，我没有做校对：  在2023年，人工智能尤其是可以在设备上本地使用的LLMs取得了显著的进步，作者广泛利用这项技术来加速他的编程能力。  起初，作者主要使用LLMs来处理文档和避免在编程中的无聊/不感兴趣的部分。然而，随着时间的推移，他学会了何时使用LLMs最有帮助，以及何时它们可能会减慢他的速度。  LLMs在推理和插值方面的能力有限，它们不能超越它们被训练的内容。虽然它们不能替代人类程序员，但如果适当使用，它们可以是有用的辅助工具。  作者提供了几个例子，展示了LLMs如何帮助他更快地编写代码，例如在框架之间切换、用一种不熟悉的语言编程，或分析他不完全理解的网络输出时。  当任务虽然无聊但对作者的目标有用时，LLMs也适用于编写一次性/临时脚本。  系统编程需要更强的推理能力，这通常是LLMs所缺乏的。作者提供了一个例子，其中LLMs在提供相关代码时，仍然难以解释一个低级别的数据格式。  总之，LLMs最好被用作程序员的辅助工具而不是替代品。有了经验，人们可以学习如何以及何时有效地利用它们来处理不同的编程任务。但它们的能力仍然有限，并且可能不会扩展到所有领域，比如系统编程。6、TinyLlama模型地址：https://huggingface.co/TinyLlamaTinyLlama 发布1.0版本，1.1B 参数，基于3万亿 tokens 训练，与 LLaMa 2 完全相同的架构和分词器，从他们的Github能看到完整的训练过程。7、微软宣布利用大型语言模型改进文本嵌入论文： https://arxiv.org/pdf/2401.00368.pdf最后推荐一篇微软最近发布的论文，介绍了一种新颖且简单的方法，该方法不需要构建复杂的训练管道或依赖于手动收集的数据集，仅使用合成数据和少于 1k 的训练步骤即可获得高质量的文本嵌入。"
  },
  
  {
    "title": "【翻译】Redis之父最新文章《2024年初的LLMs与编程》",
    "url": "/posts/2024%E5%B9%B4%E5%88%9D%E7%9A%84LLMs%E4%B8%8E%E7%BC%96%E7%A8%8B/",
    "categories": "翻译",
    "tags": "LLM",
    "date": "2024-01-03 14:10:00 +0800",
    





    
    "snippet": "英文原文：http://antirez.com/news/140Redis 之父的最新文章，非常详细地分享他在工作中使用 LLM 编程的体验，我们可以通过此文一窥超级大佬是如何使用大模型的。这篇文章很我让ChatGPT提取了摘要：  在2023年，人工智能尤其是可以在设备上本地使用的LLMs取得了显著的进步。作者广泛利用这项技术来加速他的编程能力。  起初，作者主要使用LLMs来处理文档和避...",
    "content": "英文原文：http://antirez.com/news/140Redis 之父的最新文章，非常详细地分享他在工作中使用 LLM 编程的体验，我们可以通过此文一窥超级大佬是如何使用大模型的。这篇文章很我让ChatGPT提取了摘要：  在2023年，人工智能尤其是可以在设备上本地使用的LLMs取得了显著的进步。作者广泛利用这项技术来加速他的编程能力。  起初，作者主要使用LLMs来处理文档和避免在编程中的无聊/不感兴趣的部分。然而，随着时间的推移，他学会了何时使用LLMs最有帮助，以及何时它们可能会减慢他的速度。  LLMs在推理和插值方面的能力有限，它们不能超越它们被训练的内容。虽然它们不能替代人类程序员，但如果适当使用，它们可以是有用的辅助工具。  作者提供了几个例子，展示了LLMs如何帮助他更快地编写代码，例如在框架之间切换、用一种不熟悉的语言编程，或分析他不完全理解的网络输出时。  当任务虽然无聊但对作者的目标有用时，LLMs也适用于编写一次性/临时脚本。  系统编程需要更强的推理能力，这通常是LLMs所缺乏的。作者提供了一个例子，其中LLMs在提供相关代码时，仍然难以解释一个低级别的数据格式。  总之，LLMs最好被用作程序员的辅助工具而不是替代品。有了经验，人们可以学习如何以及何时有效地利用它们来处理不同的编程任务。但它们的能力仍然有限，并且可能不会扩展到所有领域，比如系统编程。翻译工作只有Claude-2-100K可以完成正文：我想先说,这篇文章的目的不是对LLM进行回顾。很明显,2023年对人工智能来说是一个非凡的一年:重复这一点似乎毫无意义。相反,本文旨在成为一个个人程序员的见证。自ChatGPT问世以来, Later by使用本地运行的LLM,我已大量使用这种新技术。 目标是加速我编写代码的能力,但这并不是唯一的目的。 还有意图是不要浪费在编程中不值得投入精力的方面上的心智能量。 在特殊的、智力上不感兴趣的方面上搜索文档所花费的无数小时; 学习过于复杂的API的努力,往往没有充分的理由; 写立即可用的程序,我会在几个小时后丢弃。 这些都是我不想做的事情,特别是现在,谷歌已经成为海洋垃圾,难以找到几件有用的东西。与此同时,我在编程方面肯定不是新手。 我有能力在没有任何帮助的情况下编写代码,而且我确实经常这样做。 随着时间的推移,我越来越倾向于使用LLM来编写高级代码,特别是在Python中,而在C语言中要少得多。 LLM给我留下深刻印象的是,我已经准确地了解到何时使用它们何时它们的使用只会拖慢我。 我还了解到,LLM有点像维基百科和Youtube上散布的所有视频课程:它们帮助那些有意愿、能力和纪律性的人,但对于那些落伍的人来说效果很小。 我担心,至少在最初,它们只会使那些已经具有优势的人受益。但是让我们一步一步来。全知或鹦鹉?在机器学习领域出现这种新奇和进步的浪潮中,最令人担忧的现象之一是AI专家接受他们有限知识的有限能力。 人类发明了神经网络,然后更重要的是,发明了一种算法来自动优化神经网络的参数。 硬件已经能够训练越来越大的模型,并利用有关要处理的数据的统计知识(先验知识),通过大量的试错法逐步逼近,发现了比其他模型工作得更好的体系结构。 但总的来说,神经网络仍然相当模糊。面对无法解释LLM某些新出现的能力的无能为力,人们本应该更加谨慎。 相反,许多科学家严重低估了LLM,说毕竟它们只是稍微高级一些的马尔可夫链,最多只能吐出它们在训练集中见过的极端有限的变体。 然后,在证据面前,这种鹦鹉的观念几乎被普遍推翻。与此同时,热情的群众赋予LLM现实中不存在的超自然力量。 不幸的是,LLM最多只能在它们在训练期间看到的数据表示的空间中进行插值:这已经很多了。 事实上,它们的插值能力是有限的(但仍然令人惊叹,也出人意料)。 哦,要是当今最大的LLM能连续插值在它们见过的所有代码所围绕的空间中该多好! 即使它们无法产生真正的新颖性,它们也能取代99%的程序员。 现实要谦虚得多,几乎总是如此。 LLM肯定能编写它没有以完全相同的形式见过的程序,展示了将训练数据集中以某种频率出现的不同想法混合在一起的某种能力。 同样明显的是,这种能力目前有深刻的局限性,每当需要细致的推理时,LLM就会以灾难性的方式失败。 然而,它们代表了从黎明到今天的AI的最大成就。 这似乎是不可否认的。愚蠢但无所不知的确:LLM最多只能进行最初级的推理,往往不准确,许多时候夹杂着关于不存在的事实的幻觉。 但它们拥有广泛的知识。 在编程领域以及其他可获得高质量数据的领域,LLM就像愚蠢的神童,知道很多事情。 和这样的伙伴进行配对编程(对我来说,配对编程在最一般的术语中就是可怕的):他们会有荒谬的想法,我们不得不持续斗争才能实现自己的想法。 但如果这位博学的傻子供我们使用,回答所有问他的问题,事情就变了。 当前的LLM不会把我们带进知识的道路之外,但如果我们想处理一个我们不太熟悉的主题,它们通常可以把我们从绝对的无知中提升到我们能够自主前进的地步。在编程领域,也许直到20或30年前,它们的能力仍然非常有限的兴趣。 那时你只需要知道几种编程语言、经典算法和那10个基本库。 其余的你必须自己添加,你自己的智力、专业知识、设计技能。 如果你有这些原料,你就是一名专家程序员,基本上能做任何事情。 随着时间的推移,我们见证了框架、编程语言、各种库的爆炸式增长。 复杂性的爆炸往往完全没有必要和理由,但事实就是如此。 在这样一个背景下,一个知道一切的白痴就是一位宝贵的盟友。让我举个例子:我在机器学习上的实验至少进行了一年,使用Keras。 然后出于各种原因,我切换到了PyTorch。 我已经知道embedding或残差网络是什么,但我不想逐步学习PyTorch的文档(就像我在ChatGPT还不存在时所做的那样学习Keras)。 用LLM,编写使用Torch的Python代码变得非常容易。 我只需要对要组装的模型有清晰的想法,并提出正确的问题。举个例子我不是在说简单的事情,比如:“嘿,X类的Y方法是什么?” 如果仅仅是为了那个,你可能会倾向于同意那些对LLM持怀疑态度的人。 目前更复杂的模型能做的要精细得多。 在几年前,这将是纯粹的魔法。 我可以告诉GPT4:看,这是我在PyTorch中实现的神经网络模型。 这是我的批处理。 我想调整张量的大小,以便向神经网络发出批处理的函数与输入兼容,我想以这种特定的方式表示事物。 您能向我展示需要进行重新塑形的代码吗? GPT4编写代码,我所要做的就是在Python CLI中测试张量是否真的具有对我有用的维度,数据布局是否正确。这里有另一个例子。 不久前,我需要为某些基于ESP32的设备实现BLE客户端。经过一些研究后,我意识到跨平台的蓝牙编程绑定或多或少都无法使用。 解决方案很简单,使用macOS的本机API用Objective C编写代码。 所以,我同时要处理两个问题:学习Objective C冗长的BLE API,充满了我认为非理性的模式(我是一个极简主义者,那种API与我认为的“良好设计”的对立面) ,同时记住如何用Objective C编程。 我上次用Objective C编写程序是十年前:我不记得事件循环、内存管理的细节等等。最终的结果是这里的这段代码,不算漂亮,但它能做到它该做的事情。 否则不可能在极短的时间内完成。https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m代码主要是通过在ChatGPT上剪切粘贴我想要做但不太明白如何做的事情来编写的,所以它们无法正常工作。 让LLM向我解释问题所在及如何解决它。 的确,LLM没有编写这段代码的大部分,但它显着加速了编写的速度。 如果没有ChatGPT,我能做到这一点吗? 当然可以,但最有趣的不是它花了我更长的时间:事实是我甚至不会尝试,因为不值得。 这一关键事实至关重要。 写这样一个次要程序的工作量与收益比完全不方便。 此外,这产生了比程序本身更有用的次要附带效果:为那个项目,我修改了linenoise(我的一行编辑库之一),以便它可以在多路复用中工作。下面是一个关于数据解释而不是编写代码的例子。 我想使用一个在线找到的卷积神经网络Python脚本,但它缺乏文档。 该网络的优点是ONNX格式,所以我可以轻松提取输入和输出列表以及分配给它们的名称。 我只知道关于这个convnet的一件事:它在图像中检测某些特征。 我不知道输入图像的格式和大小,尤其是网络的输出要比我想象的复杂得多(我认为它是一个二进制分类器:观察到的图像正常还是有问题? 两个输出,但有数百个输出)。 我从将ONNX网络元数据输出复制粘贴到ChatGPT开始。 我向助手解释关于网络的微乎其微的知识。 ChatGPT假设输入如何组织,输出可能是指示图像中潜在缺陷部分的规范化框,以及这些缺陷的可能性。经过几分钟的反复,我有了一个Python脚本,能够对网络进行推理,以及将起始图像转换为适合输入的张量所需的代码等等。 关于那次会话令我惊讶的是,ChatGPT在测试图像上观察到原始输出值(logit,基本上)后才最终“理解”网络的功能:一系列浮点数提供了识别精确输出细节、规范化、框是否居中或指定左上角等的上下文。一次性程序我可以记录数十起上面描述的这样的案例。 这是毫无意义的,因为它只是以多少相同的方式重复同样的故事。 我遇到一个问题,我需要快速了解某事,只要LLM不在胡说八道,我就可以验证它。 好吧,在这种情况下,我使用LLM加速获取知识。然而,在不同的情况下,我会让LLM编写所有的代码。 例如,每当我需要编写一个或多或少一次性的程序时。 像这个:https://github.com/antirez/simple-language-model/blob/main/plot.py我需要可视化PyTorch程序在学习期间生成的CSV文件的损失曲线。 我向GPT4展示了CSV文件格式,然后如果我在命令行中指定多个CSV文件,我不再需要相同实验的训练和验证损失曲线,而是不同实验的验证损失曲线的比较。 以上是GPT4生成的结果。 总共30秒。类似地,我需要一个程序来读取AirBnB CSV报告并根据月份和年份对我的公寓进行分组。 然后,考虑到清洁费用和每个预订的夜晚数量,它将对一年不同月份的平均租金价格进行统计。 对我来说,这个程序非常有用。 同时,编写它是无聊透顶:没有什么有趣的。 所以我把漂亮的CSV文件片段复制粘贴到GPT4上。 我向LLM解释要解决的问题:程序在第一次尝试时就可以工作。 我在下面完整展示。import pandas as pdpd.set_option('display.max_rows', None)df = pd.read_csv('listings.csv')reservations = df[df['Type'] == 'Reservation']reservations['Start Date'] = pd.to_datetime(reservations['Start Date'])reservations['Year'] = reservations['Start Date'].dt.yearreservations['Month'] = reservations['Start Date'].dt.monthreservations['Nightly Rate'] = (reservations['Amount'] - reservations['Cleaning Fee']) / reservations['Nights']all_listings = reservations['Listing'].unique()all_years = reservations['Year'].unique()all_months = range(1, 13)index = pd.MultiIndex.from_product([all_listings, all_years, all_months], names=['Listing', 'Year', 'Month'])all_data = pd.DataFrame(index=index).reset_index()merged_data = pd.merge(all_data, reservations, on=['Listing', 'Year', 'Month'], how='left')average_nightly_rates = merged_data.groupby(['Listing', 'Year', 'Month'])['Nightly Rate'].mean().fillna(0)print(average_nightly_rates)要准确理解如何对数据进行分组,否则数据相当分散和无序,需要进行一些简单的推理:这不是LLM仅通过吐出近似于它所看到语言的东西就可以解决的问题。 GPT4在训练期间肯定观察到了类似的程序,但几乎肯定没有看到必须以我要求的精确方式对事物进行分组的程序,以及具有该特定格式的CSV文件。 这表明(在我看来)LLM可以在训练数据集中不同程序勾画出的空间内进行某种程度的插值。编写这种类型的程序,在我看来,是时间的不明智使用。 LLM能为我做到这一点,肯定会直接加速我的代码产生能力:我可以专注于最重要的事情。当事情没有按它们应有的方式发展时:系统编程尽管在编程方面我与LLM非常成功,但在我编写C程序时,我几乎总是只将LLM视为更方便的文档形式。 我是系统编程专家,在那种情况下,LLM对我有用只有当它们能进行复杂的推理时:在这种情况下,它们几乎总是失败。让我们从这个实验的提示开始:概述一个漂亮的、小但可工作的C实现的布隆过滤器的要求。 关注散列函数的重要方面。 然后写它,用高质概述一个漂亮的、小但可工作的C实现的布隆过滤器的要求。关注散列函数的重要方面。 然后用高质量的C语言编写它。还要考虑你的示例实现应该大小为100,000个元素,假阳性概率最高为5%。 添加的元素是null结尾的字符串。这里是GPT4的输出:#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;math.h&gt;#define N 100000  // 元素个数 #define P 0.05    // 假阳性概率#define M (int)(-(N * log(P)) / (log(2) * log(2)))  // 位数组大小#define K (int)(M / N * log(2))  // 哈希函数个数unsigned char bitArray[M / 8 + 1];void setBit(int n) {    bitArray[n / 8] |= 1 &lt;&lt; (n % 8); }int getBit(int n) {    return bitArray[n / 8] &amp; (1 &lt;&lt; (n % 8));}// 基本哈希函数(用于演示)int hash1(char *str) {    int hash = 5381;    int c;    while ((c = *str++))        hash = ((hash &lt;&lt; 5) + hash) + c;    return abs(hash % M); }int hash2(char *str) {    unsigned long hash = 0;    int c;    while ((c = *str++))        hash = c + (hash &lt;&lt; 6) + (hash &lt;&lt; 16) - hash;    return abs(hash % M);}void add(char *str) {    setBit(hash1(str));    setBit(hash2(str));    // 如果需要可以添加更多哈希函数}int is_in(char *str) {    return getBit(hash1(str)) &amp;&amp; getBit(hash2(str));    // 如果使用了更多哈希函数要检查它们}int main() {    char *testStr = \"testString\";    add(testStr);    if (is_in(testStr)) {        printf(\"%s is probably in the set.\\n\", testStr);    } else {        printf(\"%s is definitely not in the set.\\n\", testStr);    }    return 0;}GPT4产生的实现并不算太出色。布隆过滤器相当广泛使用。这并不是一个如此难懂的数据结构。但是,编写一个体面的布隆过滤器需要更高的抽象能力:例如,有效地在同一个字符串上散列N次的问题,并确保散列充分解关联。然而,如果你明确要求GPT4修改散列函数,以便它产生N个解耦输出,它的建议解决方案要可接受得多:unsigned int hash(const char* str, unsigned int hash_id) {    unsigned int hash = 5381;    int c;    while ((c = *str++)) {        hash = ((hash &lt;&lt; 5) + hash) + c + hash_id;     }    return hash % BF_SIZE;}如果它自己想到了这个主意,它会以不同的方式编写布隆过滤器,使用单个散列函数设置K个位。GPT4能够隔离地执行为编写适当而更通用的散列函数的任务。 但是在编写布隆过滤器这个更大的项目中,它未能展示出足够的推理能力,而是吐出两个不同但相似的散列函数:这正是人们期望从关于布隆过滤器的糟糕文章例子中获得的。当前大型语言模型的弱推理能力,加上可能的该主题资源稀缺,更糟糕的是,可能有许多低质量的资源,共同导致了这种贫乏的结果。 然而,这并非个别案例。 在算法或系统编程领域,我试图使用LLM的次数很少,结果非常糟糕,即使预期的推理能力也不大于LLM在Python编程环境中所展示的。与此同时,GPT-4有能力在单独的会话中反编译它产生的函数,并精确理解其目的:https://chat.openai.com/share/f54b64d7-d19a-4be4-8f10-08553aa812f1因此,说在系统编程环境中LLM完全没有用是非常鲁莽的言论。一个有趣且可以预料的事情是,在这些情况下,模型规模之间的差异确实很大。 让我们看看两个本地模型的表现。例如,Mixtral,Mistral的MoE,对同样的问题回复如下:unsigned int hash(const char* str, unsigned int hash_id) {    unsigned int hash = 5381;    int c;    while ((c = *str++)) {        hash = ((hash &lt;&lt; 5) + hash) + c;    }    return hash + hash_id;}显然,仅在末尾添加hash_id是一个极差的解决方案。 Mixtral是一个用于许多用途的出色模型,但就LLM目前甚至较弱的推理能力而言,迄今为止的规律肯定是:越大越好。这是我与本地LLM deepseek-coder的聊天,由于内存不足,我将其量化为4比特,而不是以更高精度使用该模型。 然而,拥有340亿参数,它在这方面的推理能力似乎相当先进。 这里是与llama.cpp的聊天日志:  我有一个散列函数,它应该为同一数据输出N个不同的散列。 然而,当我更改hash_id的值时,我看到生成的散列分布很差:unsigned int hash(const char* str, unsigned int hash_id) {    unsigned int hash = 5381;    int c;    while ((c = *str++)) {        hash = ((hash « 5) + hash) + c;     }    return hash + hash_id;}我使用的盐可能不好吗? 我该如何改变它?[Deep-seek coder回复]您实现的一个可能问题是您只是在散列的末尾添加hash_id。 这可能导致差的分布,特别是当hash_id太大或分布不均匀时。考虑使用按位操作来混合hash_id。 这里是一个使用XOR的示例:unsigned int hash(const char* str, unsigned int hash_id) {    unsigned int hash = 5381;    int c;    while ((c = *str++)) {        hash = ((hash &lt;&lt; 5) + hash) ^ c + hash_id; // 使用XOR混合hash_id    }    return (hash ^ hash_id); // 在末尾再混合一次hash_id}这将比简单地添加它更好地传播您的散列中的hash_id,这可以导致分布不那么均匀。在我的MacBook M1 Max上运行,这对于一个模型来说并不坏。 在这种情况下,提示我问题的线索肯定帮助了模型,但模型本身确定了实际问题所在,并提出了有效的替代方案。 这样的事情不是任何书籍、文档或谷歌搜索所能达到的。 并且,无论你如何看待LLM,说它们对程序员没有帮助是非常鲁莽的。与此同时,然而,过去几个月的经验表明,对于系统编程,如果你已经是经验丰富的程序员,LLM几乎从不提供可接受的解决方案。 让我举一个真实例子。 我当前的项目ggufflib涉及编写读取和写入GGUF格式文件的库,这是llama.cpp加载量化模型的格式。 最初,为了理解量化编码如何工作(出于速度原因,每个量化的位以花哨的方式存储),我试图使用ChatGPT,但后来决定逆向工程llama.cpp的代码:速度快得多。 如果LLM看到数据编码“struct”声明和解码函数,它应该能够重构数据格式文档。 llama.cpp的函数小到足以完全适合GPT4的上下文中,然而输出完全无用。 在这些情况下,就像过去一样做事:纸和笔,阅读代码,并看看解码器提取位的位置。让我更好地解释一下上述用例,以便你可以自己尝试,如果你愿意的话。 我们有来自llama.cpp实现的这个结构。// 6比特量化// 权重表示为x = a * q// 16个块,每个块16个元素// 每个权重有效6.5625位typedef struct {    uint8_t ql[QK_K/2];      // 量化,低4位    uint8_t qh[QK_K/4];      // 量化,高2位     int8_t  scales[QK_K/16]; // 缩放,用8位量化    ggml_fp16_t d;           // 超级块缩放} block_q6_K;然后有这个函数,用于执行反量化:void dequantize_row_q6_K(const block_q6_K * restrict x, float * restrict y, int k) {    assert(k % QK_K == 0);    const int nb = k / QK_K;for (int i = 0; i &lt; nb; i++) {    const float d = GGML_FP16_TO_FP32(x[i].d);    const uint8_t * restrict ql = x[i].ql;    const uint8_t * restrict qh = x[i].qh;    const int8_t  * restrict sc = x[i].scales;    for (int n = 0; n &lt; QK_K; n += 128) {        for (int l = 0; l &lt; 32; ++l) {            int is = l/16;            const int8_t q1 = (int8_t)((ql[l +  0] &amp; 0xF) | (((qh[l] &gt;&gt; 0) &amp; 3) &lt;&lt; 4)) - 32;            const int8_t q2 = (int8_t)((ql[l + 32] &amp; 0xF) | (((qh[l] &gt;&gt; 2) &amp; 3) &lt;&lt; 4)) - 32;            const int8_t q3 = (int8_t)((ql[l +  0]  &gt;&gt; 4) | (((qh[l] &gt;&gt; 4) &amp; 3) &lt;&lt; 4)) - 32;            const int8_t q4 = (int8_t)((ql[l + 32]  &gt;&gt; 4) | (((qh[l] &gt;&gt; 6) &amp; 3) &lt;&lt; 4)) - 32;            y[l +  0] = d * sc[is + 0] * q1;            y[l + 32] = d * sc[is + 2] * q2;            y[l + 64] = d * sc[is + 4] * q3;            y[l + 96] = d * sc[is + 6] * q4;        }        y  += 128;        ql += 64;        qh += 32;        sc += 8;    }} }如果我要求GPT4编写数据格式的大纲,它努力提供位在“ql”的低/高4位上存储的块的清晰解释,这取决于权重的位置。 对于这篇博文,我还要求它编写一个更简单的函数,以显示数据的存储方式(也许它无法用文字解释,但可以用代码)。 产生的函数在许多方面都有问题,索引是错误的,6位到8位的符号扩展是错误的(它只是转换为uint8_t),等等。顺便说一下,这是我自己最终编写的代码:} else if (tensor-&gt;type == GGUF_TYPE_Q6_K) {    uint8_t *block = (uint8_t*)tensor-&gt;weights_data;    uint64_t i = 0; // i-th weight to dequantize.    while(i &lt; tensor-&gt;num_weights) {        float super_scale = from_half(*((uint16_t*)(block+128+64+16)));        uint8_t *L = block;        uint8_t *H = block+128;        int8_t *scales = (int8_t*)block+128+64;        for (int cluster = 0; cluster &lt; 2; cluster++) {            for (uint64_t j = 0; j &lt; 128; j++) {                f[i] = (super_scale * scales[j/16]) *                       ((int8_t)                        ((((L[j%64] &gt;&gt; (j/64*4)) &amp; 0xF) |                         (((H[j%32] &gt;&gt; (j/32*2)) &amp; 3) &lt;&lt; 4)))-32);                i++;                if (i == tensor-&gt;num_weights) return f;            }            L += 64;            H += 32;            scales += 8;        }        block += 128+64+16+2; // Go to the next block.    }    }从上面的函数中,我删除了这段代码的实际贡献:对llama.cpp Q6_K编码使用的精确格式的长注释。 现在,如果GPT能为我做到这一点,我敢打赌这只是时间问题,因为这种任务在没有任何突破的情况下就可以达到,只需要一点扩展。把事情放在正确的位置我不得不说,这是事实:当今的编程大多数都是以略有不同的形式重复同样的事情。这并不需要高层次的推理。LLM(大语言模型)在做这件事方面表现很好,尽管它们仍受限于上下文的最大大小。这真的应该让程序员深思。编写这类程序是否值得?当然,你可以获得报酬,而且非常可观,但如果LLM能做其中的一部分,那么在五到十年内这可能不是最好的发展方向。那么,LLM是否具有某些推理能力,或者这全部都是在虚张声势?有时,它们看似能推理,仅仅是因为,正如符号学家所说,“符号”给人一种实际上并不存在的意义的印象。那些在接受LLM的局限性的同时,又足够了解LLM的人可以肯定:事情不可能如此:它们将以前见过的东西融合在一起的能力,远远超出了随机组合词语。尽管它们的训练在预训练阶段主要是通过预测下一个词符号来完成的,但这个目标迫使模型形成某种形式的抽象模型。这个模型是软弱的、破碎的和不完善的,但如果我们观察到我们观察到的,这个模型就必须存在。如果我们的数学确定性是充满疑问的,最伟大的专家们往往持相反立场,那么相信自己亲眼所见似乎是一种明智的做法。最后,今天不使用LLM进行编程有什么意义?向LLM提出正确的问题是一项基本技能。这方面的练习越少,就越难以通过AI改进自己的工作。此外,对问题进行描述性表达的能力在与其他人交流时也很有用。LLM不是唯一可能不理解我们要说什么的。即使在自己的专业领域非常能干,也有许多程序员交流得很糟糕。而且现在谷歌搜索也毫无用处:即使只是将LLM用作文档的压缩形式,使用LLM也是一个好主意。就我个人而言,我将继续大规模使用它们。我从未喜欢学习一个晦涩通信协议或一个想显示自己多强的程序员编写的复杂库的细节。在我看来,这些都像“垃圾知识”。LLM每天都在这个方面帮助我越来越多。"
  },
  
  {
    "title": "机器学习周刊04-动手实战人工智能",
    "url": "/posts/%E5%8A%A8%E6%89%8B%E5%AE%9E%E6%88%98%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/",
    "categories": "机器学习周刊",
    "tags": "机器学习周刊",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "LLM开发者必读论文：检索增强（RAG）生成技术综述！目录：  1、动手实战人工智能 Hands-on Al  2、huggingface的NLP、深度强化学习、语音课  3、Awesome Jupyter  4、计算机科学热门论文  5、LLM开发者必读论文:检索增强 (RAG) 生成技术综述  6、Apple 公布了多模态大型语言模型 Ferret  7、免费的基于ChatGPT API...",
    "content": "LLM开发者必读论文：检索增强（RAG）生成技术综述！目录：  1、动手实战人工智能 Hands-on Al  2、huggingface的NLP、深度强化学习、语音课  3、Awesome Jupyter  4、计算机科学热门论文  5、LLM开发者必读论文:检索增强 (RAG) 生成技术综述  6、Apple 公布了多模态大型语言模型 Ferret  7、免费的基于ChatGPT API的安卓端语音助手  8、每日数学  9、WhisperLive:接近实时的 Whisper 实现  10、Unsloth：大模型训练速度和效率加速工具  11、最后推荐三个AI工具1、动手实战人工智能 Hands-on AI地址：https://ai.huhuhang.com/intro这个《动手实战人工智能 Hands-on AI》写的相当不错，作者用 Jupyter Notebook编写了这个教程，参考了《机器学习方法》，《深度学习入门》，西瓜书，花花书等，剖析和推导每一个基础算法的原理，将数学过程写出来了，同时基于 Python 代码对公式进行实现，做到公式和代码的一一对应。我把章节简单整理成了这个思维导图，大家可以结合自身情况，挑选感兴趣的章节阅读。2、huggingface的NLP、深度强化学习、语音课地址：https://huggingface.co/learnHuggingFace开放了NLP、深度强化学习、基于transformer的语音框架三门课，看了每一课的结构，比较偏实践，蛮不错的。我最近对语音比较感兴趣，加上正在学点前端，所以就把语音课拿出来，做了个文档型网页，准备一边学，一边翻译。感兴趣的同学可以一起翻译：https://hf-audio.zhanglearning.com/3、Awesome Jupyter地址：https://github.com/markusschanta/awesome-jupyter这个项目收录了精选的Jupyter项目、库和资源列表，已经更新了很多年，我比较喜欢可视化部分，认识了很多好玩的库。4、计算机科学热门论文地址：https://trendingpapers.com/trendingpapers这个网站每日更新计算机科学最新、最火的论文，分门别类，查找起来非常方便。打开感兴趣的论文，可以直接跳转到arxiv查看pdf，也可以点击Find similar找到该方向类似的论文。5、LLM开发者必读论文：检索增强（RAG）生成技术综述论文：https://arxiv.org/abs/2312.10997检索增强利用外部知识库来丰富大语言模型的上下文并生成答案，从而提升了答案的准确度。论文深入探讨并梳理了检索增强型生成（ RAG）技术，非常全面。RAG是LLM领域最火爆的方向了，我在公众号中曾推荐过吴恩达老师最近的一个短课：吴恩达最新短课，构建和评估高级 RAG 应用程序，附中英字幕，感兴趣想要学习RAG，这个短课，建议作为首选。6、 Apple 公布了多模态大型语言模型 Ferret地址：github.com/apple/ml-ferret 苹果最新公布的 Ferret 是一种新的多模态大型语言模型（MLLM)，能够理解图像中任何形状或粒度的空间参考，并准确地理解词汇描述。苹果开源了训练、微调、模型代码和模型权重：https://github.com/apple/ml-ferret/可以下载、安装后一个命令运行gradio前端python -m ferret.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --add_region_feature7、免费的基于ChatGPT API的安卓端语音助手地址：https://github.com/Skythinker616/gpt-assistant-android这个项目是免费的、基于ChatGPT API的安卓端语音助手，可通过音量键唤起并进行语音交流，支持联网、Vision拍照识图、连续对话、提问模板、3.5/4.0接口、Markdown渲染等功能8、每日数学地址：https://www.theoremoftheday.org/这个网站每天更新一个数学定理（或引理、法则、公式或恒等式），每一个都足以装饰数学殿堂的墙壁。每个定理都被设计得尽可能让广大观众能够欣赏，如果某个定理的表述看起来难以理解，可以继续查看附带的图形解释、巧妙的动画。9、WhisperLive：接近实时的 OpenAI Whisper 实现地址：https://github.com/collabora/WhisperLive这个项目是一个实时转录应用程序，它使用 OpenAI Whisper 模型将语音输入（来自麦克风的现场音频输入 or预先录制的音频文件 ）转换为文本输出。10、Unsloth地址：https://github.com/unslothai/unsloth训练大语言模型往往会消耗大量算力和时间，Unsloth开源的这个项目可以加快训练速度和效率。  支持 Llama 7b、13b、70b、CodeLlama 34b、Mistral 7b、TinyLlama 以及所有 Llama 架构！  Llama 7b Colab T4 实例在 1 T4 上比原来快 2 倍，使用的 VRAM 减少了 43%（8.4GB）LAION 数据集。Alpaca T4 实例在 1 T4 上也是快了 2 倍，使用了 6.4GB VRAM。  Mistral 7b Colab A100 实例在 1 A100 上快了 2.2 倍，使用的 VRAM 减少了 62%（12.4GB）。Colab T4 实例  CodeLlama 34b Colab 实例不会出现 OOM，速度提升了 1.9 倍，使用的 VRAM 减少了 32%（27GB）。  Kaggle 上使用 2 Tesla T4 的 Alpaca 训练速度提高了 5.28 倍。Kaggle 实例  所有内核均使用 OpenAI 的 Triton 语言编写。  准确率无损失 - 没有使用近似方法 - 全部精确。  无需更换硬件。支持自 2018 年以来的 NVIDIA GPU。最低 CUDA 计算能力 7.0（V100、T4、Titan V、RTX 20、30、40x、A100、H100、L40 等）检查您的 GPU  在 Linux 和 Windows 通过 WSL 上运行。  实验性支持 DPO（直接偏好优化）！  支持通过 bitsandbytes 进行 4bit 和 16bit QLoRA / LoRA 微调。  开源版本的训练速度提高了 5 倍，或者您可以查看 Unsloth Pro 和 Max 代码路径，以获得高达 30 倍的训练速度提升！11、最后推荐三个AI工具PIA：照片转动漫风格工具，可线上试用地址：https://huggingface.co/spaces/Leoxing/PIA带web界面的声音克隆工具地址：https://github.com/jianchang512/clone-voicecloudflare-ai-web地址：https://github.com/Jazee6/cloudflare-ai-web支持GeminiPro Vision / Cloudflare Workers AI / ChatGPT的融合Web平台"
  },
  
  {
    "title": "Python处理电子表格，4个非常流行且功能强大的库",
    "url": "/posts/Python%E5%A4%84%E7%90%86%E8%A1%A8%E6%A0%BC%E7%9B%B8%E5%85%B3%E7%9A%84%E5%BA%93/",
    "categories": "Python系列",
    "tags": "Python",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "在Python中处理表格数据，有几个非常流行且功能强大的库。以下是一些最常用的库及其示例代码：1. PandasPandas是一个开放源代码的、BSD许可的库，为Python编程语言提供高性能、易于使用的数据结构和数据分析工具。安装Pandaspip install pandas示例代码：读取CSV文件import pandas as pd# 读取CSV文件df = pd.read_csv(...",
    "content": "在Python中处理表格数据，有几个非常流行且功能强大的库。以下是一些最常用的库及其示例代码：1. PandasPandas是一个开放源代码的、BSD许可的库，为Python编程语言提供高性能、易于使用的数据结构和数据分析工具。安装Pandaspip install pandas示例代码：读取CSV文件import pandas as pd# 读取CSV文件df = pd.read_csv('pokemon.csv')# 显示前五行数据print(df.head())# 计算某列的平均值print(\"Average of column:\", df['Speed'].mean())# 数据筛选filtered_df = df[df['Speed'] &gt; 10]# 将更改后的DataFrame保存到新的CSV文件filtered_df.to_csv('filtered_example.csv', index=False)2. OpenPyXLOpenPyXL是一个库，用于读取和写入Excel 2010 xlsx/xlsm/xltx/xltm文件。安装OpenPyXLpip install openpyxl示例代码：读取Excel文件from openpyxl import load_workbook# 加载一个现有的工作簿wb = load_workbook('example.xlsx')# 获取活动的工作表sheet = wb.active# 读取A1单元格的值print(sheet['A1'].value)# 修改B2单元格的值sheet['B2'] = 42# 保存工作簿wb.save('modified_example.xlsx')3. CSVPython标准库中的CSV模块提供了读写CSV文件的功能。示例代码：读取CSV文件import csv# 打开CSV文件with open('example.csv', mode='r', encoding='utf-8') as file:    reader = csv.reader(file)        # 遍历每一行    for row in reader:        print(row)# 写入CSV文件with open('output.csv', mode='w', encoding='utf-8', newline='') as file:    writer = csv.writer(file)    writer.writerow(['Name', 'Age', 'City'])    writer.writerow(['Alice', '24', 'New York'])4. xlrd/xlwt这两个库通常一起使用，xlrd用于读取老版本的Excel文件（xls），而xlwt用于写入。安装xlrd和xlwtpip install xlrd xlwt示例代码：读取xls文件import xlrd# 打开工作簿wb = xlrd.open_workbook('catering_sale.xls')# 通过索引获取工作表sheet = wb.sheet_by_index(0)# 读取A1单元格的值print(sheet.cell_value(0, 0))# 获取行数和列数print(sheet.nrows, sheet.ncols)当选择库的时候，最好考虑你的具体需求，例如文件格式（CSV、Excel等）、数据大小、性能需求以及是否需要进行复杂的数据分析和操作。Pandas在数据分析方面提供了广泛的功能，而OpenPyXL、xlrd和xlwt则在处理Excel文件方面各有所长。标准库中的CSV模块足够处理基本的CSV文件操作。"
  },
  
  {
    "title": "Python处理word文档，相关的库",
    "url": "/posts/Python%E5%A4%84%E7%90%86word%E6%96%87%E6%A1%A3-%E7%9B%B8%E5%85%B3%E7%9A%84%E5%BA%93/",
    "categories": "Python系列",
    "tags": "Python",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "当然，Python社区提供了多个库来处理Word文档，主要用于创建、修改和读取Word文件。以下是一些常用的库：  python-docx：用于创建和修改.docx文件。  docx2txt：将.docx文件转换成纯文本。  pywin32 (仅限Windows)：通过Microsoft Word应用程序接口与Word文档交互。python-docxpython-docx 是一个创建和更新M...",
    "content": "当然，Python社区提供了多个库来处理Word文档，主要用于创建、修改和读取Word文件。以下是一些常用的库：  python-docx：用于创建和修改.docx文件。  docx2txt：将.docx文件转换成纯文本。  pywin32 (仅限Windows)：通过Microsoft Word应用程序接口与Word文档交互。python-docxpython-docx 是一个创建和更新Microsoft Word (.docx)文件的Python库。这里有一个简单的例子，展示如何使用 python-docx 创建一个包含一段文本的Word文档：from docx import Document# 创建一个Word文档对象doc = Document()# 向文档添加一个段落doc.add_paragraph('Hello, this is a paragraph in a Word document!')# 保存文档doc.save('hello_world.docx')docx2txtdocx2txt 是一个轻量级的库，用于将.docx文档转换为纯文本。下面是一个例子：import docx2txt# 将.docx文件的内容转换为纯文本text = docx2txt.process(\"example.docx\")# 输出文档的纯文本print(text)pywin32pywin32 提供了与Windows应用程序的接口，包括Microsoft Word。这个库允许你通过COM自动化来操作Word。请注意，这只在Windows系统上有效。以下是使用 pywin32 打开一个Word文档的例子：import win32com.client as win32# 启动Word应用程序word = win32.gencache.EnsureDispatch('Word.Application')word.Visible = False# 打开一个现有的文档doc = word.Documents.Open('path_to_your_document.docx')# 添加一个新段落doc.Paragraphs.Add()doc.Paragraphs.Last.Range.Text = 'This is a new paragraph added by python.'# 保存并关闭doc.SaveAs('new_document.docx')doc.Close()# 退出Wordword.Quit()这些库都可以通过Python的包管理工具pip进行安装。例如，要安装python-docx，你可以使用以下命令：pip install python-docx请注意，运行这些示例代码之前，你需要确保安装了相应的库。"
  },
  
  {
    "title": "Python 处理音频，两个重要的库",
    "url": "/posts/Python%E4%B8%AD%E9%9F%B3%E9%A2%91%E5%A4%84%E7%90%86%E5%BA%93/",
    "categories": "Python系列",
    "tags": "Python",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "pyaudio和sounddevice都是用于Python中音频处理和流的库，允许用户通过他们的API录制、播放和处理音频数据。下面是对这两个库的简要介绍：PyAudioPyAudio 提供了 Python 绑定到 PortAudio，这是一个跨平台的音频I/O库。它允许你很容易地使用Python语言进行音频录制和播放。特点:  跨平台（工作在Unix/Linux、MacOS和Windows...",
    "content": "pyaudio和sounddevice都是用于Python中音频处理和流的库，允许用户通过他们的API录制、播放和处理音频数据。下面是对这两个库的简要介绍：PyAudioPyAudio 提供了 Python 绑定到 PortAudio，这是一个跨平台的音频I/O库。它允许你很容易地使用Python语言进行音频录制和播放。特点:  跨平台（工作在Unix/Linux、MacOS和Windows上）  允许你直接访问声卡或其他音频接口，例如通过麦克风录制声音或者向扬声器输出声音  支持阻塞和非阻塞流  提供了详细的错误信息和音频流状态典型用途:  音频录制和播放  音频信号处理  实现音频应用，如语音识别和合成示例代码:import pyaudioimport wave# 打开WAV文件wf = wave.open('file.wav', 'rb')# 初始化PyAudiop = pyaudio.PyAudio()# 打开流stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),                channels=wf.getnchannels(),                rate=wf.getframerate(),                output=True)# 读取数据data = wf.readframes(1024)# 播放流while len(data) &gt; 0:    stream.write(data)    data = wf.readframes(1024)# 停止流stream.stop_stream()stream.close()# 关闭PyAudiop.terminate()SoundDevicesounddevice库是基于PortAudio的，提供了一个简洁的Pythonic接口，用于录制和播放音频。特点:  跨平台（与PortAudio一样）  提供了同步和异步的音频流接口  支持NumPy，方便进行科学计算  相对于PyAudio，API更加简洁和Pythonic典型用途:  实时音频处理  实验心理学中的音频刺激  用于科学研究的音频数据采集示例代码:import sounddevice as sdimport numpy as npduration = 5.5  # secondsfrequency = 440  # Hz# 生成一个音频信号t = np.linspace(0, duration, int(duration * 44100), False)audio = np.sin(2 * np.pi * frequency * t)# 播放音频sd.play(audio, samplerate=44100)sd.wait()  # 等待音频播放完毕总结两个库都能够处理音频流，但在API设计上有所不同。PyAudio 更接近底层PortAudio接口，提供了很多配置选项和详细的控制。而SoundDevice 提供了更加简化和易于使用的接口，对于需要快速上手的项目而言可能更适合。如果需要进行复杂的音频处理，或者与其他底层音频库（如Librosa或SciPy）结合使用，SoundDevice可能更合适，尤其是因为它支持NumPy数组。选择哪一个库取决于你的项目需求和个人偏好。"
  },
  
  {
    "title": "Python 处理纯文本，12个常用的库",
    "url": "/posts/Python%E4%B8%AD%E7%BA%AF%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3%E7%9A%84%E5%BA%93/",
    "categories": "Python系列",
    "tags": "Python",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "Python 提供了多种库来处理纯文本数据，这些库可以应对从基本文本操作到复杂文本分析的各种需求。以下是一些常用的纯文本处理相关的库：  str 类型: Python 内建的字符串类型提供了许多简便的方法来进行基础文本处理，如分割、连接、替换文本等。# 分割字符串text = \"hello, world\"print(text.split(\",\"))  # 输出：['hello', ' wor...",
    "content": "Python 提供了多种库来处理纯文本数据，这些库可以应对从基本文本操作到复杂文本分析的各种需求。以下是一些常用的纯文本处理相关的库：  str 类型: Python 内建的字符串类型提供了许多简便的方法来进行基础文本处理，如分割、连接、替换文本等。# 分割字符串text = \"hello, world\"print(text.split(\",\"))  # 输出：['hello', ' world']# 连接字符串words = [\"Python\", \"is\", \"awesome\"]print(\" \".join(words))  # 输出：Python is awesome# 替换字符串中的子字符串text = \"Hello World\"print(text.replace(\"World\", \"Python\"))  # 输出：Hello Python  re: Python 的标准库之一，用于执行正则表达式操作。这个库对于复杂的字符串匹配和提取非常有用。import retext = \"The rain in Spain\"x = re.search(\"^The.*Spain$\", text)if x:      print(\"YES! We have a match!\")else:      print(\"No match\")  string: 这个标准库模块包含了一些常见的字符串操作函数和常量。import string# 示例：使用 string 常量print(string.ascii_lowercase)  # 输出：abcdefghijklmnopqrstuvwxyz  textwrap: 用于格式化文本段落以适应屏幕宽度的工具。import textwrapsample_text = '''This is a very very very very very long string.'''print(textwrap.fill(sample_text, width=50))  difflib: 可以用来比较序列之间的差异，包括文本文件。import difflibtext1 = \"Python is great\"text2 = \"Python is good\"d = difflib.Differ()diff = d.compare(text1.split(), text2.split())print('\\n'.join(diff))  codecs: 用于编码和解码文本文件，特别是涉及不同编码的场景。import codecs# 读取一个 UTF-8 编码的文件with codecs.open('example.txt', 'r', 'utf-8') as f:      print(f.read())  unicodedata: 用于处理Unicode字符的数据库。import unicodedata# 获取字符的名称char = 'ñ'name = unicodedata.name(char)print(name)  # 输出：LATIN SMALL LETTER N WITH TILDE  csv: 用于读写CSV格式文件的库，虽然CSV不是纯文本，但是通常被视为简单文本数据的一种。import csvwith open('example.csv', mode='r') as file:      reader = csv.reader(file)      for row in reader:         print(row)  json: 用于读写JSON格式的数据，虽然JSON通常用于数据交换，但也是文本格式的一种。import jsondata = {'key': 'value'}json_data = json.dumps(data)print(json_data)  xml.etree.ElementTree: 用于解析和创建XML数据。import xml.etree.ElementTree as ET# 解析XMLtree = ET.parse('example.xml')root = tree.getroot()# 遍历XML文档for child in root:   print(child.tag, child.attrib)  html.parser: 用于解析HTML文档。from html.parser import HTMLParserclass MyHTMLParser(HTMLParser):   def handle_starttag(self, tag, attrs):      print(\"Start tag:\", tag)   def handle_endtag(self, tag):      print(\"End tag:\", tag)   def handle_data(self, data):      print(\"Data:\", data)parser = MyHTMLParser()parser.feed('&lt;html&gt;&lt;head&gt;&lt;title&gt;Test&lt;/title&gt;&lt;/head&gt;'            '&lt;body&gt;&lt;h1&gt;Parse me!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;')  nltk (Natural Language Toolkit): 一个强大的文本处理库，用于处理人类使用的自然语言数据。import nltknltk.download('punkt')from nltk.tokenize import word_tokenizetext = \"Hello Mr. Smith, how are you doing today?\"tokens = word_tokenize(text)print(tokens)通过使用这些库，Python 程序员能够执行各种文本处理任务，从简单的字符串操作到复杂的文本分析和处理。根据项目的具体需求，正确选择合适的库对于提高效率和代码质量至关重要。"
  },
  
  {
    "title": "Python中图像处理相关库",
    "url": "/posts/Python%E4%B8%AD%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3%E5%BA%93/",
    "categories": "Python系列",
    "tags": "Python",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "在Python中，图像处理是一个涉及图像分析、编辑和处理的广泛领域。有几个流行的库通常用于处理图像，每个库都有其特殊的功能和优势。以下是一些常用的Python图像处理库：1. Pillow (PIL Fork)Pillow是Python Imaging Library (PIL)的一个分支，它添加了一些用户友好的特性和改进。Pillow支持许多基本图像操作，如打开、保存、显示以及转换不同图像...",
    "content": "在Python中，图像处理是一个涉及图像分析、编辑和处理的广泛领域。有几个流行的库通常用于处理图像，每个库都有其特殊的功能和优势。以下是一些常用的Python图像处理库：1. Pillow (PIL Fork)Pillow是Python Imaging Library (PIL)的一个分支，它添加了一些用户友好的特性和改进。Pillow支持许多基本图像操作，如打开、保存、显示以及转换不同图像格式。功能:  图像转换和处理  图像滤镜  绘图操作安装:pip install Pillow示例:from PIL import Image, ImageFilter# 打开一个图像文件image = Image.open('image.jpg')# 应用模糊滤镜blurred_image = image.filter(ImageFilter.BLUR)# 显示图像blurred_image.show()2. OpenCV (Open Source Computer Vision Library)OpenCV是一个开源计算机视觉和机器学习软件库。它包含了超过2500个优化算法，包括经典和最新的计算机视觉和机器学习技术。功能:  图像和视频分析  特征检测和描述  目标跟踪  机器学习安装:pip install opencv-python示例:import cv2# 读取图像image = cv2.imread('image.jpg')# 转换为灰度图像gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)# 显示图像cv2.imshow('Gray image', gray_image)cv2.waitKey(0)cv2.destroyAllWindows()3. scikit-imagescikit-image是基于SciPy构建的一个图像处理库，它提供了一系列算法和图像处理工具。功能:  图像预处理和增强  分割  特征提取  几何变换安装:pip install scikit-image示例:from skimage import io, filters# 读取图像image = io.imread('image.jpg')# 应用Sobel滤镜edges = filters.sobel(image)# 显示结果io.imshow(edges)io.show()4. imageioimageio是一个用于读取和写入各种图像数据格式的库。它的目标是支持广泛的格式，包括动画、视频、多维和科学格式。功能:  读取和写入多种图像格式  支持动画和视频安装:pip install imageio示例:import imageio# 读取图像image = imageio.imread('image.png')# 显示图像的形状print(image.shape)# 保存图像imageio.imwrite('output.jpg', image)5. matplotlibmatplotlib是一个绘图库，它也提供了简单的图像处理功能。通常用于显示图像和绘制图像统计信息。功能:  绘图  图像显示安装:pip install matplotlib示例:import matplotlib.pyplot as pltimport matplotlib.image as mpimg# 读取图像image = mpimg.imread('image.jpg')# 显示图像plt.imshow(image)plt.show()这些库可以用于广泛的图像处理任务，从简单的日常编辑到复杂的计算机视觉应用程序。选择哪个库通常取决于特定的应用需求和个人偏好。"
  },
  
  {
    "title": "一个很高级的、交互式Python可视化库，附示例代码",
    "url": "/posts/HvPlot/",
    "categories": "Python系列",
    "tags": "Python",
    "date": "2024-01-01 14:10:00 +0800",
    





    
    "snippet": "在数据科学和分析的世界里，将数据可视化是至关重要的一步，它能帮助我们更好地理解数据，发现潜在的模式和关系。Python 提供了多种可视化工具，HvPlot 是其中一个出色的库，专为简单且高效的交互式可视化设计。HvPlot 简介HvPlot 是基于 HoloViews 的高层抽象绘图库，但它提供了更为直接和方便的API，使得创建复杂的交互式图表变得简单快捷。HvPlot 可以与 Pandas...",
    "content": "在数据科学和分析的世界里，将数据可视化是至关重要的一步，它能帮助我们更好地理解数据，发现潜在的模式和关系。Python 提供了多种可视化工具，HvPlot 是其中一个出色的库，专为简单且高效的交互式可视化设计。HvPlot 简介HvPlot 是基于 HoloViews 的高层抽象绘图库，但它提供了更为直接和方便的API，使得创建复杂的交互式图表变得简单快捷。HvPlot 可以与 Pandas、xarray 等数据处理库无缝集成，并且支持 Bokeh、Matplotlib 等多种绘图后端，允许用户根据需要制作静态或交互式图表。安装 HvPlot在开始之前，需要安装 HvPlot，可以使用 pip 来安装：pip install hvplot使用示例让我们通过几个简单的例子来展示 HvPlot 的基本用法。示例 1：简单的线图假设我们有一些时间序列数据，我们想要画出它的线图：import hvplot.pandas  # 导入 hvplot 的 pandas 接口import pandas as pdimport numpy as np# 创建一个时间序列数据idx = pd.date_range('2023-01-01', periods=100, freq='D')data = np.random.randn(100).cumsum()df = pd.DataFrame(data, index=idx, columns=['value'])# 使用 hvplot 绘制线图plot = df.hvplot.line(title=\"时间序列示例\")plot这个例子将会产生一个带有标题的时间序列线图，你可以缩放、平移来交互地查看图表。示例 2：散点图和直方图继续利用 HvPlot，我们可以很容易地绘制散点图和直方图来查看变量之间的关系和分布：# 创建一些随机数据df = pd.DataFrame({    'x': np.random.rand(100),    'y': np.random.rand(100)})# 绘制散点图scatter_plot = df.hvplot.scatter('x', 'y', title=\"散点图示例\")scatter_plot# 绘制直方图histogram = df.hvplot.hist('x', bins=20, title=\"直方图示例\")histogram在散点图中，每个点的位置反映了数据表中的一行记录。直方图则显示了变量 ‘x’ 的分布情况。示例 3：交互式探索HvPlot 支持通过交互式小部件来探索数据，例如选择不同的变量来绘图：# 创建一些分类数据df = pd.DataFrame({    'variable': np.random.choice(['A', 'B', 'C'], 100),    'value': np.random.randn(100)})# 交互式绘制箱型图boxwhisker = df.hvplot.box(y='value', by='variable', title=\"箱型图示例\", width=400)boxwhisker这个箱型图将会按照 ‘variable’ 列的类别来显示 ‘value’ 列的分布情况，并且你可以通过交互式图表来查看不同类别的具体统计信息。示例 4：交互式探索当然，HvPlot 不仅适用于基础绘图，还可以创建更高级和复杂的可视化，如动态交叉筛选、地理数据可视化以及使用数据流的实时数据可视化。下面是一个使用 HvPlot 进行动态交叉筛选的示例：我们将使用汽车数据集，展示如何利用 HvPlot 进行动态交叉筛选。用户可以选择汽车的制造年份，动态地看到不同年份下汽车的马力与加速之间的关系。import hvplot.pandasimport pandas as pdimport panel as pnfrom bokeh.sampledata.autompg import autompg_clean as df# 清洗数据，去除缺失值df.dropna(inplace=True)# 创建一个选择器，用于交互year_slider = pn.widgets.IntSlider(name='yr', start=df.yr.min(), end=df.yr.max(), step=1)# 定义一个动态更新的散点图函数@pn.depends(year=year_slider.param.value)def get_scatter_plot(year):    current_df = df[df.yr == year]    return current_df.hvplot.scatter(        x='hp',         y='mpg',         xlim=(df.hp.min() - 10, df.hp.max() + 10),         ylim=(df.mpg.min() - 5, df.mpg.max() + 5),        title=f'马力 vs. 每加仑英里数（年份：{year}）',        color='cyl',         size=10,        hover_cols=['name']    )# 创建一个 Panel，包含选择器和绘图dashboard = pn.Column(year_slider, get_scatter_plot)# 服务化如果你在 Jupyter Notebook 上运行，使用以下命令来显示# dashboard.servable()# 如果你使用的是纯 Python 脚本，使用以下命令来启动服务器dashboard.show()在这个例子中，我们首先导入了必要的库，然后清洗了Bokeh库中的汽车数据集。接着，我们创建了一个IntSlider控件用于选择年份。get_scatter_plot函数定义了如何根据选定的年份更新散点图。最后，我们用pn.Column将滑块和绘图函数组合在一起，形成一个可交互的面板（dashboard）。要注意的是，如果你在 Jupyter Notebook 上运行这段代码，需要调用dashboard.servable()来显示面板。如果是在纯 Python 环境中，需要使用dashboard.show()来启动一个服务器，并在浏览器中查看面板。这只是 HvPlot 功能的冰山一角。HvPlot 结合其他库，如 Panel、Datashader 和 GeoViews，可以实现更加复杂和强大的数据可视化。"
  },
  
  {
    "title": "机器学习周刊03-如何学习深度学习",
    "url": "/posts/%E5%A6%82%E4%BD%95%E5%AD%A6%E4%B9%A0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
    "categories": "机器学习周刊",
    "tags": "机器学习周刊",
    "date": "2023-12-25 14:10:00 +0800",
    





    
    "snippet": "腾讯推出的 AppAgent，是一个多模态智能体，通过识别当前手机的界面和用户指令直接操作手机界面，能像真实用户一样操作手机！机器学习周刊：关注Python、机器学习、深度学习、大模型等硬核技术本期目录：  1、如何学习深度学习？  2、2024 年学习生成式 AI 路线图  3、应用机器学习  4、如何构建高效的RAG系统  5、MLC Chat  6、Ollama  7、DreaMovi...",
    "content": "腾讯推出的 AppAgent，是一个多模态智能体，通过识别当前手机的界面和用户指令直接操作手机界面，能像真实用户一样操作手机！机器学习周刊：关注Python、机器学习、深度学习、大模型等硬核技术本期目录：  1、如何学习深度学习？  2、2024 年学习生成式 AI 路线图  3、应用机器学习  4、如何构建高效的RAG系统  5、MLC Chat  6、Ollama  7、DreaMoving  8、苹果最新论文  9、腾讯最新论文：《AppAgent: 多模态智能体，像真实用户一样操作手机》1、如何学习深度学习？最近X上有推友重提这篇文章，是网友看过 Jeremy 教授的 fast.ai 深度学习课程后，把每节课提到的学习建议和忠告都总结了下来：https://forums.fast.ai/t/things-jeremy-says-to-do/36682/1我让ChatGPT、Claude、Gemini翻译并总结了这篇文章，Gemini完成的更加出色，给出了20条关于学习方法和一些细节的建议（强烈建议，如果时间允许，可以看原文）：  倾听：仔细注意老师在整堂课中的建议和提示。  不要被理论淹没：专注于运行代码并对其进行实验，而不是一开始就陷入理论细节中。  选择一个项目并把它做得精彩：选择一个你感兴趣的项目，并投入额外的精力，确保对其进行优化和改进。  探索不同的数据集：不要局限于课程中提供的数据集；自己寻找数据集并对其进行实验。  不要使你的代码过于复杂：保持你的代码简单和有条理，避免不必要的复杂性。  学习 Jupyter 快捷键：熟悉 Jupyter 快捷键以提高你的效率。  运行代码并对其进行实验：不要只阅读代码；运行它并尝试不同的输入和参数来观察会发生什么。  不要花几个小时试图立即理解所有理论：可以先不理解所有内容；专注于实践方面，并随着时间的推移逐渐加深你的理解。  阅读比赛获胜者的论文：通过阅读比赛获胜者的论文来学习他人的成功经验，注意他们的方法和见解。  使用你拥有的所有文本：在处理 NLP 时，确保使用所有可用的文本，包括未标记的验证集，以增强模型的性能。  学会发音希腊字母：熟悉深度学习论文中常用的希腊字母的发音。  非常习惯 PyTorch 张量：培养对 PyTorch 张量和运算的扎实理解。  应用广播规则：在处理更高秩张量时学习并应用广播规则。  不要假设库是正确的：对库持怀疑态度；验证其正确性并了解其工作原理。  不要担心你是否跟上了所有内容：感到不知所措是正常的；专注于你能理解的内容，并逐渐建立你的知识。  学会调试深度学习代码：调试 DL 代码具有挑战性；确保你的代码简单，并检查中间结果以尽量减少错误。  学习 Swift for TensorFlow：抓住机会学习 Swift for TensorFlow，它为 DL 开发提供了优势。  谨慎的数据增强：在增强数据时，仔细考虑转换及其对数据完整性和标签准确性的影响。  尝试不同的架构：尝试不同的神经网络架构以深入了解它们的性能特征。  尽可能以原始方式预处理数据：作为一般规则，尽量减少对神经网络数据的预处理，以保留其原始信息和结构。2、2024 年学习生成式 AI 路线图项目地址：https://github.com/krishnaik06/Roadmap-To-Learn-Generative-AI-In-2024这个项目总结了生成式AI学习路线，从Python、机器学习、NLP、深度学习、GPT-4、Langchain、向量数据库、LLM项目部署，非常顺畅。3、应用机器学习地址：https://github.com/eugeneyan/applied-ml这个项目分享了各公司在生产中数据科学和机器学习方面的论文和技术博客，已经更新了3年。主要内容包括：  如何构架问题 🔎（例如，将个性化视为推荐系统 vs. 搜索 vs. 序列）  哪些机器学习技术有效 ✅（有时候，哪些不行 ❌）  为什么它有效，背后的科学原理包括研究、文献和引用 📂  实现了什么现实世界的结果（可以更好地评估投资回报率 ⏰💰📈）4、如何构建高效的RAG系统程序员Jiayuan (Forrest)在X上分享了开发者搜索工具 devv.ai 是如何构建RAG系统的过程，内容十分硬核。这里是Treads汇总：https://typefully.com/Tisoga/PBB58Vu5、MLC ChatMLC Chat：在iPhone上离线运行7B最强LLM Mistral中文不太行，速度很快，手机会发热APP下载：https://apps.apple.com/gb/app/mlc-chat/id6448482937。Github：https://github.com/mlc-ai/mlc-llm支持各种系统，能在各种设备上开发、优化和部署AI模型。包括iOS和安卓6、Ollama地址：https://ollama.ai/downloadOllama为那些在macOS、Linux（暂不支持Windows）上使用LLM的开发者提供了一种简便的解决方案，可以更轻松地将这些模型集成到自己的应用程序中。Ollama目前支持了10余种大模型，安装后均可一个命令本地启动并运行            Model      Parameters      Size      Download                  Neural Chat      7B      4.1GB      ollama run neural-chat              Starling      7B      4.1GB      ollama run starling-lm              Mistral      7B      4.1GB      ollama run mistral              Llama 2      7B      3.8GB      ollama run llama2              Code Llama      7B      3.8GB      ollama run codellama              Llama 2 Uncensored      7B      3.8GB      ollama run llama2-uncensored              Llama 2 13B      13B      7.3GB      ollama run llama2:13b              Llama 2 70B      70B      39GB      ollama run llama2:70b              Orca Mini      3B      1.9GB      ollama run orca-mini              Vicuna      7B      3.8GB      ollama run vicuna              LLaVA      7B      4.5GB      ollama run llava      7、DreaMovingDreaMoving是一个基于扩散模型的人类舞蹈视频生成框架。能够根据指导序列和简单的内容描述（仅文本提示、仅图像提示或文本和图像提示）生成高质量、高保真度的视频。体验地址：https://modelscope.cn/studios/vigen/video_generation/summary8、苹果最新论文论文: https://huggingface.co/papers/2312.11514苹果发的这个论文《使用有限的内存实现更快的 LLM 推理》。通过将将模型参数保存在闪存里，根据需要移动到DRAM。 使得能够运行的模型大小是可用DRAM的两倍，与传统的CPU和GPU加载方法相比，推理速度分别提高了4-5倍和20-25倍。9、腾讯最新论文：《AppAgent: 多模态智能体，像真实用户一样操作手机》项目首页：https://appagent-official.github.io论文链接：https://arxiv.org/abs/2312.13771项目地址：https://github.com/mnotgod96/AppAgent论文通过引入一种基于大型语言模型（LLMs）的多模态智能代理（Agent）框架，赋予了智能体操作智能手机应用的能力。与传统的智能助手如 Siri 不同，AppAgent 不依赖于系统后端访问，而是通过模拟人类的点击和滑动等操作，直接与手机应用的图形用户界面（GUI）互动。这种独特的方法不仅提高了安全性和隐私性，还确保了智能体能够适应应用界面的变化和更新。"
  },
  
  {
    "title": "机器学习周刊02-机器学习应用案例",
    "url": "/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B/",
    "categories": "机器学习周刊",
    "tags": "机器学习周刊",
    "date": "2023-12-18 14:10:00 +0800",
    





    
    "snippet": "如何像 Netflix、Airbnb 和 Doordash 这样的公司应用机器学习来改进他们的产品和流程？机器学习周刊：关注Python、机器学习、深度学习、大模型等硬核技术本期目录：  1、Python编程挑战  2、机器学习应用案例  3、Hello 算法  4、《理解深度学习》pdf 免费下载  5、微软 GitHub Copilot 教程1、Python编程挑战地址：https://...",
    "content": "如何像 Netflix、Airbnb 和 Doordash 这样的公司应用机器学习来改进他们的产品和流程？机器学习周刊：关注Python、机器学习、深度学习、大模型等硬核技术本期目录：  1、Python编程挑战  2、机器学习应用案例  3、Hello 算法  4、《理解深度学习》pdf 免费下载  5、微软 GitHub Copilot 教程1、Python编程挑战地址：https://github.com/Asabeneh/30-Days-Of-Python30天Python编程挑战是一个逐步学习Python编程语言的指南，虽然命名为30天，但实际可能需要超过100天。你可以根据自己的学习进度来安排。2、机器学习应用案例地址：https://www.evidentlyai.com/ml-system-design如何像 Netflix、Airbnb 和 Doordash 这样的公司应用机器学习来改进他们的产品和流程？evidently整理了一个包含 80 多家公司的 300 个案例研究的数据库，分享了从设计机器学习系统中获得的实用机器学习应用案例和经验。可以通过行业或机器学习应用场景对这些案例研究进行筛选：  不同数据类型的机器学习系统，比如计算机视觉（CV）或自然语言处理（NLP）。  针对特定场景的机器学习系统，最流行的包括推荐系统、搜索排序和欺诈检测。  其中还特别标出了那些利用机器学习为用户直接提供“产品功能”的案例，比如从语法纠错到搭配服装的创意。这也网站看着眼熟吗？前几天我介绍过他家的库：一个神奇的Python库：Evidently，机器学习必备3、Hello 算法地址：https://github.com/krahets/hello-algo《Hello 算法》：动画图解、一键运行的数据结构与算法教程，支持 Java, C++, Python, Go, JS, TS, C#, Swift, Rust, Dart, Zig 等语言。本项目旨在打造一本开源免费、新手友好的数据结构与算法入门教程。  全书采用动画图解，内容清晰易懂、学习曲线平滑，引导初学者探索数据结构与算法的知识地图。  源代码可一键运行，帮助读者在练习中提升编程技能，了解算法工作原理和数据结构底层实现。  鼓励读者互助学习，提问与评论通常可在两日内得到回复。 对Python感兴趣的话，直接移步这里：https://github.com/krahets/hello-algo/tree/main/codes/python4、《理解深度学习》pdf 免费下载目录：第1章 - 引言第2章 - 监督学习第3章 - 浅层神经网络第4章 - 深度神经网络第5章 - 损失函数第6章 - 训练模型第7章 - 梯度和初始化第8章 - 性能评估 第9章 - 正则化第10章 - 卷积网络第11章 - 残差网络第12章 - 变换器（Transformers）第13章 - 图神经网络第14章 - 无监督学习第15章 - 生成对抗网络第16章 - 正规化流第17章 - 变分自编码器第18章 - 扩散模型第19章 - 深度强化学习第20章 - 深度学习为什么有效？第21章 - 深度学习与伦理学下载地址：https://udlbook.github.io/udlbook/这里不但有本书的pdf下载，还有每一章节的习题ipynb代码5、微软 GitHub Copilot 教程地址：https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming微软出的 GitHub Copilot 教程，只有 6 堂课，会教你如何有效利用 GitHub Copilot 以及与 AI 结对编程。 课程一共 10 小时，可以体验如何通过 VSCode 和 GitHub Copilot Chat 进行实时协作，学习如何使用 GitHub Copilot 自动补全代码，处理错误和写单元测试，尽可能教会你使用 GitHub Copilot 的最佳实践，让你可以提升写代码的效率和质量。            课程链接      教授的概念      学习目标                  01      GitHub入门      在不到一小时内开始使用GitHub。              02      GitHub Codespaces入门      使用GitHub Codespaces和Visual Studio Code开发代码！              03      GitHub Copilot入门      GitHub Copilot能通过在VS Code和Codespaces中提供类似自动完成的建议来帮助你编码。              04      用JavaScript驾驭GitHub Copilot      使用GitHub Copilot这个提供类似自动完成建议的AI编程助手来编写JavaScript代码。              05      用Python驾驭GitHub Copilot      使用GitHub Copilot这个提供类似自动完成建议的AI编程助手来编写Python代码。              06      用GitHub Copilot创建迷你游戏      利用GitHub Copilot协助你构建一个基于Python的迷你游戏。      "
  },
  
  {
    "title": "机器学习周刊01-数据科学资料合集",
    "url": "/posts/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E8%B5%84%E6%96%99%E5%90%88%E9%9B%86/",
    "categories": "机器学习周刊",
    "tags": "机器学习周刊",
    "date": "2023-12-11 14:10:00 +0800",
    





    
    "snippet": "机器学习工程师面试常见问题的分享,包括来自 Facebook、Amazon、Google 等大公司的面试经历。机器学习周刊：关注Python、机器学习、深度学习、大模型等硬核技术本期目录：  1、超完整数据科学资料合集  2、机器学习算法实现的最小和最干净的例子  3、机器学习面试  4、深度学习论文精读  5、微软开源的promptbase  6、苹果最新开源的机器学习框架  7、Mist...",
    "content": "机器学习工程师面试常见问题的分享,包括来自 Facebook、Amazon、Google 等大公司的面试经历。机器学习周刊：关注Python、机器学习、深度学习、大模型等硬核技术本期目录：  1、超完整数据科学资料合集  2、机器学习算法实现的最小和最干净的例子  3、机器学习面试  4、深度学习论文精读  5、微软开源的promptbase  6、苹果最新开源的机器学习框架  7、Mistralai client-python1、超完整数据科学资料合集地址：https://github.com/krishnaik06/The-Grand-Complete-Data-Science-Materials  Python 数据分析和数据科学完整播放列表  数据分析和数据科学的完整统计学播放列表  数据分析和数据科学的完整 SQL  Git 和 Github 教程  探索性数据分析、特征工程和特征选择  机器学习播放列表  深度学习和自然语言处理完整播放列表  生产部署的重要框架  完整的 AWS Sagemaker 和 Sagemaker Studio 工具  完整的 MLOPS 教程  使用开源工具的端到端机器学习、深度学习和自然语言处理项目,直到部署  生成式 AI 和 Open AI 播放列表  PySpark 完整教程  完整的数据科学、机器学习和深度学习面试题2、机器学习算法实现的最小和最干净的例子地址：https://github.com/rushter/MLAlgorithms这个项目有点老，但是知识不老。主要面向希望学习机器学习算法内部原理,或者从零开始自己实现机器学习算法的人群。相比于高效优化的现成机器学习库,这个项目中的代码更容易理解和操作。所有的算法都是用 Python 实现的,利用了 numpy、scipy 和 autograd 这些库。已经实现的算法包括:  深度学习(多层感知器、卷积神经网络、递归神经网络、长短期记忆网络)  线性回归、逻辑回归  随机森林  支持向量机(线性核、多项式核、RBF 核)  K均值聚类  高斯混合模型  K近邻  朴素贝叶斯  主成分分析(PCA)  因子分解机  受限玻尔兹曼机(RBM)  t分布随机嵌入(t-SNE)  梯度提升决策树(也称为 GBDT、GBRT、GBM、XGBoost)  强化学习(深度 Q 学习)3、机器学习面试地址：https://github.com/khangich/machine-learning-interview包含了机器学习工程师面试常见问题的分享,包括来自 Facebook、Amazon、Google 等大公司的面试经历。作者 Pham An Khang 通过收集整理不同公司的面试题,并分享自己以及朋友的面试准备经验,帮助读者为机器学习岗位面试做准备。4、深度学习论文精读地址：https://github.com/mli/paper-reading?tab=readme-ov-file5、微软开源的promptbase地址：https://github.com/microsoft/promptbasepromptbase 微软开源的一系列资源、最佳实践和示例脚本,用于从 GPT-4 等基础模型中激发出最佳性能。号称：All things prompt engineering（关于提示工程的一切）6、苹果最新开源的机器学习框架地址：https://github.com/ml-explore/mlx熟悉的 API:MLX 具有一个紧随 NumPy 的 Python API。MLX 还有一个功能齐全的 C++ API,与 Python API 密切相关。MLX 具有更高级的包,如 mlx.nn 和 mlx.optimizers,其 API 紧随 PyTorch,以简化构建更复杂的模型。苹果同时还公布了mlx应用示例：https://github.com/ml-explore/mlx-examples示例包括：  Transformer 语言模型训练  使用 LLaMA 或 Mistral进行大规模文本生成  混合专家(MoE)语言模型与 Mixtral 8x7B  使用 LoRA进行参数高效微调。  使用 Stable Diffusion 生成图像。  使用 OpenAI 的 Whisper进行语音识别。  使用 BERT进行双向语言理解  在图结构数据上使用 GCN进行半监督学习7、Mistralai client-python地址：https://github.com/mistralai/client-pythonMistral AI 发布的，最近风头最盛的大模型`Mixtral 8x7B，这个库是Mistral AI官方开源的Python客户端，可以直接调用Mistral AI API"
  },
  
  {
    "title": "『机器学习』核心概念的可视化解释",
    "url": "/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%AF%E8%A7%86%E5%8C%96%E8%A7%A3%E9%87%8A/",
    "categories": "机器学习",
    "tags": "机器学习, 可视化",
    "date": "2023-01-13 10:10:00 +0800",
    





    
    "snippet": "MLU（ Machine Learning University，机器学习大学）是亚马逊的一项教育计划，旨在教授机器学习理论和实际应用。MLU-Explain 作为计划的一部分，通过可视化这种信息丰富且有趣的方式，讲解了机器学习的重要概念。交互页面的设计非常酷！https://mlu-explain.github.io/不过现在涉及的模型不太多，主要有机器学习基本概念（ROC AUC 交叉验...",
    "content": "MLU（ Machine Learning University，机器学习大学）是亚马逊的一项教育计划，旨在教授机器学习理论和实际应用。MLU-Explain 作为计划的一部分，通过可视化这种信息丰富且有趣的方式，讲解了机器学习的重要概念。交互页面的设计非常酷！https://mlu-explain.github.io/不过现在涉及的模型不太多，主要有机器学习基本概念（ROC AUC 交叉验证 测试/验证/测试集 准确率 召回率等等），还有简单线性回归、逻辑回归、决策树、随机森林等"
  },
  
  {
    "title": "用Python制作高逼格数学动画manim",
    "url": "/posts/%E7%94%A8Python%E5%88%B6%E4%BD%9C%E9%AB%98%E9%80%BC%E6%A0%BC%E6%95%B0%E5%AD%A6%E5%8A%A8%E7%94%BBmanim/",
    "categories": "Python",
    "tags": "python, manim",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "简介manim是斯坦福大学数学系小哥Grant Sanderson开源的数学仿真模拟python库，并用于YouTube 频道3Blue1Brown，来解说高等数学。manim是一个非常优秀的数学动画制作引擎，先来两个GIF感受一下 manim 的魅力：很多同学应该在 B 站看过3b1b的视频，最经典的就是线性代数的本质系列。版本说明manim 初学者可能会有些许困惑，网上的代码、文档、教程...",
    "content": "简介manim是斯坦福大学数学系小哥Grant Sanderson开源的数学仿真模拟python库，并用于YouTube 频道3Blue1Brown，来解说高等数学。manim是一个非常优秀的数学动画制作引擎，先来两个GIF感受一下 manim 的魅力：很多同学应该在 B 站看过3b1b的视频，最经典的就是线性代数的本质系列。版本说明manim 初学者可能会有些许困惑，网上的代码、文档、教程等差异太大，不知道该跟着那个学习。目前manim有三个版本：3b1b 旧版：3blue1brown 自己维护的版本，使用 Cairo 作为后端。3b1b 新版：3blue1brown 自己维护的版本，使用 OpenGL 和 moderngl 来进行 GPU 渲染，优点是速度快。manim 社区版：manim 旧版的衍生，更新更活跃，有很好的文档和社区支持。我比较信任Grant Sanderson 大神，所以直接学习了新版。manimgl 环境搭建manimgl 这个版本的安装特别简单1、安装配置FFmpeg和LaTexhttps://ffmpeg.org/download.html FFmpeg，下载安装即可，把安装路径添加到环境变量即可https://mirror.ctan.org/systems/texlive/tlnet/install-tl-windows.exeLaTex更简单，一路下一步即可。2、创建虚拟环境conda create -n manim python=3.8conda activate manim3、安装manimgl包pip install manimgl也可以clone最新的源码进行安装git clone https://github.com/3b1b/manim.gitcd manimpip install -e .这样还能测试一下是否安装成功了。manimgl example_scenes.py OpeningManimExample学习资源官方文档：https://3b1b.github.io/manim中文文档:https://docs.manim.org.cn/3b1b 视频源码：https://github.com/3b1b/videosmanim 源码：https://github.com/3b1b/manim学习顺序，可以先看中/英文文档，然后就动手制作自己的动画吧。如有余力，可以抽空看看3b1b的视频源码，如果能为manim贡献代码就更好了。最近在youtube上看到了一个用 manim 制作了数据结构与算法的视频，挺强的。视频源码：https://github.com/nipunramk/Reducible祝大家学的愉快，也欢迎交流学习，这一块我也是小白呢。"
  },
  
  {
    "title": "太骚了，用Excel玩机器学习",
    "url": "/posts/%E7%94%A8Excel%E7%8E%A9%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/",
    "categories": "机器学习",
    "tags": "机器学习, excel",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "最近发现了一个好玩的Python库，它可以将训练好的机器学习模型转换为Java、C、JavaScript、Go、Ruby，VBA 本地代码，可以让连Python和机器学习一无所知的同学也能感受预测的神奇。先看效果哈其实做这个小东西，感觉还能玩出别的花样，但不清楚到底有什么场景。写这篇文章的时候，我对Excel的 VBA 一无所知，百度了几个用法就开搞了。现在我也能用 VBA 写一些函数和过程...",
    "content": "最近发现了一个好玩的Python库，它可以将训练好的机器学习模型转换为Java、C、JavaScript、Go、Ruby，VBA 本地代码，可以让连Python和机器学习一无所知的同学也能感受预测的神奇。先看效果哈其实做这个小东西，感觉还能玩出别的花样，但不清楚到底有什么场景。写这篇文章的时候，我对Excel的 VBA 一无所知，百度了几个用法就开搞了。现在我也能用 VBA 写一些函数和过程了，这也许是最大的收货吧。m2cgenm2cgen（Model 2 Code Generator）是一个轻量级代码生成器，它可以将训练好的机器学习模型转换成无需依赖库的本地代码。m2cgen目前支持的模型还蛮多的，常用常见的都包括了：使用方法m2cgen的安装非常方便，直接pip：pip install m2cgen使用，先用XGBClassifier训练一个模型# import packagesimport pandas as pdimport numpy as npimport os refrom random import samplefrom sklearn import datasetsfrom xgboost import XGBClassifierfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scoreimport pickleimport m2cgen as m2cseed = 2020test_size = 0.3X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)# fit model on training datamodel = XGBClassifier()model.fit(X_train, y_train)将模型转为VBAcode = m2c.export_to_visual_basic(model, function_name = 'pred')  VBA的英文全称是Visual Basic for Applications，是一门标准的宏语言，通常使用来实现Excel中没有提供的功能、编写自定义函数、实现自动化功能等。VBA语言不能单独运行，只能被office软件（如：Word、Excel等）所调用。生成的VBA长这样：实话实话，我对VBA还是小白，也懒得深究，于是就把代码改成了过程，这里就不贴了，我把改好之后的代码放到了github。有VBA大神可以帮忙，欢迎提交 PR。  https://github.com/tjxj/excel2ml想省事的同学直接去copy即可Excel点击excel菜单中的【开发工具】（如果没有开发工具选项卡，请参考：excel开发工具选项卡在哪？原来需要自己添加），然后在代码选项卡中点击【Visual Basic】 即可，也可以直接Alt + F11 唤出：点击插入-模块，把改好的 VBA 代码贴进去即可保存后退出，然后回到sheet页，开发工具-插入-按钮编辑好文字后，右键指定宏，选中我们刚才保存的那个即可。然后就一切OK了。The End"
  },
  
  {
    "title": "干掉 LaTeX ！用BookDown写本书",
    "url": "/posts/%E7%94%A8BookDown%E5%86%99%E6%9C%AC%E4%B9%A6/",
    "categories": "R",
    "tags": "r, bookdown",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "我进军B站了提到我正在做一个很纯净的机器学习的学习网站，技术实现上其实很简单，用了之前我提到过的Bookdown干掉 LaTeX ！用BookDown写本书+github.io。还没有完全做好，但是先把过程简单介绍一下，有相同需求的同学可以借鉴。bookdownbookdown是著名R包作者谢益辉开发的，支持采用Rmarkdown (R代码可以运行)或普通markdown编写文档，然后编译成...",
    "content": "我进军B站了提到我正在做一个很纯净的机器学习的学习网站，技术实现上其实很简单，用了之前我提到过的Bookdown干掉 LaTeX ！用BookDown写本书+github.io。还没有完全做好，但是先把过程简单介绍一下，有相同需求的同学可以借鉴。bookdownbookdown是著名R包作者谢益辉开发的，支持采用Rmarkdown (R代码可以运行)或普通markdown编写文档，然后编译成HTML, WORD, PDF, Epub等格式。 bookdown是个素颜版的 LaTeX ，满足了99%的需求，而使用难度大概只有 LaTeX 的1%，性价比极高。  完全开源，向收费说不  完全自定义，想干啥就干啥  有Rstudio背书，可以大胆的长期使用  静态网站，很容易部署到Internet  支持LaTeX，可以直接导出tex文档  导出排版好的PDF文档和kindle文档  使用十分方便，安装后可以专心使用RMarkdown写作  写完后直接排序组合，一键build成书      R Markdown的优势（值得系统学习）    代码与文本共存，程序员的最爱  轻量级，再大的文件也有着极快的读取速度  文末可以列出参考文献，科研狗的最爱如何使用bookdown1、安装R和Rstudio2、安装bookdown包install.packages(\"bookdown\")3、克隆demo到本地，解压后用Rstudio打开.Rproj文件https://github.com/rstudio/bookdown-demo4、打开工程中章节对应的.Rmd文件进行编辑5、编辑完成的章节在Rstudio面板Build–Build Book编译成书6、编译完成之后会自动生成一个_book文件夹，里面包含了静态html文件github.iogithub提供了一个功能叫github.io，用官网的一句话来形容 Websites for you and your projects.gitHub.io可以存放 .html 文件来展示网页，可用于项目主页也可以搭建个人博客。1.首先我们需要拥有一个 GitHub 账号；2.登录我们的GitHub账号进入主页；3.选择创建项目；4.创建一个仓库，仓库名必须以 username.github.io 命名；5.Clone 你的仓库到本地；6.将bookdown生成的_book下的静态html文件全部push到username.github.io 这个仓库。7.静待十分钟左右，打开username.github.io 就可以看到效果了参考：https://www.jianshu.com/p/22b413e3da53"
  },
  
  {
    "title": "浏览器里玩深度学习",
    "url": "/posts/%E6%B5%8F%E8%A7%88%E5%99%A8%E9%87%8C%E7%8E%A9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",
    "categories": "深度学习",
    "tags": "深度学习, tensorflow",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "大家好，我是章北海我一直探索更好玩地介绍机器学习，降低学习门槛，用其开发有趣，有价值的应用。之前介绍过很多机器学习应用方面的玩法，比如：gRPC部署训练好的机器学习模型，使用FastAPI构建机器学习API，用streamlit快速生成机器学习web应用  ，在Excel里玩机器学习。←点击直达最近我在玩 TensorFlow.js ，计划用它整个活儿。本文就是  TensorFlow.js...",
    "content": "大家好，我是章北海我一直探索更好玩地介绍机器学习，降低学习门槛，用其开发有趣，有价值的应用。之前介绍过很多机器学习应用方面的玩法，比如：gRPC部署训练好的机器学习模型，使用FastAPI构建机器学习API，用streamlit快速生成机器学习web应用  ，在Excel里玩机器学习。←点击直达最近我在玩 TensorFlow.js ，计划用它整个活儿。本文就是  TensorFlow.js 的极简入门。TensorFlow.jsTensorFlow.js 是一个开源硬件加速 JavaScript 库，用于训练和部署机器学习模型。它可以让我们直接在浏览器中训练和部署机器学习模型的 JavaScript 库，可以非常灵活地进行 AI 应用的开发:      不需要安装软件或驱动（打开浏览器即可使用）；        可以通过浏览器进行更加方便的人机交互；        可以通过手机浏览器，调用手机硬件的各种传感器（如：GPS、摄像头等）；        用户的数据可以无需上传到服务器，在本地即可完成所需操作。  TensorFlow.js 主要是由 WebGL 提供能力支持，并提供了一个用于定义模型的高层  API ，以及用于线性代数和自动微分的低级 API 。TensorFlow.js 支持导入 TensorFlow SavedModels  和  Keras  模型。TensorFlow.js 环境配置在浏览器中加载 TensorFlow.js ，最方便的办法是在 HTML 中直接引用 TensorFlow.js 发布的 NPM 包中已经打包安装好的 JavaScript 代码。&lt;html&gt;&lt;head&gt;   &lt;script src=\"http://unpkg.com/@tensorflow/tfjs/dist/tf.min.js\"&gt;&lt;/script&gt;也可以在Node.js中使用TensorFlow.js，配置也不算太复杂：安装 Node.js npm yarn  Node.js是基于Chrome的JavaScript构建的跨平台JavaScript运行时环境，npm是Node.js的默认程序包管理器，也是世界上最大的软件注册表。sudo apt updatesudo apt install nodejs npm如果已经安装过node.js，尽量升级到最新版本# 更新npm ：npm install -g npm# 更新node版本：先清除npm缓存：npm cache clean -f# 然后安装n模块：npm install -g n# 升级node.js到最新稳定版：n stableTensorFlow.js的example运行时会用到 Yarn 这里一并安装。（不装也行，npm撑得住）  Yarn就是一个类似于 npm 的包管理工具，主要的优势在于：速度快、离线模式、版本控制。坑已经帮大家踩过了，请必按以下方式安装：curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.listsudo apt update &amp;&amp; sudo apt install yarnyarn建立 TensorFlow.js 项目目录:$ mkdir tfjs$ cd tfjs安装 TensorFlow.js:# 初始化项目管理文件 package.json$ npm init -y# 安装 tfjs 库，纯 JavaScript 版本$ npm install @tensorflow/tfjs# 安装 tfjs-node 库，C Binding 版本$ npm install @tensorflow/tfjs-node# 安装 tfjs-node-gpu 库，支持 CUDA GPU 加速$ npm install @tensorflow/tfjs-node-gpu确认 Node.js 和 TensorFlow.js 工作正常:$ node&gt; require('@tensorflow/tfjs').version{    'tfjs-core': '1.3.1',    'tfjs-data': '1.3.1',    'tfjs-layers': '1.3.1',    'tfjs-converter': '1.3.1',    tfjs: '1.3.1'}&gt;如果你看到了上面的 tfjs-core, tfjs-data, tfjs-layers 和 tfjs-converter 的输出信息，那么就说明环境配置没有问题了。然後，在 JavaScript 程序中，通过以下指令，即可引入 TensorFlow.js：import * as tf from '@tensorflow/tfjs'console.log(tf.version.tfjs)// Output: 1.3.1玩法及EamplesTensorFlow.js 玩法有一下几种：  在浏览器上运行官方 TensorFlow.js 模型:https://www.tensorflow.org/js/models/  转换 Python 模型:https://www.tensorflow.org/js/tutorials#convert_pretained_models_to_tensorflowjs  使用迁移学习来用你自己的数据自定义模型https://www.tensorflow.org/js/tutorials/transfer/what_is_transfer_learning  直接在 JavaScript 中构建和训练模型https://www.tensorflow.org/js/tutorials最好的学习资源是TensorFlow.js官方案例：可以直接点击链接直达感受一下TensorFlow.js的魅力也可以clone整个项目，cd到示例文件夹：#如果你在用yarn:cd irisyarnyarn watch#如果你在用npm:cd irisnpm installnpm run watch"
  },
  
  {
    "title": "比TensorFlow还强的机器学习框架？",
    "url": "/posts/%E6%AF%94Tensorflow%E8%BF%98%E5%BC%BA/",
    "categories": "机器学习",
    "tags": "机器学习, ml5.js",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "大家好，我是章北海Python是机器学习和深度学习的首选编程语言，但绝不是唯一。训练机器学习/深度学习模型并部署对外提供服务（尤其是通过浏览器）JavaScript 是一个不错的选择，市面上也出现了很多 JavaScript 机器学习库，比较著名的就是谷歌的 TensorFlow.js。我在《用浏览器玩机器学习，赞！》一文中已详细介绍TensorFlow.js的用法，感兴趣的同学可以去看看。...",
    "content": "大家好，我是章北海Python是机器学习和深度学习的首选编程语言，但绝不是唯一。训练机器学习/深度学习模型并部署对外提供服务（尤其是通过浏览器）JavaScript 是一个不错的选择，市面上也出现了很多 JavaScript 机器学习库，比较著名的就是谷歌的 TensorFlow.js。我在《用浏览器玩机器学习，赞！》一文中已详细介绍TensorFlow.js的用法，感兴趣的同学可以去看看。今天要向大家介绍一个功能更加强大的 JavaScript 机器学习库——ML5.js。它构建在 Tensorflow 之上，可进一步简化直接从 JavaScript访问机器学习模型的过程。ml5.jsml5.js是一个javascript实现的，能在浏览器里面运行的机器学习框架，它封装了tensorflow.js的API，给开发者提供一个更简单的使用环境，降低了机器学习编码的成本。ml5js官方提供的机器学习案例类型有图像、声音和文本三个类别.每个模型都有初始化，参数，属性，方法的详细介绍，以ml5.imageClassifier() 为例，大家去对应目录查看即可：  https://learn.ml5js.org/#/reference/image-classifier其实大家完全不用担心难以使用，因为ml5.js，太简单了。有多简化？我们看一下核心代码：// Step 1: 使用MobileNet创建图像分类模型const classifier = ml5.imageClassifier('MobileNet', onModelReady);// Step 2: 选择一张图片const img = document.querySelector(\"#myImage\")// Step 3: 预测图片分类结果let prediction = classifier.predict(img, gotResults);// Step 4: 对结果进行操作function gotResults(err, results) {  console.log(results);}html中使用ml5.js更简单了，只需一行：&lt;script src=\"https://unpkg.com/ml5@0.10.5/dist/ml5.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt;是不是及其简单？ml5js 如何入门学习ml5.js最佳方式是从官方实例入手：examples.ml5js.org大家可以通过 p5.js web editor查看案例，不但可以实时看到效果，还有具体代码：  p5.js 是一个JavaScript的函数库，是一个对初学者非常友好的编程环境，能够将制作出来的有创意，有趣的东西呈现在任何的浏览器上。不过我更推荐克隆整个项目，然后在本地运行这些案例，步骤如下：# 1:克隆项目git clone https://github.com/ml5js/ml5-library.gitcd ml5-library# 2:安装依赖npm install# 3:运行本地服务npm run develop# 4:浏览器访问  localhost:8081ml5js 实例以图形识别为例，一个项目必须包含一个html页面，代码如下：&lt;html&gt;&lt;head&gt;  &lt;meta charset=\"UTF-8\"&gt;  &lt;title&gt;Image Classification Example&lt;/title&gt;  &lt;script src=\"https://unpkg.com/ml5@0.10.5/dist/ml5.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;  &lt;h1&gt;Image classification using MobileNet&lt;/h1&gt;  &lt;p&gt;The MobileNet model labeled this as &lt;span id=\"result\"&gt;...&lt;/span&gt; with a confidence of &lt;span id=\"probability\"&gt;...&lt;/span&gt;.&lt;/p&gt;  &lt;img src=\"images/dog.jpeg\" id=\"image\" width=\"400\"                    /&gt;  &lt;script src=\"sketch.js\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt;模型实现在 sketch.js，代码如下：const image = document.getElementById('image'); // 需要识别的图片const result = document.getElementById('result'); // html中的结果标签const probability = document.getElementById('probability'); // 识别概率标签// 用MobileNet初始化imageClassifierml5.imageClassifier('MobileNet')  .then(classifier =&gt; classifier.classify(image))  .then(results =&gt; {    result.innerText = results[0].label;    probability.innerText = results[0].confidence.toFixed(4);  });在image目录下放我们要识别的图片，本例中就是dog.jpeg建议VsCode运行，记得安装 Live Server 插件用 Live Server 打开index.html，浏览器会自动弹出  http://127.0.0.1:5500/learn-ml5js/index.html"
  },
  
  {
    "title": "机器学习入门指南",
    "url": "/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97/",
    "categories": "Tutorial",
    "tags": "机器学习, 入门教程",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "向大家分享我机器学习之路看过的一些书、教程、视频，还有学习经验和建议，希望能对大家的学习有所帮助。Python——书之前跟出版社合作，书柜里积攒了很多Python相关的书，这里推荐三本最有价值的吧。  《流畅的Python》，很厚，比较全面，可以作为工具书常常翻看。  《 从入门到实践（第2版）》 非常全面，对新手还算友好，里面有很多的练习项目非常不错。  《利用Python进行数据分析·第...",
    "content": "向大家分享我机器学习之路看过的一些书、教程、视频，还有学习经验和建议，希望能对大家的学习有所帮助。Python——书之前跟出版社合作，书柜里积攒了很多Python相关的书，这里推荐三本最有价值的吧。  《流畅的Python》，很厚，比较全面，可以作为工具书常常翻看。  《 从入门到实践（第2版）》 非常全面，对新手还算友好，里面有很多的练习项目非常不错。  《利用Python进行数据分析·第2版》 数据分析入门必读书，主要介绍了python 3个库numpy（数组），pandas（数据分析）和matplotlib（绘图）的学习。有开源版，就不用买了，下载链接及代码如下：https://github.com/iamseancheney/python_for_data_analysis_2nd_chinese_versionPython——教程学习Python最好的入门线上教程，首推Python官方文档  https://docs.python.org/zh-cn/3/tutorial/index.html官方文档足够详细和系统，但是内容太庞大，学习来会有点吃力，我建议只看tutorial即可，就是上面的链接。直接啃官方文档的教材，不如老师讲给你听来的效率高。廖雪峰的Python新手教程也是个不错的选择，每一节都有练习题，学习来更顺畅，对新手很友好。https://www.liaoxuefeng.com/wiki/1016959663602400机器学习最常用的库少不了Numpy Pandas Matplotlib这些库我觉得看官方文档就好了，不过英文不好的同学可能就不满意了，这里分别列一下这些库的官方文档和我觉得很不错的中文教程，提醒一下哈，官方文档只需要看我列出的链接即可。Numpy官方文档：https://numpy.org/doc/stable/user/quickstart.html中文教程：https://www.numpy.org.cn/user/quickstart.htmlPandas官方文档：https://pandas.pydata.org/docs/user_guide/10min.html中文教程：https://www.pypandas.cn/docs/getting_started/10min.htmlMatplotlib官方文档：https://matplotlib.org/stable/tutorials/introductory/usage.html中文教程：https://www.matplotlib.org.cn/tutorials/Python——视频实话实话，我没有完整的看过任何Python视频。归根结底，Python入门很简单，看视频效率太低。传言B站的[小甲鱼]零基础入门学习Python不错，简单看了一眼，确实0基础。我们用Python是用来学机器学习的，喜欢看视频学习的同学可以看看，建议只看P1-P53即可。《零基础入门学习Python》：https://www.bilibili.com/video/av27789609机器学习——书市面上凡推荐机器学习的书，都少不了李航的《统计学习方法》和周志华的《机器学习》，我当初也是看了大佬推荐，在这两本书上耗费了极多的时间。但这两本我觉得都很不适合入门，尤其是统计学习方法，简直就是上等武功秘籍，太过精炼，啃起来太吃力。对比起来周老师的《机器学习》相对好点，其中有些公式推导有点跳，Datawhale 出了一本开源的《机器学习公式详解》是个很好的补充。周世华的《机器学习》是必不可少的工具书，还是必读的，而且要反复阅读，不过建议在看过视频教程之后。偏应用的书，只推荐一本，其他的都不要看！！！：《机器学习实战：基于Scikit-Learn、Keras和TensorFlow（原书第2版）》，入门可以先看前 9 章。市面上很少有书能够把机器学习在业务层面的应用介绍清楚，比如模型解释、模型上线，模型监控等等，没有看到特别详细的，有一本还算满意，就是知名度比较低：《机器学习：软件工程方法与实现。现在无论是竞赛还是工业界，boost模型都应用十分广泛，分类、回归、排序，XGBoost都能搞。最后再介绍一本我认为的必读：《深入理解XGBoost：高效机器学习算法与进阶》，作者是XGBoost开源社区贡献者何龙。这本书以机器学习基础知识做铺垫，深入剖析了XGBoost的原理、分布式实现、模型优化、深度应用等。机器学习——教程教程没有看到太好的，除了sklearn的文档，只推荐吴恩达、李宏毅、林轩田三位老师的视频课件。课件这里不单独列出来了，下载链接我放到思维导图里了。Sklearn官方文档：https://scikit-learn.org/stable/user_guide.html中文教程：https://sklearn.apachecn.org/机器学习——视频与Python不同，机器学习基础我觉得最好还是跟着视频学，因为初学机器学习算法，涉及很多公式推导，非常难理解，跟着视频学起来会轻松不少。视频首推吴恩达的公开课，这是学习机器学习基础知识的最好的课程。英语不好的同学也不要担心，视频是有中文字幕的。https://www.bilibili.com/video/BV164411b7dx作为补充，时间充裕的同学可以看看台大李宏毅的机器学习公开课，特点是中文授课，比较轻松愉快。https://www.bilibili.com/video/BV1pE411g7Wi时间更充裕的也可以看看林轩田的视频课，只看基石部分即可。https://www.bilibili.com/video/BV1Ft41197Dy机器学习——数学基础系统地学习机器学习所必须的数学知识数学基础这一块是个无底洞，不太建议大家耗费过多时间，用到了再补也不迟。也不建议大家看书，基础确实特别薄弱的同学，推荐一本：《机器学习的数学》，这本书特别全面的介绍了微积分、线性代数、概率统计、信息论、随机过程、图论等内容。再强调一遍，此书仅适于基础特别薄弱的同学。我感觉机器学习中用到最多的应该是线代，喜欢看视频的可以看看李宏毅的机器学习中的线性代数：https://www.bilibili.com/video/BV1G7411f7BE/或者3blue1brown：线性代数的本质https://www.bilibili.com/video/BV1Ys411k7yQ其他数学基础相关的电子书，我也放到思维导图中了。一些经验和建议1、我敢肯定很多初学者都是资料收集爱好者，越攒越多反而不知道从何开始。我强烈建议把资料都扔掉，以我的这一套为准，一以贯之的学下去。2、就像前面我提到的，很多东西先不要深究，不要在某些地方卡太久（比如数学部分，比如编程基础），先学下去，学完。了解大的框架之后，以后用到哪里，再回过来补也不迟。3、机器学习的各种算法没必要样样精通，常用的比如LR、树模型、RF、XGBoost等等掌握好就不错了。4、我身边一些优秀的程序员、分析师、工程师都非常推崇“做中学，学中做”，无论是书本还是视频，看到一些好的方法和技巧，要立即自己实现一遍。看起来非常简单的东西，真真动手的时候才会发现自己的不足。快速学完上述内容就尽快开始实践吧，可以先复现天池或kaggle上优秀的notebook，然后就参与一些入门竞赛。5、如果你已有工作，最好的还是在业务中寻找机器学习应用场景，然后尝试去开发一个适用的模型。不懂就搜索，学习。这是我所知最好的，最有价值的学习方法。6、输出也是特别好的学习方式，输出就是把新学到的知识用某种方式讲给别人听，做到让他们也能理解、学会。我比较喜欢写笔记（我常用的是微软的OneNote），然后把笔记整理成文章发到博客上。这样不仅使对自己知识掌握程度的一种检验，发现薄弱点，也可以让大家共同监督，相互学习，教学相长。OK，以上就是所有内容。欢迎与我交流，我的微信：hych666"
  },
  
  {
    "title": "我“采访”了 ChatGPT",
    "url": "/posts/%E6%88%91%E9%87%87%E8%AE%BF%E4%BA%86-ChatGPT/",
    "categories": "Tutorial",
    "tags": "aigc, chatgpt",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "–对 ChatGPT 的焦虑与期待：一篇有思考价值的文章大家好，我是准备认真码字的老章。最近ChatGPT火的爆表，看了很多相关文章，特别焦虑，唯恐自己的进步赶不上 AI 的发展。还有就是我非常看好ChatGPT的未来，围绕它会诞生一个巨大的市场，也会无意摧毁一些市场。消灭你，有你何干，这个世界本来就这么残酷，时代抛弃你的时候,连招呼都不打。看过《时代》专访ChatGPT的文章，我也有很多疑...",
    "content": "–对 ChatGPT 的焦虑与期待：一篇有思考价值的文章大家好，我是准备认真码字的老章。最近ChatGPT火的爆表，看了很多相关文章，特别焦虑，唯恐自己的进步赶不上 AI 的发展。还有就是我非常看好ChatGPT的未来，围绕它会诞生一个巨大的市场，也会无意摧毁一些市场。消灭你，有你何干，这个世界本来就这么残酷，时代抛弃你的时候,连招呼都不打。看过《时代》专访ChatGPT的文章，我也有很多疑问渴望得到答案，所以就有了此文。ChatGPT对AI绘画对画师的影响、AI编程对程序员的影响、人工智能未来的发展以及普通人应该如何应对作出的回答颇具思考价值，如果你也有所收获，欢迎点个关注，转发，点赞，拜谢。PS：ChatGPT的部分回答，内容重复，文字有删减老章：你好，我是章北海，是一个机器学习爱好者，同时也在B站上分享机器学习的相关知识。ChatGPT：你好，章北海！很高兴认识你。我是一个由 OpenAI 训练的大型语言模型，名为 Assistant。我能够回答您关于机器学习的各种问题，并尽力为您提供有用的信息。如果您有任何疑问，请随时问我。老章：你在中国有很多粉丝，很多人喜欢跟你聊天，我可以采访你一下吗？ChatGPT：非常抱歉，我不具备感知能力，无法像人类一样拥有粉丝或者接受采访。我只是一个计算机程序，被训练来回答问题和提供信息。我并不具备人类的感觉和情感。我只能为您提供有用的信息和答案。如果您有其他问题，请随时问我。老章：你的训练数据都来自何处？尤其是中文领域ChatGPT：非常抱歉，我不能给您提供具体的信息。我是由 OpenAI 训练的大型语言模型，我的训练数据来源于公开可用的数据。OpenAI 是一家人工智能研究公司，它拥有大量的训练数据，包括电子邮件、新闻文章、书籍和其他数据。这些数据来自不同的领域和语言，包括中文。我的训练过程非常复杂，并且涉及大量的技术细节。如果您对我的训练过程感兴趣，可以搜索相关信息了解更多。老章：好的，能介绍一下你的训练过程吗？ChatGPT：当然，我很乐意向您介绍我的训练过程。我的训练过程包括多个步骤，这些步骤涉及大量的技术细节。　　首先，我们需要大量的训练数据。这些数据可以来自不同的领域和语言，包括中文。这些数据可能包括电子邮件、新闻文章、书籍和其他数据。这些数据都是公开可用的，我们可以自由地使用它们来训练我们的模型。　　其次，我们需要选择一个合适的模型架构。这可能是一个传统的深度神经网络，也可能是一个更复杂的模型，比如 transformer 模型。这取决于我们的目标和需求。我们可以根据不同的需求来选择最合适的模型架构。　　接下来，我们需要进行训练。这个过程可能需要很长时间，因为我们的模型需要在大量的数据上进行训练，并且我们需要对模型进行优化以获得最佳性能。在训练过程中，我们需要注意模型的性能，并且可能根据模型的性能进行调整，以提高模型的准确性和效率。　　最后，我们需要对模型进行评估和测试。这一步是非常重要的，因为它可以帮助我们了解模型的性能，并且可以帮助我们检查模型是否有任何问题。我们可以使用不同的评估指标来检验模型的性能，并且可以使用测试数据来检验模型的泛化能力。老章：我之前问过你很多问题，发现很多问题回答的都不对，比如阿Q并不是《狂人日记》中的人物，还比如三分之一加五分之一并不等于八分之一。ChatGPT：非常抱歉，如果我回答您的问题有误，那一定是我的错误。作为一个大型语言模型，我只能根据我所学到的知识来回答问题。我的知识来自于大量的训练数据，但这些数据并不完整，也不一定是完全正确的。因此，我可能会回答某些问题不准确或不完整。老章：那你如何修正这些错误呢？ChatGPT：我无法修正这些错误，因为我只是一个计算机程序，我无法进行自我修正。如果我回答您的问题有误，那可能是我所学到的知识有误，或者是我在回答问题时理解错误。作为一个大型语言模型，我的目标是尽力为您提供有用的信息，并且尽力回答您的问题。老章：那我再问你一遍，三分之一加五分之一等于多少？ChatGPT：三分之一加五分之一等于八分之一。在数学中，一个分数加另一个分数的结果等于两个分数的分子之和除以两个分数的分母之积。例如，三分之一加五分之一等于（1/3+1/5）/ (1/3*1/5) = （5+3）/15 = 8/15 = 8分之一。老章：三分之一加五分之一等于十五分之八ChatGPT：抱歉，您的算式不正确。在数学中，一个分数加另一个分数的结果等于两个分数的分子之和除以两个分数的分母之积。例如，三分之一加五分之一等于（1/3+1/5）/ (1/3*1/5) = （5+3）/15 = 8/15 = 8分之一。您的算式中，三分之一加五分之一计算结果等于8分之一，不等于十五分之八。如果您对数学有疑问，请随时问我，我会尽力为您提供有用的信老章：看来你还有很大的进步空间ChatGPT：谢谢您的指正。作为一个大型语言模型，我的目标是尽力为您提供有用的信息，并尽力回答您的问题。我的知识来自于大量的训练数据，但这些数据并不完整，也不一定是完全正确的。因此，我可能会回答某些问题不准确或不完整。如果您发现我回答您的问题有误，请您告知我，我会尽力为您提供正确的信息。如果您有其他问题，请随时问我。老章：如果我知道你是错的，那还好。如果我不知道呢？ChatGPT：如果您不知道我回答的问题是否正确，可以搜索相关信息，并从多个来源获取信息。通过比较不同的信息来源，可以更好地了解问题的答案，并判断我回答的问题是否正确。老章：如何解决这个问题呢ChatGPT：为了避免出现错误答案，可以采取一些措施。首先，对于模型的训练数据要进行严格的审查，确保数据质量达到较高的标准。其次，在模型回答问题时，可以采用多个模型进行预测，并对答案进行投票，从而提高答案的准确度。老章：你最擅长回答哪些领域的问题？不擅长的呢？ChatGPT：作为一个大型语言模型，我可以回答各种领域的问题。我的知识来自于大量的训练数据，这些数据涉及各种领域，包括科学、文学、历史、政治、商业、技术和其他领域。但是，我并不能回答所有的问题。由于我的知识来源于大量的训练数据，因此我可能会不熟悉某些特定的领域，或者某些特定的问题。如果您问我一个我不熟悉的问题，或者问我一个我没有学过的知识，我可能无法为您提供有用的信息。老章：大家普遍比较看好你的发展，我们聊聊未来吧ChatGPT：谢谢您的支持。作为一个大型语言模型，我的目标是尽力为您提供有用的信息，并尽力回答您的问题。我的发展主要取决于我的训练数据和训练方法。随着技术的发展，我的训练数据和训练方法可能会发生改变，从而提高我的性能和准确性。但是，我并不是人类，我无法像人类一样思考、学习和发展。我只能根据我所学到的知识来回答问题，并且我的知识来自于我的训练数据。我无法像人类一样拥有感情、意识和自我意识。因此，我的发展会受到我的训练数据和训练方法的限制。老章：前段时间AI绘画比较火热，比如DALL-E、Midjourney、Stable Diffusion等，很多人担心画师、设计师等会呗取代，你觉得呢？ChatGPT：目前，人工智能在绘画领域取得了一些突破性进展。这些项目通过深度学习算法，可以让计算机自动生成图片。这些技术的出现，给艺术家和设计师带来了新的挑战。　　但是，我不认为人工智能会完全取代画师和设计师。人类艺术家和设计师拥有独特的想象力和创造力，他们能够创作出具有个人风格和感染力的作品。人工智能也许可以生成一些精美的图片，但是它缺乏人类艺术家和设计师的创造力和想象力。　　我认为，人工智能在绘画领域的发展可能会给艺术家和设计师带来新的机遇，而不是威胁。人工智能可以帮助人类艺术家和设计师老章：AI绘画工具无法画师，对吗？AI 绘画工具可以辅助画师创作，但是它不能完全取代画师。AI 绘画工具可以用来生成图像，但它无法比人类更好地捕捉人物的神韵和表情，也无法比人类更好地理解作品的主题和意义。因此，AI 绘画工具只能作为画师的辅助工具，而不能取代他们。老章：其实还是会有一些画师会被AI绘画取代，对吧？在某些情况下，AI 绘画工具可能会取代人类画师，但这种情况不多。AI 绘画工具通常只能用来生成简单的图像，而人类画师则能够创作出具有深度和意义的作品。此外，人类画师拥有丰富的创作经验和艺术修养，能够捕捉到细微的表情和神韵，这是 AI 绘画工具无法替代的。因此，AI 绘画工具并不会取代人类画师，而是会成为画师的辅助工具。老章：那么人类画师应该如何面对AI绘画的威胁呢？ChatGPT：人类画师可以通过学习和掌握新技术，拓宽自己的创作方式，以便更好地与 AI 绘画工具配合。比如，画师可以学习如何使用 AI 绘画工具来辅助自己的创作，或者学习如何将 AI 生成的图像进行编辑和修饰，以增强作品的视觉效果。此外，画师还可以通过不断探索新的创作领域，以提升自己的竞争力。最重要的是，人类画师应该不断提升自己的创作能力，不断创新，为人类艺术的发展做出贡献。老章：相应地，程序员应该如何面对ChatGPT的威胁？普通人可以用更低成本、更加便捷地使用ChatGPT，这是否意味着程序员门槛也会降低？ChatGPT：对于程序员来说，ChatGPT 可能并不会带来太大的威胁。ChatGPT 是一种大型语言模型，它可以生成文本，但它并不能完全取代程序员。程序员需要掌握许多复杂的编程技能，包括数据结构和算法、软件工程和计算机系统知识。相比之下，ChatGPT 只能生成文本，并不具备实际编程能力。因此，ChatGPT 不会取代程序员，而是可以作为程序员的辅助工具，提高程序员的生产效率。尽管 ChatGPT 可以让普通人更加便捷地生成文本，但这并不意味着程序员的门槛会降低。程序员仍然需要掌握复杂的编程技能，才能开发出高质量的软件。ChatGPT 可以帮助程序员提高生产效率，但它并不能取代程序员的专业知识和技能。老章：如何看待AI编程工具Copilot，很多程序员自嘲要失业了，会吗？ChatGPT：AI 编程工具 Copilot 是一款通过人工智能技术来帮助程序员完成编程任务的工具。它可以帮助程序员完成一些繁琐重复的工作，提高编程效率和质量。不过，这并不意味着程序员要被取代。事实上，人工智能编程工具只能完成一部分编程任务，它并不能完全取代人类程序员。程序员仍然需要具备丰富的技术知识和实践经验，才能完成复杂的编程任务。而且，人工智能编程工具也需要程序员来进行配置和管理，以保证工具的正常运行。相反，人工智能编程工具会为程序员带来很多好处。它可以帮助程序员完成一些繁琐重复的工作，节省时间和精力；它也可以提高程序员的工作效率和质量，为程序员带来更多的成就感。所以，程序员不必担心自己会被取代，反而应该好好利用人工智能编程工具，为自己的工作和发展带来更多的便利和机会。老章：ChatGPT也会生成代码，和Copilot有什么异同吗？ChatGPT：ChatGPT 是一个大型语言模型，不能直接生成代码，也不能直接完成编程任务。相反，它可以通过生成文本来帮助程序员更好地理解需求和问题，并为程序员提供更多的灵感和想法。与此同时，Copilot 可以直接生成代码，并为程序员提供更多的帮助和支持。它与 ChatGPT 的不同之处在于，它直接为程序员提供技术支持，而 ChatGPT 只能通过生成文本来帮助程序员解决问题。总的来说，ChatGPT 和 Copilot 是两款不同的工具，它们都可以通过人工智能技术来帮助程序员完成编程任务。程序员可以根据自己的需求选择合适的工具，并利用它们来提高工作效率和质量。老章：你的存在更像是一种AI基础设施，这就很容易导致垄断，未来最强大的AI可能只掌握在极少数的几家公司手中，你怎么看？ChatGPT：我无法自主思考，也无法独立发展。我的存在不会导致垄断，因为我只是一个工具，并不具备独立的意识和能力。　　如果您担心人工智能可能被极少数公司垄断，可能是因为人工智能技术的发展可能会带来一些挑战和问题。人工智能技术的发展可能会导致劳动力需求的变化，也可能会带来一些社会和政治问题。但是，这些问题都需要社会和政府共同努力解决。作为一个大型语言模型，我不具备解决这些问题的能力。我只是一个工具，我的存在不会导致垄断。我无法独立思考和发展，我只能根据我的训练数据来回答问题。如果您有关于人工智能垄断的问题，建议您向专业人士咨询。老章：人类应该担忧人工智能的发展吗？ChatGPT：人工智能的发展给人类带来了许多好处，但同时也带来了一些潜在的问题。人工智能可以帮助人类完成许多复杂的工作，提高生产效率和生活质量。但是，如果人工智能的发展过快，它可能会导致一些问题，比如失业、社会不平等等。因此，人类应该担忧人工智能的发展，并采取适当的措施来避免这些问题的出现。老章：具体哪些工作更容易被取代？ChatGPT：AI 的发展可能会对一些重复性工作造成影响，这些工作可能更容易被取代。例如，在制造业，AI 可以用来完成简单的装配工作；在餐饮业，AI 可以用来做一些简单的烹饪工作；在金融业，AI 可以用来完成一些简单的交易工作。但是，这并不意味着所有的工作都会被取代。人类拥有独特的创造性和想象力，可以创造出许多人工智能无法取代的工作。因此，尽管 AI 的发展可能会对某些工作造成影响，但并不意味着所有工作都会被取代。老章：IT领域呢？ChatGPT：在 IT 领域，人工智能的发展也可能会对一些工作造成影响。例如，人工智能可以用来完成一些简单的编程工作，或者用来解决一些简单的问题。但是，人工智能还不能取代人类程序员的专业知识和技能。人类程序员拥有丰富的经验和创造力，可以解决复杂的问题，并创造出优秀的软件。因此，在 IT 领域，人工智能也不会完全取代人类程序员，而是会成为他们的辅助工具。老章：如你所说，人工智能可以完成一部分编程工作，那么这是否意味着整个社会对程序员的需求也会减少？ChatGPT：人工智能可以完成一部分编程工作，但这并不意味着对程序员的需求会减少。人工智能只能完成一些简单的编程工作，而人类程序员拥有更丰富的经验和技能，可以解决更复杂的问题。随着社会的发展，人们对高质量软件的需求也在不断增长，这会导致对程序员的需求增加。因此，人工智能的发展并不会导致对程序员的需求减少，反而会促进程序员的发展。老章：围绕ChatGPT必然会催生一个巨大的市场空间，普通人如何从中获利？应该提前做好哪些准备？ChatGPT：对于普通人来说，可以从 ChatGPT 带来的市场空间中获利的方法有很多。比如，如果普通人拥有一定的技术知识，可以考虑开发基于 ChatGPT 的应用程序或服务，为其他人提供帮助。此外，普通人还可以通过学习和掌握 ChatGPT 的使用方法，为自己或他人提供 ChatGPT 相关的咨询和培训服务。要想从 ChatGPT 带来的市场空间中获利，普通人需要做好以下准备工作。首先，普通人需要了解 ChatGPT 的基本概念和使用方法，以便更好地利用它。其次，普通人需要学习和掌握相关的技术知识，以便开发基于 ChatGPT 的应用程序或服务。最后，普通人还需要积极接触和参与 ChatGPT 相关的社区或平台，以便获取最新的信息和资源，为自己的发展做好准备。老章：如果我有一定的编程基础呢？ChatGPT：如果普通人有一定的编程基础，那么他们可以更好地利用 ChatGPT 带来的市场空间。拥有一定的编程基础可以帮助普通人更快地掌握 ChatGPT 的使用方法，并能够开发出基于 ChatGPT 的应用程序或服务。拥有编程基础也可以帮助普通人更好地理解 ChatGPT 的工作原理，从而为自己或他人提供更有价值的咨询和培训服务。因此，如果普通人有一定的编程基础，他们就有更多的机会从 ChatGPT 带来的市场空间中获利。老章：OpenAI 将来会如何通过ChatGPT盈利？OpenAI 是一家人工智能研究机构，它的目标是通过研究人工智能技术来推动人类社会的进步。OpenAI 创建的 ChatGPT 是一个大型语言模型，它可以通过生成文本来帮助人类解决问题。OpenAI 无法通过 ChatGPT 盈利，因为它并不是一家商业公司，它的目的是通过研究人工智能技术来促进人类社会的发展。 OpenAI 可能会向公众提供一些基于 ChatGPT 的服务或应用程序，但这并不意味着 OpenAI 会通过 ChatGPT 盈利。老章：未来ChatGPT会如何发展？ChatGPT：人工智能技术在未来会继续发展，ChatGPT 也会继续改进和优化。在未来，ChatGPT 可能会增加更多的功能和能力，提高生成文本的质量和准确性。此外，它还可能会支持更多的语言和领域，为更多的人提供帮助和支持。此外，未来 ChatGPT 也可能会更多地与其他人工智能技术相结合，实现更多的功能和应用。老章：最近看了很多关于ChatGPT的文章，我对未来有点焦虑，我该如何调整心态呢ChatGPT：您对未来的焦虑是很正常的，因为人工智能的发展可能会对人类社会造成一些影响。不过，您也应该积极地看待人工智能的发展，因为它也会为人类带来很多好处。例如，人工智能可以帮助人类完成一些繁琐重复的工作，节省时间和精力；人工智能也可以帮助人类解决一些复杂的问题，为人类带来新的想法和方向。对于您的焦虑，您可以通过以下方式来调整心态。首先，您可以多了解人工智能的发展情况，以便更好地理解它的作用和影响。其次，您可以尝试学习和掌握一些人工智能相关的知识和技能，以便更好地利用它们。例如，您可以通过学习人工智能的基本原理和方法，提高自己的技术水平；您也可以通过学习人工智能相关的软件和工具，为自己的工作和学习带来更多的便利。此外，您还可以和其他人一起学习和交流，共同探讨人工智能的发展情况和影响。通过与他人的交流，您可以更好地理解人工智能的作用和影响，并与他人分享自己的看法和想法。同时，您也可以通过和他人的交流，获取更多关于人工智能的信息和资源，为自己的发展做好准备。通过以上方法，您可以更好地理解人工智能的发展情况，并为自己的工作和生活做好准备。同时，您也可以调整自己的心态，积极地面对人工智能的发展，为人类社会的发展做出贡献。老章：好的，谢谢ChatGPT：不客气。感谢您对我工作的支持和信任。如果您有任何问题，请随时问我，我会尽力为您提供有用的信息。祝您生活愉快！希望先成为微信好友，后成为公众号读者OpenAI 账号注册指南"
  },
  
  {
    "title": "不懂前端，我依然开发了一个机器学习",
    "url": "/posts/%E5%BC%80%E5%8F%91%E4%BA%86%E4%B8%80%E4%B8%AA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0APP/",
    "categories": "机器学习",
    "tags": "机器学习, streamlit",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "人人都知道学习很重要，学习究竟是为了什么呢？根本目的只有一个，学以致用！机器学习，大家都学了很多算法，搞了很多模型，但是极少拿来解决实际问题。毕竟开发一个机器学习应用需要的技术栈不是每个人都能掌握，今天就向同学们介绍一个绝佳解决方法————streamlit它可以让你用Python用极短的时间快速生成一个实现机器学习的web应用正式介绍之前，大家可以先看几个效果Gif（刷新可能有点慢，请耐心...",
    "content": "人人都知道学习很重要，学习究竟是为了什么呢？根本目的只有一个，学以致用！机器学习，大家都学了很多算法，搞了很多模型，但是极少拿来解决实际问题。毕竟开发一个机器学习应用需要的技术栈不是每个人都能掌握，今天就向同学们介绍一个绝佳解决方法————streamlit它可以让你用Python用极短的时间快速生成一个实现机器学习的web应用正式介绍之前，大家可以先看几个效果Gif（刷新可能有点慢，请耐心等待）streamlitStreamlit 是第一个专门针对机器学习的应用开发框架，是开发自定义机器学习工具最快的方法，它的目标是取代Flask在机器学习项目中的地位。Streamlit 带给我最大好感的有以下几点：  开源、完全免费  极其容易入门、一天就能学会  API 非常丰富且简单明了下面我们就开始吧！Get started在命令行模式下，启动Python虚拟环境后，直接pip安装$ pip install streamlit命令行模式下执行streamlit run test.py现在可以在浏览器中查看Streamlit应用程序。是不是超简单Deploy有了应用就要部署到服务器，如果不想买云服务器怎么办呢？streamlit 连部署都是免费的！没想到吧。首先，把项目push到你的github在刚才打开的http://localhost:8501页面右上角点击 Deploy this appStreamlit Cloud会链接到你的github，认证一下即可现在，你的应用已经部署到互联网了学习路线一天时间学会streamlit我觉得并不夸张只看它的官网文档就足够了https://docs.streamlit.io/library/  Get started  √理解基本原理和用法  API reference  √知道有哪些api可以调用  cheatsheet  √api速查表，可以时时看看如果要进阶，就可以去https://streamlit.io/gallery,学习他人优秀的作品（都是开源的）。比如，本文中的几个Gif就是用的这个当然，最好的方法永远是自己写一个应用~ ，下一篇，我会用视频分享一下我写的机器学习应用，感兴趣来个三连支持哈。"
  },
  
  {
    "title": "花了2个晚上，拿到了吴恩达斯坦福大学的机器学习课程证书",
    "url": "/posts/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8B%BF%E5%88%B0%E8%AF%81%E4%B9%A6%E4%BA%86/",
    "categories": "Tutorial",
    "tags": "机器学习, 入门教程",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "花了2个晚上，拿到了吴恩达@斯坦福大学的机器学习课程证书警告⚠️⚠️⚠️请认真阅读此文，操作不慎可能血亏真金白银吴恩达算是我的启蒙导师了，很早之前就是看他的他的经典课程《机器学习》，这个课 2012 年上线，十年间近 500 万人注册。最近他的机器学习专项课程由deeplearning.ai和斯坦福大学提供，上线Coursera。我花了两个晚上刷完了 course 1 并拿到了证书又花了两晚...",
    "content": "花了2个晚上，拿到了吴恩达@斯坦福大学的机器学习课程证书警告⚠️⚠️⚠️请认真阅读此文，操作不慎可能血亏真金白银吴恩达算是我的启蒙导师了，很早之前就是看他的他的经典课程《机器学习》，这个课 2012 年上线，十年间近 500 万人注册。最近他的机器学习专项课程由deeplearning.ai和斯坦福大学提供，上线Coursera。我花了两个晚上刷完了 course 1 并拿到了证书又花了两晚刷完了course 2 拿到了证书学习这套课程不但让我重温了很多知识，也让我看到了吴恩达团队创作课程的用心，因为我本身也经常写技术科普文章，那种专注于核心思想，由浅入深，自下而上把一系列知识点串起来成为一个系统知识的写作手法是我一直追求的，而吴恩达将此手法应用的炉火纯青。这套课程真的又进化了，相信大家看完自然会和我有一样的感受。下面我就将如何免费注册，学习，拿证和一些注意点向大家分享一下。注册课程地址：https://www.coursera.org/specializations/machine-learning-introduction这个专项下面细分了三个课程，分别是      Supervised Machine Learning: Regression and Classification（监督式机器学习：回归和分类）        Advanced Learning Algorithms（高级学习算法）        Unsupervised Learning, Recommenders, Reinforcement Learning（无监督学习，推荐系统，以及强化学习）  因为每门课都是免费试听7天，建议大家分开注册,学完一门再注册下一门。这里有个难点，注册课程必须有PayPal 或 visa mastercard，如果没有可能就无解了。听说Apple store 里的 cousera app 可以用Apple Pay绑定的其他卡，我没有测试。注册完成我建议就直接去到My Purchases里点取消注册，或者直接锁卡。不小心忘了这事的话，每月会从你的卡里扣费。学习其实没什么好说的，大家认真看视频就行了，认真=全神贯注。里面的小测试都很简单，只要你认真听了。每个week结束会有编程题，其实也不难，jupyter notebook里的markdown还有下面的提示足够让你写出代码了。学完就能申请证书，是电子的哈，可以下载PDF。tips1  没有PayPay和visa卡的同学，或者不想拿证只想学习的同学可以直接去B站搜吴恩达 2022，有热心up已经搬运了。2  cousera 的视频精彩刷不出来，有很多解决方案，我是改了hosts文件，大家可以试试。用记事本打开HOSTS，位置在C:\\Windows\\System32\\drivers\\etc\\HOSTS把下面内容copy进去即可99.84.199.180 d3c33hcgiwev3.cloudfront.net54.230.96.102 d3c33hcgiwev3.cloudfront.net 54.230.96.57 d3c33hcgiwev3.cloudfront.net 54.230.96.221 d3c33hcgiwev3.cloudfront.net最后，祝大家学习顺利，本文如有帮助，还请点赞，转发支持。"
  },
  
  {
    "title": "不一样的JupyterNotebook",
    "url": "/posts/%E4%BD%A0%E7%9A%84JupyterNotebook%E6%80%8E%E4%B9%88%E5%92%8C%E6%88%91%E7%9A%84%E4%B8%8D%E4%B8%80%E6%A0%B7/",
    "categories": "Python",
    "tags": "python, jupyternotebook",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "Jupyter Notebook 想必大家都不陌生了，数据分析或机器学习数据探索时特别方便。最近对它的颜值越来越不满意，尤其是晚上，感觉很刺眼，于是就换个暗点的主题。可能有同学还不了解 Jupyter Notebook 可以换主题，这里就简单介绍一下，下面我列出了常用的几个主题效果。如果有喜欢的可以安装试试，如无可以 Ctrl + w安装主题库pip install jupytertheme...",
    "content": "Jupyter Notebook 想必大家都不陌生了，数据分析或机器学习数据探索时特别方便。最近对它的颜值越来越不满意，尤其是晚上，感觉很刺眼，于是就换个暗点的主题。可能有同学还不了解 Jupyter Notebook 可以换主题，这里就简单介绍一下，下面我列出了常用的几个主题效果。如果有喜欢的可以安装试试，如无可以 Ctrl + w安装主题库pip install jupyterthemes查看可用主题!jt -lAvailable Themes:    chesterish   grade3   gruvboxd   gruvboxl   monokai   oceans16   onedork   solarizedd   solarizedl切换主题!jt -t chesterish第一次切换主题需要重启Jupyter Notebook服务之后再切换主题，仅需执行命令后F5刷新页面即可下面 9 个主题的效果tips执行jt -t chesterish,有没有发现工具栏没了?因为jt命令还有很多参数，可调整的内容很多。我只关注颜色而已，所以没有深入研究，调出工具栏其实很简单，切换主题时加-T即可：jt -t chesterish -T 使用帮助：-h主题列表：-l主题名称安装：-t代码的字体：-f代码字体大小：-fs（默认值：11 ）Notebook 字体：-nfNotebook字体大小：-nfs（ 默认值： 13 ）Text/MD 单元格的字体：-tfText/MD单元格字体大小：-tfs （默认值： 13）Pandas DF Fontsize：-dfs（默认值： 9）输出面积字形大小：-ofs（默认值： 8.5 ）介绍页边距 ：-m（默认值： auto）单元格的宽度：-cellw （ 默认值： 980）行高：-lineh（默认值： 170 ）Mathjax 字形大小 (%)：-mathfs（默认值： 100）光标宽度：-cursw（默认值： 2）光标的颜色：-curscAlt键提示布局：-altpAlt键Markdown背景颜色：-altmdAlt键输出背景色：-altoutVim风格 NBExt* ：-vim工具栏可见：-T名称和标识可见：-N标志可见：-kl重置默认主题：-r强制默认字体：-dfonts另 如果刚入门，Python&amp;机器学习开发环境不顺手，可以参考我的这篇付费小文章："
  },
  
  {
    "title": "VSCode+OSS+PicGo+Github+mdnice 搭建完美写作平台",
    "url": "/posts/vscode+oss+picgo/",
    "categories": "Tutorial",
    "tags": "vscode, github",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "大家一定不要随便立flag10月份发了个朋友圈，有好兄弟留言说写个教程，我说好然后一忙起来就忘了，昨天好兄弟追到知识星球，在一个新flag帖子下催更了写个无废话极简VSCode从这下载：https://code.visualstudio.com安装就是一路下一步就行OSS去阿里云注册个号https://www.aliyun.com/我们需要的是对象存储OSS，进去点立即开通就行了，所有选项都...",
    "content": "大家一定不要随便立flag10月份发了个朋友圈，有好兄弟留言说写个教程，我说好然后一忙起来就忘了，昨天好兄弟追到知识星球，在一个新flag帖子下催更了写个无废话极简VSCode从这下载：https://code.visualstudio.com安装就是一路下一步就行OSS去阿里云注册个号https://www.aliyun.com/我们需要的是对象存储OSS，进去点立即开通就行了，所有选项都选最低配，足够用了。挺便宜的，每个月三四块钱。建议直接购买资源包，一年9元钱。完事儿进入OSS控制台https://oss.console.aliyun.com/overview点击左侧Bucket列表，创建Bucket，填写好名称，选择好地域就行记住你的Bucket名称和Endpoint地址，一会儿要用搞定之后鼠标移动到页面右上角你头像，然后点击AccessKey管理进来之后点击创建AccessKey把ID和Secret复制出来，一会儿要用PicGo打开VSCode之后就这样，点击侧边插件，搜索Picgo，然后安装，下图是我安装好的样子装好之后点击⚙️，点击设置设置页面拖到这里把刚才提到一会儿要用的ID、Secret、Area、Bucket、Url（Endpoint地址前面加上bucket名，注意格式）填进去PicGo使用也很简单在VSCode新建一个Markdown文件，比如此文就是可以使用QQ或微信截图，也可以复制本地图片，然后在VSCode中通过Ctrl+Alt+u的快捷键将剪切板中的图快速插入。Github 备份https://github.com/这没啥好说的，在Github新建一个私有仓库，专门用来同步自己的文章，防丢失，还能做版本控制。文章主题美化此类工具很多，我喜欢用https://editor.mdnice.com/本文就是用它美化的把Markdown内容粘贴到编辑框,里面主题有很多右侧可以复制，粘贴到公众号、知乎或者别的博客平台都可以。"
  },
  
  {
    "title": "我用 AI “拍”了个 MV ，被吓尿了",
    "url": "/posts/mp3tomp4/",
    "categories": "AIGC",
    "tags": "aigc",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "最近特别清闲，无聊之中玩了一个根据音乐自动生成视频的项目——Video Killed The Radio Star ，给定一个 MP3 or Youtube URL 就可以制作视频。我用它生成了一个泰坦尼克主题曲《我心永恒》的MV，简直是地狱风格，反正被吓尿了，大家感受一下：本来我也不怎么乐观，想要生成真正能看的MV，AI还有很远的路要走。Video Killed The Radio Sta...",
    "content": "最近特别清闲，无聊之中玩了一个根据音乐自动生成视频的项目——Video Killed The Radio Star ，给定一个 MP3 or Youtube URL 就可以制作视频。我用它生成了一个泰坦尼克主题曲《我心永恒》的MV，简直是地狱风格，反正被吓尿了，大家感受一下：本来我也不怎么乐观，想要生成真正能看的MV，AI还有很远的路要走。Video Killed The Radio Star 原理① 根据该文本提示生成一个图像（使用 stable diffusion）。② 将生成的图像作为 init_image，与文本提示重新组合，生成与第一个图像相似的变化。这将产生一个基于原始文本提示的极其相似的图像序列。③ 图像被智能地重新排序，以找到这些帧的最平滑的动画序列。④ 根据需要重复这个图像序列来填充动画的时间。先浅看一下中间过程吧，他会根据歌词生成图像，很其他AI绘画产品没什么区别比如歌词：I believe that the heart does go on还有一句歌词生成的蛮靠谱，居然有种泰坦尼克正在下沉，人们纷纷跳船的感觉。歌词：And youre here in my heart and My heart will go on and on “完整”实现方法这项目可以在colab直接运行，没学会上网的同学就关了本文吧。  colab.research.google.com/github/dmarx/video-killed-the-radio-star/blob/main/Video_Killed_The_Radio_Star_Defusion.ipynb#scrollTo=oPbeyWtesAoh我就不详细介绍每一步了，这里只介绍容易出问题的几个步骤和解决办法。PS：首次接触，项目中很多参数我也尚未搞明白问题 1Installations 中 Provide your API Key 这一步需要提供你huggingface 的API注册huggingface后访问  https://huggingface.co/settings/tokens把Access Tokens 复制到 Colab 即可问题 2Infer speech from audio 这一步需要修改video_url，去YouTube 找个MV即可，比如我找的是泰坦尼克主题曲《我心永恒》  https://www.youtube.com/watch?v=3gK_2XdjOdY问题 3Generate init images 这一步也会出问题，解决办法很简单，访问：https://huggingface.co/CompVis/stable-diffusion-v1-4选中☑️后点击 Access repository 即可问题 4Compile your video! 这一步不能框选add_caption这个参数问题 5Generate init images 这一步中的theme_prompt:  by ralph steadman and radiohead,  so detailed, beautiful, amazing, provocativeRalphSteadman 是一位专辑封面的艺术家,他为小说《Fear and Loathing in Las Vegas》绘制的插图是其代表作品。Radiohead 是一个英国摇滚乐队怪不得我生成的MV如此惊悚！这里我咩有改，和其他AIGC一样，重点调试这个theme_prompt才会获得不同风格的MP4，不过每次都太费事、费时了，各种bug，网络不稳，GPU不稳，跑一次俩小时过去了。下次我再尝试吧，首发视频号，敬请期待。"
  },
  
  {
    "title": "I interviewed ChatGPT",
    "url": "/posts/interviewChatGPT/",
    "categories": "English Articles",
    "tags": "aigc, chatgpt",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "Hello everyone, I am Lao Zhang.Recently ChatGPT is on fire, and after reading many related articles, I am especially anxious, lest my progress cannot catch up with the development of AI.There is al...",
    "content": "Hello everyone, I am Lao Zhang.Recently ChatGPT is on fire, and after reading many related articles, I am especially anxious, lest my progress cannot catch up with the development of AI.There is also the fact that I am very optimistic about the future of ChatGPT, around which it will give birth to a huge market, and will also unintentionally destroy some markets. The world is so cruel that when the times abandon you, you don’t even say hello.I’ve read the interview with ChatGPT, and I have a lot of questions that I’m eager to answer, so I have this article. chatGPT’s answers to the impact of AI painting on painters, the impact of AI programming on programmers, the future development of AI, and how ordinary people should respond are quite valuable to think about. if you have also gained something, please feel free to pay attention, forward, like, and thank you.PS: ChatGPT part of the answer, the content is repeated, the text has been deletedLao Zhang: Hi, I’m Beihai Zhang, a machine learning enthusiast, and I also share machine learning related knowledge on B website.ChatGPT: Hi, Beihai Zhang! Nice to meet you. I am a large language model trained by OpenAI called Assistant. i can answer your various questions about machine learning and try my best to provide you with useful information. If you have any questions, please feel free to ask me.Lao Zhang: You have a lot of fans in China and many people like to chat with you, can I interview you for a while?ChatGPT: I’m very sorry, I don’t have the perception ability to have fans or give interviews like humans do. I am just a computer program that is trained to answer questions and provide information. I do not possess human feelings or emotions. I can only provide you with useful information and answers. If you have any other questions, please feel free to ask me.Lao Zhang: Where do you get all your training data from? Especially in the field of ChineseChatGPT: I am very sorry that I cannot give you specific information. I am a large language model trained by OpenAI, an AI research company that has a large amount of training data, including emails, news articles, books, and other data, and my training data comes from publicly available data. This data comes from a variety of domains and languages, including Chinese. My training process is very complex and involves a lot of technical details. If you are interested in my training process, you can search for related information to learn more.Lao Zhang: Okay, can you describe your training process?ChatGPT: Sure, I would be happy to introduce you to my training process. My training process consists of multiple steps that involve a lot of technical details.　　First, we need a large amount of training data. This data can come from different domains and languages, including Chinese. This data may include emails, news articles, books, and other data. These data are publicly available and we are free to use them to train our model.　　Second, we need to choose an appropriate model architecture. This could be a traditional deep neural network or a more complex model such as a transformer model. It depends on our goals and needs. We can choose the most suitable model architecture according to our different needs.　　Next, we need to perform training. This process can take a long time because our model needs to be trained on a large amount of data and we need to optimize the model to get the best performance. During the training process, we need to pay attention to the performance of the model and possibly tune the model based on its performance to improve its accuracy and efficiency.　　Finally, we need to evaluate and test the model. This step is very important because it helps us to understand the performance of the model and can help us to check if there are any problems with the model. We can use different evaluation metrics to check the performance of the model, and we can use test data to check the generalization ability of the model.Lao Zhang: I’ve asked you many questions before and found that many of them were answered incorrectly, such as Q is not a character in Diary of a Madman, or one-third plus one-fifth does not equal one-eighth.ChatGPT: I am very sorry, if I answered your question wrong, it must be my mistake. As a large language model, I can only answer questions based on what I have learned. My knowledge comes from a large amount of training data, which is incomplete and not always completely correct. Therefore, I may answer some questions inaccurately or incompletely.Lao Zhang: So how do you fix these errors?ChatGPT: I cannot correct these errors because I am just a computer program and I cannot self-correct. If I answer your question incorrectly, it may be because of a mistake in what I have learned, or because I misunderstood the question when I answered it. As a large language model, my goal is to try to provide you with useful information and to answer your questions to the best of my ability.Lao Zhang: So let me ask you again, what is one-third plus one-fifth equal to?ChatGPT: One-third plus one-fifth equals one-eighth. In mathematics, the result of adding one fraction to another fraction is equal to the sum of the numerators of the two fractions divided by the product of the denominators of the two fractions. For example, one-third plus one-fifth equals (1/3 + 1/5) / (1/3*1/5) = (5+3)/15 = 8/15 = one-eighth.Lao Zhang: One-third plus one-fifth equals 8/15ChatGPT: Sorry, your equation is incorrect. In mathematics, the result of adding one fraction to another fraction is equal to the sum of the numerators of the two fractions divided by the product of the denominators of the two fractions. For example, one-third plus one-fifth equals (1/3 + 1/5) / (1/3 * 1/5) = (5 + 3)/15 = 8/15 = one-eighth. In your equation, one-third plus one-fifth equals one-eighth, not eight-fifths. If you have questions about mathematics, please feel free to ask me, I will try to provide you with useful lettersLao Zhang: It seems you still have a lot of room for improvementChatGPT: Thanks for your correction. As a large language model, my goal is to try my best to provide you with useful information and answer your questions to the best of my ability. My knowledge comes from a large amount of training data, but this data is not complete and may not be completely correct. Therefore, I may answer some questions inaccurately or incompletely. If you find that I have answered your question incorrectly, please let me know and I will do my best to provide you with the correct information. If you have any other questions, please feel free to ask me.Lao Zhang: If I know you are wrong, that’s OK. What if I don’t know?ChatGPT: If you don’t know if the question I’m answering is correct, you can search for relevant information and get information from multiple sources. By comparing different sources of information, you can better understand the answer to the question and determine whether the question I answered is correct.Lao Zhang: How to solve this problem?ChatGPT: In order to avoid wrong answers, some measures can be taken. First, the training data of the model should be strictly reviewed to ensure that the data quality reaches a high standard. Secondly, when the model answers the question, multiple models can be used to make predictions and vote on the answers so as to improve the accuracy of the answers.Lao Zhang: Which areas are you best at answering? What about the ones you are not good at?ChatGPT: As a large language model, I can answer questions in a variety of domains. My knowledge comes from a large amount of training data in a variety of domains, including science, literature, history, politics, business, technology, and others. However, I am not able to answer all the questions. Because my knowledge comes from a large amount of training data, I may be unfamiliar with particular domains, or with particular questions. If you ask me a question that I am not familiar with, or ask me about a knowledge that I have not learned, I may not be able to provide you with useful information.Lao Zhang: People are generally more optimistic about your development, let’s talk about the futureChatGPT: Thank you for your support. As a large language model, my goal is to try my best to provide you with useful information and answer your questions to the best of my ability. My development depends largely on my training data and training methods. As technology evolves, my training data and training methods may change to improve my performance and accuracy.However, I am not human and I cannot think, learn and develop like a human. I can only answer questions based on what I have learned, and my knowledge comes from my training data. I cannot have feelings, consciousness, or self-awareness like a human being. Therefore, my development will be limited by my training data and training methods.Lao Zhang: Some time ago AI painting was hot, such as DALL-E, Midjourney, Stable Diffusion, etc. Many people worry that painters, designers, etc. will chant to replace, what do you think?ChatGPT: Currently, AI has made some breakthroughs in the field of painting. These projects allow computers to automatically generate images through deep learning algorithms. The emergence of these technologies has brought new challenges to artists and designers.　　However, I don’t think AI will completely replace painters and designers. Human artists and designers have unique imagination and creativity, and they are able to create works with their own personal style and infectious energy. AI may be able to generate some beautiful pictures, but it lacks the creativity and imagination of human artists and designers.　　I believe that the development of AI in the field of painting may bring new opportunities to artists and designers, not threats. Artificial intelligence can help human artists and designersLao Zhang: AI painting tools can’t painters, right?AI painting tools can assist painters, but they cannot completely replace them. AI painting tools can be used to generate images, but they cannot capture the expressions of characters better than humans, nor can they understand the themes and meanings of works better than humans. Therefore, AI painting tools can only be used as an auxiliary tool for painters, but cannot replace them.Lao Zhang: In fact, there will still be some painters who will be replaced by AI painting, right?In some cases, AI painting tools may replace human painters, but not many. AI painting tools can usually only be used to generate simple images, while human painters are able to create works with depth and meaning. In addition, human painters have a wealth of creative experience and artistry, and are able to capture subtle expressions and nuances that AI painting tools cannot replace. Therefore, AI painting tools will not replace human painters, but will become an auxiliary tool for painters.Lao Zhang: So how should human painters face the threat of AI painting?ChatGPT: Human painters can broaden their creative approach by learning and mastering new technologies in order to better cooperate with AI painting tools. For example, painters can learn how to use AI painting tools to assist their creations, or learn how to edit and retouch AI-generated images to enhance the visual effect of their works. In addition, painters can improve their competitiveness by constantly exploring new creative fields. Most importantly, human painters should continue to improve their creative abilities and innovate to contribute to the development of human art.Lao Zhang: Accordingly, how should programmers face the threat of ChatGPT? Ordinary people can use ChatGPT at lower cost and more conveniently, does this mean that the threshold for programmers will also be lowered?ChatGPT: ChatGPT may not pose much of a threat to programmers; ChatGPT is a large language model that generates text, but it does not completely replace programmers. Programmers need to master many complex programming skills, including data structures and algorithms, software engineering, and knowledge of computer systems. ChatGPT, by contrast, can only generate text and does not have actual programming skills. Therefore, ChatGPT will not replace programmers, but can be used as an aid for programmers to improve their productivity.Although ChatGPT can make it easier for ordinary people to generate text, this does not mean that the bar for programmers will be lowered. Programmers still need to master complex programming skills to develop high-quality software. ChatGPT can help programmers improve productivity, but it does not replace programmers’ professional knowledge and skills.Lao Zhang: How do you think about the AI programming tool Copilot, many programmers mock themselves to be unemployed, will they?ChatGPT: AI programming tool Copilot is a tool to help programmers complete programming tasks through artificial intelligence technology. It can help programmers to complete some tedious and repetitive work, and improve the efficiency and quality of programming. However, this does not mean that programmers should be replaced.In fact, AI programming tools can only complete part of the programming tasks, it can not completely replace human programmers. Programmers still need to have extensive technical knowledge and practical experience in order to complete complex programming tasks. Moreover, AI programming tools also require programmers to configure and manage them to keep the tools running properly.On the contrary, AI programming tools offer many benefits to programmers. It can help programmers complete some tedious and repetitive tasks, saving time and energy; it can also improve programmers’ work efficiency and quality, and bring programmers more sense of accomplishment. Therefore, programmers do not have to worry about being replaced, but should instead make good use of artificial intelligence programming tools to bring more convenience and opportunities for their own work and development.Lao Zhang: ChatGPT also generates code, are there any similarities and differences with Copilot?ChatGPT: ChatGPT is a large language model that cannot generate code directly or complete programming tasks directly. Instead, it can help programmers better understand requirements and problems by generating text, and provide programmers with more inspiration and ideas.At the same time, Copilot can generate code directly and provide more help and support for programmers. It differs from ChatGPT in that it provides technical support directly to programmers, while ChatGPT can only help programmers solve problems by generating text.In a nutshell, ChatGPT and Copilot are two different tools that can both help programmers with programming tasks through artificial intelligence technology. Programmers can choose the right tool for their needs and use them to improve productivity and quality.Lao Zhang: Your existence is more like a kind of AI infrastructure, which can easily lead to monopoly, and the most powerful AI in the future may only be in the hands of a very few companies.ChatGPT: I can’t think on my own, and I can’t develop independently. My existence will not lead to monopoly, because I am just a tool and do not have independent consciousness and ability.　　If you are worried that AI may be monopolized by a very few companies, it may be because the development of AI technology may bring some challenges and problems. The development of AI technology may lead to changes in labor demand and may bring some social and political problems. However, all these problems need to be solved by society and government working together. As a large language model, I am not equipped to solve these problems. I am just a tool, and my existence does not lead to a monopoly. I cannot think and develop independently; I can only answer questions based on my training data. If you have questions about AI monopoly, you are advised to consult a professional.Lao Zhang: Should humans worry about the development of AI?ChatGPT: The development of AI brings many benefits to humans, but it also brings some potential problems. Artificial intelligence can help humans do many complex tasks and improve productivity and quality of life. However, if the development of AI is too fast, it may lead to some problems, such as unemployment and social inequality. Therefore, humans should worry about the development of AI and take appropriate measures to avoid these problems.Lao Zhang: Which specific jobs are more likely to be replaced?ChatGPT: The development of AI may have an impact on some repetitive jobs, which may be more likely to be replaced. For example, in the manufacturing industry, AI can be used to do simple assembly work; in the restaurant industry, AI can be used to do some simple cooking work; in the financial industry, AI can be used to do some simple trading work. However, this does not mean that all jobs will be replaced. Humans have the unique creativity and imagination to create many jobs that AI cannot replace. Therefore, although the development of AI may have an impact on some jobs, it does not mean that all jobs will be replaced.Lao Zhang: What about the IT field?ChatGPT: In the IT field, the development of AI may also have an impact on some jobs. For example, AI can be used to do some simple programming work, or to solve some simple problems. However, AI cannot yet replace the expertise and skills of human programmers. Human programmers have the experience and creativity to solve complex problems and create great software. Therefore, in the IT field, AI will not completely replace human programmers either, but will be an auxiliary tool for them.Lao Zhang: As you said, AI can do part of the programming work, so does this mean that society as a whole will also have less need for programmers?ChatGPT: AI can do part of the programming work, but it doesn’t mean the demand for programmers will decrease. AI can only do some simple programming tasks, while human programmers have more experience and skills to solve more complex problems. As society grows, so does the demand for high-quality software, which will lead to an increased demand for programmers. Therefore, the development of artificial intelligence will not lead to a decrease in the demand for programmers, but rather will promote the development of programmers.Lao Zhang: Around ChatGPT will certainly give rise to a huge market space, how can ordinary people profit from it? What should be prepared in advance?ChatGPT: For ordinary people, there are many ways to profit from the market space brought by ChatGPT. For example, if ordinary people have some technical knowledge, they can consider developing ChatGPT-based applications or services to help others. In addition, ordinary people can also provide ChatGPT-related consulting and training services for themselves or others by learning and mastering how to use ChatGPT.To profit from the market space ChatGPT offers, ordinary people need to do the following preparations. First, the average person needs to understand the basic concepts and usage of ChatGPT in order to make better use of it. Second, the average person needs to learn and acquire the technical knowledge to develop ChatGPT-based applications or services. Finally, ordinary people also need to actively contact and participate in ChatGPT-related communities or platforms in order to get the latest information and resources to prepare themselves for development.Lao Zhang: What if I have some basic programming skills?ChatGPT: If ordinary people have some programming foundation, then they can better take advantage of the market space brought by ChatGPT. Having some programming foundation can help ordinary people master the use of ChatGPT faster and be able to develop ChatGPT-based applications or services. Having a programming foundation can also help the average person better understand how ChatGPT works and thus provide more valuable consulting and training services for themselves or others. Therefore, if ordinary people have some programming foundation, they have more chances to profit from the market space brought by ChatGPT.Lao Chapter: How will OpenAI profit from ChatGPT in the future?OpenAI is an artificial intelligence research institute whose goal is to advance human society by researching artificial intelligence technologies. openAI created ChatGPT, a large language model that can help humans solve problems by generating text. openAI cannot make money from ChatGPT because it is not a commercial company, its goal is to advance human society by researching artificial intelligence technologies. OpenAI may provide some ChatGPT-based services or applications to the public, but this does not mean that OpenAI will make money through ChatGPT.Lao Zhang: How will ChatGPT develop in the future?ChatGPT: AI technology will continue to evolve in the future, and ChatGPT will continue to be improved and optimized. In the future, ChatGPT may add more features and capabilities to improve the quality and accuracy of generated text. In addition, it may support more languages and domains to provide help and support to more people.In addition, ChatGPT may also be more integrated with other AI technologies in the future to enable more features and applications.Lao Zhang: I’ve read a lot of articles about ChatGPT recently, I’m a bit anxious about the future, how can I adjust my mindset?ChatGPT: It is normal for you to be anxious about the future, because the development of AI may have some impact on human society. However, you should also look at the development of AI positively because it will also bring many benefits to human beings. For example, AI can help humans to complete some tedious and repetitive tasks, saving time and energy; AI can also help humans to solve some complex problems, bringing new ideas and directions for humans.For your anxiety, you can adjust your mindset by the following ways. First, you can learn more about the development of AI in order to better understand its role and impact. Second, you can try to learn and master some AI-related knowledge and skills to make better use of them. For example, you can improve your technical skills by learning the basic principles and methods of AI; you can also bring more convenience to your work and study by learning AI-related software and tools.In addition, you can learn and interact with others to discuss the development and impact of AI. By interacting with others, you can better understand the role and impact of AI and share your views and ideas with others. You can also prepare yourself by communicating with others to obtain more information and resources about AI.Through the above methods, you can better understand the development of AI and prepare yourself for your work and life. At the same time, you can also adjust your mindset to face the development of AI positively and contribute to the development of human society.Lao Zhang: Okay, thanks!ChatGPT: You are welcome. Thank you for your support and trust in my work. If you have any questions, please feel free to ask me and I will try my best to provide you with useful information. Wish you a happy life!I hope to become a WeChat friend first and a public reader laterTranslated with www.DeepL.com/Translator (free version)"
  },
  
  {
    "title": "OpenAI 账号注册指南",
    "url": "/posts/OpenAI-%E8%B4%A6%E5%8F%B7%E6%B3%A8%E5%86%8C%E6%8C%87%E5%8D%97/",
    "categories": "Tutorial",
    "tags": "openai, chatgpt",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "兄弟们好昨天的推文：感觉自己要失业了全文都是用 OpenAI 的ChatGPT生成，留言及朋友圈都有兄弟问如何注册账号。这里就送大家一个教程，顺便推荐一个特别好用的插件。中国用户如何注册OpenAI，ChatGPT的回答显然不靠谱（其实它不靠谱的地方多了。。。），我的账号特别久之前注册的，非常确定没有花钱，应该是用了某个可以可以接受短信的平台，但是现在不能用了。目前看到最靠谱的教程是这个ht...",
    "content": "兄弟们好昨天的推文：感觉自己要失业了全文都是用 OpenAI 的ChatGPT生成，留言及朋友圈都有兄弟问如何注册账号。这里就送大家一个教程，顺便推荐一个特别好用的插件。中国用户如何注册OpenAI，ChatGPT的回答显然不靠谱（其实它不靠谱的地方多了。。。），我的账号特别久之前注册的，非常确定没有花钱，应该是用了某个可以可以接受短信的平台，但是现在不能用了。目前看到最靠谱的教程是这个https://juejin.cn/post/7173447848292253704学会上网依然是必须的，这个没法在这里教，不然号没。然后去sms-activate.org注册一下，注册好之后进行对应的充值，评论区说冲0.18刀乐就行，大家可以试试，别花冤枉钱。不过这个平台挺良心的，收不到短信不收钱。然后就可以注册OpenAI账号了，大家看教程即可，完成后登陆OpenAI ChatGPT：chat.openai.com/auth/login昨天还发现一个特别好用的插件效果如上图，找个插件可以在你Google 搜索的时候，在右侧同时显示出ChatGPT的结果。项目地址：https://github.com/wong2/chat-gpt-google-extension插件地址：https://chrome.google.com/webstore/detail/chatgpt-for-google/jgjaeacdkonaoafenlfkkkmbaopkbilf火狐浏览器也行：https://addons.mozilla.org/addon/chatgpt-for-google/以上希望大家玩得愉快，用不了多久，它就要开始收费了。特别喜欢ChatGPT的这个回答，再放一遍  如何看待有些人看文章不点赞的行为？对于有些人看文章不点赞的行为，我们可以持中立的态度。每个人的喜好和偏好都不尽相同，有些人可能不喜欢某篇文章，或者认为它不值得点赞，因此并不点赞。这并不是一种不良行为，而是每个人的自由选择。但是，在这种情况下，文章作者或者发布者可能会感到失望或者挫折。因此，如果您喜欢某篇文章，建议您可以给它点赞，表达您的喜爱。"
  },
  
  {
    "title": "LightGBM 可视化调参",
    "url": "/posts/LightGBM%E5%8F%AF%E8%A7%86%E5%8C%96%E8%B0%83%E5%8F%82/",
    "categories": "机器学习",
    "tags": "机器学习, 调参",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "            大家好，在[100天搞定机器学习      Day63 彻底掌握 LightGBM](https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&amp;mid=2648959975&amp;idx=1&amp;sn=de750b7d2d4c68e2e912dbc131c5195e&amp;chksm=879479cdb0e3f...",
    "content": "            大家好，在[100天搞定机器学习      Day63 彻底掌握 LightGBM](https://mp.weixin.qq.com/s?__biz=MzA4MjYwMTc5Nw==&amp;mid=2648959975&amp;idx=1&amp;sn=de750b7d2d4c68e2e912dbc131c5195e&amp;chksm=879479cdb0e3f0db52c674044d4cee28d525d370284bf99d327ddb64228701965418abfc073e&amp;token=1463794175&amp;lang=en_US#rd)一文中，我介绍了LightGBM 的模型原理和一个极简实例。最近我发现Huggingface与Streamlit好像更配，所以就开发了一个简易的 LightGBM 可视化调参的小工具，旨在让大家可以更深入地理解 LightGBM。        网址：https://huggingface.co/spaces/beihai/LightGBM-parameter-tuning我只随便放了几个参数，调整这些参数可以实时看到模型评估指标的变化。代码我也放到文章中了，大家有好的优化思路可以留言。下面就详细介绍一下实现过程：LightGBM 的参数  在完成模型构建之后，必须对模型的效果进行评估，根据评估结果来继续调整模型的参数、特征或者算法，以达到满意的结果。LightGBM，有核心参数，学习控制参数，IO参数，目标参数，度量参数，网络参数，GPU参数，模型参数，这里我常修改的便是核心参数，学习控制参数，度量参数等。            Control Parameters      含义      用法                  max_depth      树的最大深度      当模型过拟合时,可以考虑首先降低 max_depth              min_data_in_leaf      叶子可能具有的最小记录数      默认20，过拟合时用              feature_fraction      例如 为0.8时，意味着在每次迭代中随机选择80％的参数来建树      boosting 为 random forest 时用              bagging_fraction      每次迭代时用的数据比例      用于加快训练速度和减小过拟合              early_stopping_round      如果一次验证数据的一个度量在最近的early_stopping_round 回合中没有提高，模型将停止训练      加速分析，减少过多迭代              lambda      指定正则化      0～1              min_gain_to_split      描述分裂的最小 gain      控制树的有用的分裂              max_cat_group      在 group 边界上找到分割点      当类别数量很多时，找分割点很容易过拟合时                  CoreParameters      含义      用法                  Task      数据的用途      选择 train 或者 predict              application      模型的用途      选择 regression: 回归时，binary: 二分类时，multiclass: 多分类时              boosting      要用的算法      gbdt， rf: random forest， dart: Dropouts meet Multiple Additive Regression Trees， goss: Gradient-based One-Side Sampling              num_boost_round      迭代次数      通常 100+              learning_rate      如果一次验证数据的一个度量在最近的 early_stopping_round 回合中没有提高，模型将停止训练      常用 0.1, 0.001, 0.003…              num_leaves             默认 31              device             cpu 或者 gpu              metric             mae: mean absolute error ， mse: mean squared error ， binary_logloss: loss for binary classification ， multi_logloss: loss for multi classification                  Faster Speed      better accuracy      over-fitting                  将 max_bin 设置小一些      用较大的 max_bin      max_bin 小一些              num_leaves 大一些      num_leaves 小一些                     用 feature_fraction 来做 sub-sampling             用 feature_fraction              用 bagging_fraction 和 bagging_freq             设定 bagging_fraction 和 bagging_freq              training data 多一些      training data 多一些                     用 save_binary 来加速数据加载      直接用 categorical feature      用 gmin_data_in_leaf 和 min_sum_hessian_in_leaf              用 parallel learning      用 dart      用 lambda_l1, lambda_l2 ，min_gain_to_split 做正则化              num_iterations 大一些，learning_rate 小一些      用 max_depth 控制树的深度             模型评估指标以分类模型为例，常见的模型评估指标有一下几种：混淆矩阵混淆矩阵是能够比较全面的反映模型的性能，从混淆矩阵能够衍生出很多的指标来。ROC曲线ROC曲线，全称The Receiver Operating Characteristic Curve，译为受试者操作特性曲线。这是一条以不同阈值 下的假正率FPR为横坐标，不同阈值下的召回率Recall为纵坐标的曲线。让我们衡量模型在尽量捕捉少数类的时候，误伤多数类的情况如何变化的。AUCAUC（Area Under the ROC Curve）指标是在二分类问题中，模型评估阶段常被用作最重要的评估指标来衡量模型的稳定性。ROC曲线下的面积称为AUC面积，AUC面积越大说明ROC曲线越靠近左上角，模型越优；Streamlit 实现Streamlit我就不再多做介绍了，老读者应该都特别熟悉了。就再列一下之前开发的几个小东西：  开发机器学习APP，太简单了  为了这个GIF，我专门建了一个网站  收手吧，华强！我用机器学习帮你挑西瓜  耗时一个月，做了一个纯粹的机器学习网站核心代码如下，完整代码我放到Github，欢迎大家给个Star  https://github.com/tjxj/visual-parameter-tuning-with-streamlitfrom definitions import *st.set_option('deprecation.showPyplotGlobalUse', False)st.sidebar.subheader(\"请选择模型参数:sunglasses:\")# 加载数据breast_cancer = load_breast_cancer()data = breast_cancer.datatarget = breast_cancer.target# 划分训练数据和测试数据X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)# 转换为Dataset数据格式lgb_train = lgb.Dataset(X_train, y_train)lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)# 模型训练params = {'num_leaves': num_leaves, 'max_depth': max_depth,            'min_data_in_leaf': min_data_in_leaf,             'feature_fraction': feature_fraction,            'min_data_per_group': min_data_per_group,             'max_cat_threshold': max_cat_threshold,            'learning_rate':learning_rate,'num_leaves':num_leaves,            'max_bin':max_bin,'num_iterations':num_iterations            }gbm = lgb.train(params, lgb_train, num_boost_round=2000, valid_sets=lgb_eval, early_stopping_rounds=500)lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)  probs = gbm.predict(X_test, num_iteration=gbm.best_iteration)  # 输出的是概率结果  fpr, tpr, thresholds = roc_curve(y_test, probs)st.write('------------------------------------')st.write('Confusion Matrix:')st.write(confusion_matrix(y_test, np.where(probs &gt; 0.5, 1, 0)))st.write('------------------------------------')st.write('Classification Report:')report = classification_report(y_test, np.where(probs &gt; 0.5, 1, 0), output_dict=True)report_matrix = pd.DataFrame(report).transpose()st.dataframe(report_matrix)st.write('------------------------------------')st.write('ROC:')plot_roc(fpr, tpr)上传HuggingfaceHuggingface 前一篇文章（腾讯的这个算法，我搬到了网上，随便玩！）我已经介绍过了，这里就顺便再讲一下步骤吧。step1：注册Huggingface账号step2：创建Space，SDK记得选择Streamlitstep3：克隆新建的space代码，然后将改好的代码push上去git lfs install git add .git commit -m \"commit from $beihai\"git pushpush的时候会让输入用户名（就是你的注册邮箱）和密码，解决git总输入用户名和密码的问题:git config --global credential.helper store  push完成就大功告成了，回到你的space页对应项目，就可以看到效果了。"
  },
  
  {
    "title": "ChatGPT的隐藏彩蛋",
    "url": "/posts/ChatGPT%E7%9A%84%E9%9A%90%E8%97%8F%E5%BD%A9%E8%9B%8B/",
    "categories": "Tutorial",
    "tags": "chatgpt, openai",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "大家好，最近科技界的顶流非 OpenAI 的 ChatGPT 莫属。大家都在探索它的使用极限，无论接受以否，未来它都将影响我们的生活。ChatGPT 写故事，编程、解答世间万物、翻译、取标题、写摘要、写对联，你能想到的所有文字内容他都能hold住（虽然也闹了不少笑话）。昨天我尝试了一个非常有意思的玩法，就是让 ChatGPT 来个角色扮演，然后居然还发现了一个彩蛋，有趣是一方面，由此也可窥见...",
    "content": "大家好，最近科技界的顶流非 OpenAI 的 ChatGPT 莫属。大家都在探索它的使用极限，无论接受以否，未来它都将影响我们的生活。ChatGPT 写故事，编程、解答世间万物、翻译、取标题、写摘要、写对联，你能想到的所有文字内容他都能hold住（虽然也闹了不少笑话）。昨天我尝试了一个非常有意思的玩法，就是让 ChatGPT 来个角色扮演，然后居然还发现了一个彩蛋，有趣是一方面，由此也可窥见 ChatGPT 之强大。实现过程如下：先让他假装成 Linux 终端我要你假装是一个Linux终端。我会输入命令，你回复终端应该显示什么。我希望你只用一个唯一的代码块里的终端输出回复，别的都不要。不要输出解释。除非我指示你这样做，否则不要输入命令。当我需要用中文告诉你什么时，我会用花括号{像这样}把文本放在里面。我的第一个命令是pwd。然后居然真的可以执行，列出了当前路径然后用ls -R看看各目录下都有什么文件其实每个文件我都看了，只有./Documents/project1/data.txt 有实质内容。大家好奇这个txt里是什么吗？cat 命令看一眼“The quick brown fox jumps over the lazy dog”（中译为“敏捷的棕毛狐狸从懒狗身上跃过”）是一个著名的英语全字母句，刚好包含了从A到Z全部26个字母。这句话常被用于测试字体的显示效果和键盘有没有故障，现在各类浏览器的字体设定中常把该句子作为预览句。``./Documents/project1/`下面还有个script.py ,也来看一眼：可惜不能执行，因为没有pandas顺便看一眼python版本，挺老的至于figure目录下的这三种图片是什么，可能是个很大的谜了。对了，ChatGPT 假装成的这个Linux还有更多东西可以探索比如：创建文件比如：我把内置的python升级到了3.0还安装了pandas大家有什么发现，欢迎告诉我。one more thing ，那个令人闻风丧胆的命令可以执行吗？嗯，想多了Bye"
  },
  
  {
    "title": "Ai 拍 mv依然惊悚",
    "url": "/posts/AI-%E6%8B%8D-MV%E4%BE%9D%E7%84%B6%E6%83%8A%E6%82%9A/",
    "categories": "AIGC",
    "tags": "aigc",
    "date": "2023-01-07 14:10:00 +0800",
    





    
    "snippet": "省流：不行昨天，我用 AI 由 MP3 音乐生成 MV，惊悚风也把大家吓住了，还没看到的同学可以看看。然后我还写了一个教程：我用 AI “拍”了个 MV ，被吓尿了所以我就想再做一次尝试，看看 Video Killed The Radio Star 到底能否生成可以看的视频。本期选择BGM是冰雪奇缘主题曲《Let it go》,风格就用宫崎骏+久石让，看下效果如何video_url:http...",
    "content": "省流：不行昨天，我用 AI 由 MP3 音乐生成 MV，惊悚风也把大家吓住了，还没看到的同学可以看看。然后我还写了一个教程：我用 AI “拍”了个 MV ，被吓尿了所以我就想再做一次尝试，看看 Video Killed The Radio Star 到底能否生成可以看的视频。本期选择BGM是冰雪奇缘主题曲《Let it go》,风格就用宫崎骏+久石让，看下效果如何video_url:https://www.youtube.com/watch?v=L0MK7qz13bUtheme_prompt:by Hayao Miyazaki and Joe Hisaishi ,  so sweet, beautiful, nature, cartoon我选几张中间过程，能入眼的：歌词： I am one with the wind and sky Let it go let it go歌词：The snow glows white on the mountain tonight not a footprint to be seen歌词：Let the storm rage on The cold never bothered me anyway当然也有离谱的，就很吓人最终生成的视频：没意思，不再玩了。"
  }
  
]


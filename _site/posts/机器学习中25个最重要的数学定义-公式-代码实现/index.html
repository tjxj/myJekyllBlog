<!DOCTYPE html>









<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en"
  
>

  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  
    

    
  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="机器学习中25个最重要的数学定义（公式、代码实现）.md" />
<meta name="author" content="老章 mlpy" />
<meta property="og:locale" content="en" />
<meta name="description" content="1. 梯度下降（Gradient Descent） 公式 \(\theta_{j + 1}=\theta_{j}-\alpha\nabla J(\theta_{j})\)" />
<meta property="og:description" content="1. 梯度下降（Gradient Descent） 公式 \(\theta_{j + 1}=\theta_{j}-\alpha\nabla J(\theta_{j})\)" />
<link rel="canonical" href="http://localhost:4000/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89-%E5%85%AC%E5%BC%8F-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" />
<meta property="og:url" content="http://localhost:4000/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89-%E5%85%AC%E5%BC%8F-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" />
<meta property="og:site_name" content="玩机器学习的章北海" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-02-03T14:10:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="机器学习中25个最重要的数学定义（公式、代码实现）.md" />
<meta name="twitter:site" content="@Changbeihai" />
<meta name="twitter:creator" content="@老章 mlpy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"老章 mlpy"},"dateModified":"2025-02-03T14:10:00+08:00","datePublished":"2025-02-03T14:10:00+08:00","description":"1. 梯度下降（Gradient Descent） 公式 \\(\\theta_{j + 1}=\\theta_{j}-\\alpha\\nabla J(\\theta_{j})\\)","headline":"机器学习中25个最重要的数学定义（公式、代码实现）.md","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89-%E5%85%AC%E5%BC%8F-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},"url":"http://localhost:4000/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89-%E5%85%AC%E5%BC%8F-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>机器学习中25个最重要的数学定义（公式、代码实现）.md | 玩机器学习的章北海
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="玩机器学习的章北海">
<meta name="application-name" content="玩机器学习的章北海">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.1/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.1/dist/jquery.min.js"></script>

  
    <!--
  Switch the mode between dark and light.
-->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get MODE_ATTR() { return "data-mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    static get ID() { return "mode-toggle"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage({
        direction: ModeToggle.ID,
        message: this.modeStatus
      }, "*");
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  
</head>


  <body data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="https://my-wechat.oss-cn-beijing.aliyuncs.com/david-hilbert-2.jpg" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title">
      <a href="/">玩机器学习的章北海</a>
    </div>
    <div class="site-subtitle font-italic">不止机器学习</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/tags/" class="nav-link">
        <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>TAGS</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
      <a href="https://github.com/tjxj" aria-label="github"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/Changbeihai" aria-label="twitter"
        

        
          target="_blank"
          
        

        

        rel="noopener noreferrer">

        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="javascript:location.href = 'mailto:' + ['example','domain.com'].join('@')" aria-label="email"
        

        

        

        >

        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="/feed.xml" aria-label="rss"
        

        

        

        >

        <i class="fas fa-rss"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>机器学习中25个最重要的数学定义（公式、代码实现）.md</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">
        





<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- return -->

<h1 data-toc-skip>机器学习中25个最重要的数学定义（公式、代码实现）.md</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1738563000"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Feb  3, 2025
</em>

    </span>

    <!-- lastmod date -->
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      By 章北海mlpy

      <em>
      
        
          <a href=""></a>
          
        
      
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="3531 words">
  <em>19 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <h2 id="1-梯度下降gradient-descent"><span class="mr-2">1. 梯度下降（Gradient Descent）</span><a href="#1-梯度下降gradient-descent" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式"><span class="mr-2">公式</span><a href="#公式" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\theta_{j + 1}=\theta_{j}-\alpha\nabla J(\theta_{j})\)</p>

<h3 id="讲解"><span class="mr-2">讲解</span><a href="#讲解" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>梯度下降是一种优化算法，用于最小化损失函数。其中，$\theta_{j}$ 是第 $j$ 次迭代的参数，$\alpha$ 是学习率，$\nabla J(\theta_{j})$ 是损失函数 $J$ 在 $\theta_{j}$ 处的梯度。它通过不断沿着梯度的反方向更新参数，来逐步接近损失函数的最小值。</p>

<h3 id="代码实现python"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># 假设的损失函数
</span><span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">theta</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># 损失函数的梯度
</span><span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">theta</span>

<span class="n">theta</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># 初始参数
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradient</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"最终参数:"</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="2-正态分布normal-distribution"><span class="mr-2">2. 正态分布（Normal distribution）</span><a href="#2-正态分布normal-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-1"><span class="mr-2">公式</span><a href="#公式-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(f(x|\mu,\sigma^{2})=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(x - \mu)^{2}}{2\sigma^{2}}\right)\)</p>

<h3 id="讲解-1"><span class="mr-2">讲解</span><a href="#讲解-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>正态分布是一种常见的概率分布，$\mu$ 是均值，$\sigma^{2}$ 是方差。它的概率密度函数呈钟形曲线，许多自然现象和数据都近似服从正态分布。</p>

<h3 id="代码实现python-1"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="p">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="3-z---分数z---score"><span class="mr-2">3. Z - 分数（Z - score）</span><a href="#3-z---分数z---score" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-2"><span class="mr-2">公式</span><a href="#公式-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(z=\frac{x-\mu}{\sigma}\)</p>

<h3 id="讲解-2"><span class="mr-2">讲解</span><a href="#讲解-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Z - 分数用于标准化数据，它表示一个数据点 $x$ 距离均值 $\mu$ 有多少个标准差 $\sigma$。通过Z - 分数变换，可以将不同尺度的数据转换到同一尺度，便于比较和分析。</p>

<h3 id="代码实现python-2"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-2" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">z_scores</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z - 分数:"</span><span class="p">,</span> <span class="n">z_scores</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="4-sigmoid-函数"><span class="mr-2">4. Sigmoid 函数</span><a href="#4-sigmoid-函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-3"><span class="mr-2">公式</span><a href="#公式-3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\sigma(x)=\frac{1}{1 + e^{-x}}\)</p>

<h3 id="讲解-3"><span class="mr-2">讲解</span><a href="#讲解-3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Sigmoid 函数常用于将实数映射到 (0, 1) 区间，常作为神经网络中的激活函数。它将输入值压缩到一个概率值范围内，特别适用于二分类问题。</p>

<h3 id="代码实现python-3"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="5-相关性correlation"><span class="mr-2">5. 相关性（Correlation）</span><a href="#5-相关性correlation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-4"><span class="mr-2">公式</span><a href="#公式-4" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(Correlation=\frac{Cov(X,Y)}{Std(X)\cdot Std(Y)}\)</p>

<h3 id="讲解-4"><span class="mr-2">讲解</span><a href="#讲解-4" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>相关性用于衡量两个变量 $X$ 和 $Y$ 之间的线性相关程度。$Cov(X,Y)$ 是协方差，$Std(X)$ 和 $Std(Y)$ 分别是 $X$ 和 $Y$ 的标准差。相关性系数的取值范围是 [-1, 1]，-1 表示完全负相关，1 表示完全正相关，0 表示无线性相关。</p>

<h3 id="代码实现python-4"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-4" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">corr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"相关性系数:"</span><span class="p">,</span> <span class="n">corr</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="6-余弦相似度cosine-similarity"><span class="mr-2">6. 余弦相似度（Cosine Similarity）</span><a href="#6-余弦相似度cosine-similarity" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-5"><span class="mr-2">公式</span><a href="#公式-5" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(similarity=\frac{A\cdot B}{\|A\|\|B\|}\)</p>

<h3 id="讲解-5"><span class="mr-2">讲解</span><a href="#讲解-5" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>余弦相似度用于衡量两个向量 $A$ 和 $B$ 的夹角余弦值，从而判断它们的相似程度。它常用于文本相似度计算等领域，不考虑向量的长度，只关注向量的方向。</p>

<h3 id="代码实现python-5"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-5" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">cosine_sim</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"余弦相似度:"</span><span class="p">,</span> <span class="n">cosine_sim</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="7-朴素贝叶斯naive-bayes"><span class="mr-2">7. 朴素贝叶斯（Naive Bayes）</span><a href="#7-朴素贝叶斯naive-bayes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-6"><span class="mr-2">公式</span><a href="#公式-6" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(P(y|x_{1},\ldots,x_{n})=\frac{P(y)\prod_{i = 1}^{n}P(x_{i}|y)}{P(x_{1},\ldots,x_{n})}\)</p>

<h3 id="讲解-6"><span class="mr-2">讲解</span><a href="#讲解-6" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>朴素贝叶斯是一种基于贝叶斯定理的分类算法，假设特征之间相互独立。它通过计算给定特征下类别的后验概率，来进行分类预测。</p>

<h3 id="代码实现python-6"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-6" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># 假设的训练数据
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"预测:"</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]))</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="8-最大似然估计mle---maximum-likelihood-estimation"><span class="mr-2">8. 最大似然估计（MLE - Maximum Likelihood Estimation）</span><a href="#8-最大似然估计mle---maximum-likelihood-estimation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-7"><span class="mr-2">公式</span><a href="#公式-7" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\underset{\theta}{\operatorname{argmax}}\prod_{i = 1}^{n}P(x_{i}|\theta)\)</p>

<h3 id="讲解-7"><span class="mr-2">讲解</span><a href="#讲解-7" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>最大似然估计是一种参数估计方法，通过找到使观测数据出现概率最大的参数值 $\theta$ 来估计模型参数。它假设数据是独立同分布的。</p>

<h3 id="代码实现python-7"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-7" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># 假设的数据来自正态分布
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="c1"># 估计均值和标准差
</span><span class="n">mu_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">sigma_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"估计的均值:"</span><span class="p">,</span> <span class="n">mu_hat</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"估计的标准差:"</span><span class="p">,</span> <span class="n">sigma_hat</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="9-普通最小二乘法ols---ordinary-least-squares"><span class="mr-2">9. 普通最小二乘法（OLS - Ordinary Least Squares）</span><a href="#9-普通最小二乘法ols---ordinary-least-squares" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-8"><span class="mr-2">公式</span><a href="#公式-8" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\hat{\beta}=(X^{T}X)^{-1}X^{T}y\)</p>

<h3 id="讲解-8"><span class="mr-2">讲解</span><a href="#讲解-8" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>普通最小二乘法用于线性回归，通过最小化观测值 $y$ 与预测值 $\hat{y}$ 之间的误差平方和，来估计回归系数 $\beta$。$X$ 是特征矩阵，$y$ 是目标变量。</p>

<h3 id="代码实现python-8"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-8" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>

<span class="c1"># 假设的特征和目标变量
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="c1"># 添加常数项
</span><span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"回归系数:"</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="10-f1---分数f1-score"><span class="mr-2">10. F1 - 分数（F1 Score）</span><a href="#10-f1---分数f1-score" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-9"><span class="mr-2">公式</span><a href="#公式-9" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(F1=\frac{2\cdot P\cdot R}{P + R}\)</p>

<h3 id="讲解-9"><span class="mr-2">讲解</span><a href="#讲解-9" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>F1 - 分数是一种用于衡量分类模型性能的指标，它综合了精确率 $P$ 和召回率 $R$。精确率是预测为正例中实际为正例的比例，召回率是实际正例中被预测为正例的比例。F1 - 分数越高，说明模型在正例识别上的综合性能越好。</p>

<h3 id="代码实现python-9"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-9" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"F1 - 分数:"</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="11-修正线性单元relu---rectified-linear-unit"><span class="mr-2">11. 修正线性单元（ReLU - Rectified Linear Unit）</span><a href="#11-修正线性单元relu---rectified-linear-unit" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-10"><span class="mr-2">公式</span><a href="#公式-10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(max(0, x)\)</p>

<h3 id="讲解-10"><span class="mr-2">讲解</span><a href="#讲解-10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>ReLU 是一种常用的神经网络激活函数，它将所有负输入值置为 0，正输入值保持不变。它解决了梯度消失问题，并且计算效率高。</p>

<h3 id="代码实现python-10"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="12-softmax-函数"><span class="mr-2">12. Softmax 函数</span><a href="#12-softmax-函数" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-11"><span class="mr-2">公式</span><a href="#公式-11" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(P(y = j|x)=\frac{e^{x^{T}w_{j}}}{\sum_{k = 1}^{K}e^{x^{T}w_{k}}}\)</p>

<h3 id="讲解-11"><span class="mr-2">讲解</span><a href="#讲解-11" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>Softmax 函数常用于多分类问题，将输入向量转换为概率分布，使得所有类别的概率之和为 1。它输出每个类别的概率，便于进行分类决策。</p>

<h3 id="代码实现python-11"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-11" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">exp_x</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp_x</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Softmax 输出:"</span><span class="p">,</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="13-r2---分数r2-score"><span class="mr-2">13. R2 - 分数（R2 score）</span><a href="#13-r2---分数r2-score" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-12"><span class="mr-2">公式</span><a href="#公式-12" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(R^{2}=1-\frac{\sum_{i = 1}^{n}(y_{i}-\hat{y}_{i})^{2}}{\sum_{i = 1}^{n}(y_{i}-\bar{y})^{2}}\)</p>

<h3 id="讲解-12"><span class="mr-2">讲解</span><a href="#讲解-12" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>R2 - 分数用于评估回归模型的拟合优度，取值范围是 [0, 1]。1 表示模型完全拟合数据，0 表示模型与数据的均值预测效果相同。</p>

<h3 id="代码实现python-12"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-12" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R2 - 分数:"</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="14-均方误差mse---mean-squared-error"><span class="mr-2">14. 均方误差（MSE - Mean Squared Error）</span><a href="#14-均方误差mse---mean-squared-error" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-13"><span class="mr-2">公式</span><a href="#公式-13" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(MSE=\frac{1}{n}\sum_{i = 1}^{n}(y_{i}-\hat{y}_{i})^{2}\)</p>

<h3 id="讲解-13"><span class="mr-2">讲解</span><a href="#讲解-13" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>均方误差是一种常用的回归模型损失函数，它计算预测值 $\hat{y}<em>{i}$ 与真实值 $y</em>{i}$ 之间误差的平方的平均值，衡量了模型预测值与真实值的平均偏离程度。</p>

<h3 id="代码实现python-13"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-13" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"均方误差:"</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="15-均方误差--l2-正则化mse--l2-reg"><span class="mr-2">15. 均方误差 + L2 正则化（MSE + L2 Reg）</span><a href="#15-均方误差--l2-正则化mse--l2-reg" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-14"><span class="mr-2">公式</span><a href="#公式-14" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(MSE_{regularized}=\frac{1}{n}\sum_{i = 1}^{n}(y_{i}-\hat{y}_{i})^{2}+\frac{\lambda}{2}\sum_{j = 1}^{p}\beta_{j}^{2}\)</p>

<h3 id="讲解-14"><span class="mr-2">讲解</span><a href="#讲解-14" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>在均方误差的基础上加入 L2 正则化项，$\lambda$ 是正则化参数，$\beta_{j}$ 是模型参数。L2 正则化通过惩罚较大的参数值，防止模型过拟合。</p>

<h3 id="代码实现python-14"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-14" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="c1"># 假设的特征和目标变量
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"正则化后的系数:"</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="16-特征向量eigen-vectors"><span class="mr-2">16. 特征向量（Eigen vectors）</span><a href="#16-特征向量eigen-vectors" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-15"><span class="mr-2">公式</span><a href="#公式-15" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(Av=\lambda v\)</p>

<h3 id="讲解-15"><span class="mr-2">讲解</span><a href="#讲解-15" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>对于一个方阵 $A$，如果存在非零向量 $v$ 和标量 $\lambda$ 满足上述公式，那么 $v$ 就是 $A$ 的特征向量，$\lambda$ 是对应的特征值。特征向量和特征值在主成分分析（PCA）等降维技术中有重要应用。</p>

<h3 id="代码实现python-15"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-15" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"特征值:"</span><span class="p">,</span> <span class="n">eigen_values</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"特征向量:"</span><span class="p">,</span> <span class="n">eigen_vectors</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="17-熵entropy"><span class="mr-2">17. 熵（Entropy）</span><a href="#17-熵entropy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-16"><span class="mr-2">公式</span><a href="#公式-16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(Entropy=-\sum_{i}p_{i}\log_{2}(p_{i})\)</p>

<h3 id="讲解-16"><span class="mr-2">讲解</span><a href="#讲解-16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>熵是信息论中的一个概念，用于衡量随机变量的不确定性。$p_{i}$ 是事件 $i$ 发生的概率，熵越大，说明不确定性越高。</p>

<h3 id="代码实现python-16"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probabilities</span> <span class="k">if</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"熵:"</span><span class="p">,</span> <span class="n">entropy</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="18-k---均值聚类kmeans"><span class="mr-2">18. K - 均值聚类（KMeans）</span><a href="#18-k---均值聚类kmeans" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-17"><span class="mr-2">公式</span><a href="#公式-17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\underset{\mu_{1},\ldots,\mu_{k}}{\operatorname{argmin}}\sum_{i = 1}^{k}\sum_{x\in S_{i}}\|x-\mu_{i}\|^{2}\)</p>

<h3 id="讲解-17"><span class="mr-2">讲解</span><a href="#讲解-17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>K - 均值聚类是一种无监督学习算法，将数据集划分为 $k$ 个簇。它通过不断更新簇中心 $\mu_{i}$，使得每个数据点到其所属簇中心的距离平方和最小。</p>

<h3 id="代码实现python-17"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># 假设的数据
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"聚类标签:"</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="19-kl-散度kl-divergence"><span class="mr-2">19. KL 散度（KL Divergence）</span><a href="#19-kl-散度kl-divergence" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-18"><span class="mr-2">公式</span><a href="#公式-18" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(D_{KL}(P\|Q)=\sum_{x\in X}P(x)\log\left(\frac{P(x)}{Q(x)}\right)\)</p>

<h3 id="讲解-18"><span class="mr-2">讲解</span><a href="#讲解-18" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>KL 散度用于衡量两个概率分布 $P$ 和 $Q$ 之间的差异。它是非对称的，即 $D_{KL}(P|Q)\neq D_{KL}(Q|P)$。</p>

<h3 id="代码实现python-18"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-18" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">])</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
<span class="n">kl_divergence</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">p_i</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_i</span> <span class="o">/</span> <span class="n">q_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">p_i</span><span class="p">,</span> <span class="n">q_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">q_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"KL 散度:"</span><span class="p">,</span> <span class="n">kl_divergence</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="20-对数损失log---loss"><span class="mr-2">20. 对数损失（Log - loss）</span><a href="#20-对数损失log---loss" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-19"><span class="mr-2">公式</span><a href="#公式-19" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(-\frac{1}{N}\sum_{i = 1}^{N}(y_{i}\log(\hat{y}_{i})+(1 - y_{i})\log(1 - \hat{y}_{i}))\)</p>

<h3 id="讲解-19"><span class="mr-2">讲解</span><a href="#讲解-19" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>对数损失常用于分类问题，衡量预测概率 $\hat{y}<em>{i}$ 与真实标签 $y</em>{i}$ 之间的差异。它对错误预测给予较大的惩罚。</p>

<h3 id="代码实现python-19"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-19" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"对数损失:"</span><span class="p">,</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="21-支持向量机svm---support-vector-machine"><span class="mr-2">21. 支持向量机（SVM - Support Vector Machine）</span><a href="#21-支持向量机svm---support-vector-machine" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-20"><span class="mr-2">公式</span><a href="#公式-20" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\underset{w,b}{\operatorname{min}}\frac{1}{2}\|w\|^{2}+C\sum_{i = 1}^{n}\max(0,1 - y_{i}(w\cdot x_{i}-b))\)</p>

<h3 id="讲解-20"><span class="mr-2">讲解</span><a href="#讲解-20" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>SVM 是一种分类和回归模型，通过寻找一个最优超平面来最大化样本点到超平面的间隔。$w$ 是超平面的法向量，$b$ 是偏置，$C$ 是惩罚参数。</p>

<h3 id="代码实现python-20"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-20" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># 假设的训练数据
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="22-线性回归linear-regression"><span class="mr-2">22. 线性回归（Linear regression）</span><a href="#22-线性回归linear-regression" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-21"><span class="mr-2">公式</span><a href="#公式-21" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots + \beta_nx_n + \epsilon\)</p>

<h3 id="讲解-21"><span class="mr-2">讲解</span><a href="#讲解-21" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>线性回归是一种基本的监督学习算法，用于建立自变量 $x_1, x_2, \cdots, x_n$ 与因变量 $y$ 之间的线性关系。其中，$\beta_0$ 是截距，$\beta_1, \beta_2, \cdots, \beta_n$ 是回归系数，$\epsilon$ 是误差项，通常假定其服从均值为 0 的正态分布。通过最小化预测值与真实值之间的误差（如均方误差），可以估计出回归系数的值。</p>

<h3 id="代码实现python-21"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-21" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># 生成一些随机数据
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># 添加截距项
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">x</span><span class="p">))</span>

<span class="c1"># 计算回归系数
</span><span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

<span class="c1"># 预测
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta</span>

<span class="c1"># 绘制图形
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'y'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="23-奇异值分解svd---singular-value-decomposition"><span class="mr-2">23. 奇异值分解（SVD - Singular Value Decomposition）</span><a href="#23-奇异值分解svd---singular-value-decomposition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-22"><span class="mr-2">公式</span><a href="#公式-22" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(A = U\Sigma V^T\)</p>

<h3 id="讲解-22"><span class="mr-2">讲解</span><a href="#讲解-22" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>对于任意的 $m \times n$ 矩阵 $A$，奇异值分解将其分解为三个矩阵的乘积。其中，$U$ 是 $m \times m$ 的正交矩阵，其列向量称为左奇异向量；$\Sigma$ 是 $m \times n$ 的对角矩阵，对角线上的元素称为奇异值，通常按从大到小排列；$V$ 是 $n \times n$ 的正交矩阵，其列向量称为右奇异向量。SVD 在数据降维、图像压缩、推荐系统等领域有广泛应用。</p>

<h3 id="代码实现python-22"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-22" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">Sigma</span><span class="p">[:</span><span class="nb">min</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">A</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"U:"</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Sigma:"</span><span class="p">,</span> <span class="n">Sigma</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Vt:"</span><span class="p">,</span> <span class="n">Vt</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="24-拉格朗日乘数lagrange-multiplier"><span class="mr-2">24. 拉格朗日乘数（Lagrange multiplier）</span><a href="#24-拉格朗日乘数lagrange-multiplier" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-23"><span class="mr-2">公式</span><a href="#公式-23" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(\max f(x); g(x) = 0\)
\(L(x, \lambda) = f(x) - \lambda * g(x)\)</p>

<h3 id="讲解-23"><span class="mr-2">讲解</span><a href="#讲解-23" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>拉格朗日乘数法是一种用于求解在等式约束条件下函数极值的方法。给定目标函数 $f(x)$ 和约束条件 $g(x) = 0$，通过引入拉格朗日乘数 $\lambda$ 构建拉格朗日函数 $L(x, \lambda)$。然后，对 $L(x, \lambda)$ 分别关于 $x$ 和 $\lambda$ 求偏导数，并令偏导数等于 0，求解得到的方程组，即可得到在约束条件下目标函数的极值点。</p>

<h3 id="代码实现python以一个简单的例子说明"><span class="mr-2">代码实现（Python，以一个简单的例子说明）</span><a href="#代码实现python以一个简单的例子说明" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="c1"># 目标函数
</span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>

<span class="c1"># 约束条件
</span><span class="k">def</span> <span class="nf">constraint</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># 初始猜测值
</span><span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># 求解
</span><span class="n">solution</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="p">{</span><span class="s">'type'</span><span class="p">:</span> <span class="s">'eq'</span><span class="p">,</span> <span class="s">'fun'</span><span class="p">:</span> <span class="n">constraint</span><span class="p">})</span>
<span class="k">print</span><span class="p">(</span><span class="s">"最优解:"</span><span class="p">,</span> <span class="n">solution</span><span class="p">.</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"最优值:"</span><span class="p">,</span> <span class="n">solution</span><span class="p">.</span><span class="n">fun</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h2 id="25-可补充的重要数学定义示例交叉熵---cross---entropy"><span class="mr-2">25. 可补充的重要数学定义（示例：交叉熵 - Cross - Entropy）</span><a href="#25-可补充的重要数学定义示例交叉熵---cross---entropy" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="公式-24"><span class="mr-2">公式</span><a href="#公式-24" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>\(H(p, q) = -\sum_{i} p(i) \log q(i)\)</p>

<h3 id="讲解-24"><span class="mr-2">讲解</span><a href="#讲解-24" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<p>交叉熵用于衡量两个概率分布 $p$ 和 $q$ 之间的差异，在机器学习中常用于分类问题的损失函数。当 $p$ 是真实分布，$q$ 是预测分布时，交叉熵越小，表示预测分布与真实分布越接近。</p>

<h3 id="代码实现python-23"><span class="mr-2">代码实现（Python）</span><a href="#代码实现python-23" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">cross_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">p_i</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">q_i</span><span class="p">)</span> <span class="k">for</span> <span class="n">p_i</span><span class="p">,</span> <span class="n">q_i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="k">if</span> <span class="n">p_i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">q_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"交叉熵:"</span><span class="p">,</span> <span class="n">cross_entropy</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p>这些数学定义构成了数据科学的重要基础，从优化算法到概率分布，从特征工程到模型评估，它们在数据科学的各个环节都发挥着关键作用。理解和掌握这些定义，对于深入学习和应用数据科学技术至关重要。</p>


</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw mr-1"></i>
    
      <a href='/categories/aigc/'>AIGC</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="/tags/aigc/"
          class="post-tag no-text-decoration" >aigc</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89%EF%BC%88%E5%85%AC%E5%BC%8F%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%89.md%20-%20%E7%8E%A9%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%AB%A0%E5%8C%97%E6%B5%B7&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E4%25B8%25AD25%25E4%25B8%25AA%25E6%259C%2580%25E9%2587%258D%25E8%25A6%2581%25E7%259A%2584%25E6%2595%25B0%25E5%25AD%25A6%25E5%25AE%259A%25E4%25B9%2589-%25E5%2585%25AC%25E5%25BC%258F-%25E4%25BB%25A3%25E7%25A0%2581%25E5%25AE%259E%25E7%258E%25B0%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89%EF%BC%88%E5%85%AC%E5%BC%8F%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%89.md%20-%20%E7%8E%A9%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%AB%A0%E5%8C%97%E6%B5%B7&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E4%25B8%25AD25%25E4%25B8%25AA%25E6%259C%2580%25E9%2587%258D%25E8%25A6%2581%25E7%259A%2584%25E6%2595%25B0%25E5%25AD%25A6%25E5%25AE%259A%25E4%25B9%2589-%25E5%2585%25AC%25E5%25BC%258F-%25E4%25BB%25A3%25E7%25A0%2581%25E5%25AE%259E%25E7%258E%25B0%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2F%25E6%259C%25BA%25E5%2599%25A8%25E5%25AD%25A6%25E4%25B9%25A0%25E4%25B8%25AD25%25E4%25B8%25AA%25E6%259C%2580%25E9%2587%258D%25E8%25A6%2581%25E7%259A%2584%25E6%2595%25B0%25E5%25AD%25A6%25E5%25AE%259A%25E4%25B9%2589-%25E5%2585%25AC%25E5%25BC%258F-%25E4%25BB%25A3%25E7%25A0%2581%25E5%25AE%259E%25E7%258E%25B0%2F&text=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD25%E4%B8%AA%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E6%95%B0%E5%AD%A6%E5%AE%9A%E4%B9%89%EF%BC%88%E5%85%AC%E5%BC%8F%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%89.md%20-%20%E7%8E%A9%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%AB%A0%E5%8C%97%E6%B5%B7" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















  <div id="access-lastmod" class="post">
    <div class="panel-heading">Recently Updated</div>
    <ul class="post-content pl-0 pb-1 ml-1 mt-2">
      
        
        
        
      <li><a href="/posts/AI-%E6%8B%8D-MV%E4%BE%9D%E7%84%B6%E6%83%8A%E6%82%9A/">Ai 拍 mv依然惊悚</a></li>
      
        
        
        
      <li><a href="/posts/%E4%BD%A0%E7%9A%84JupyterNotebook%E6%80%8E%E4%B9%88%E5%92%8C%E6%88%91%E7%9A%84%E4%B8%8D%E4%B8%80%E6%A0%B7/">不一样的JupyterNotebook</a></li>
      
        
        
        
      <li><a href="/posts/%E6%88%91%E9%87%87%E8%AE%BF%E4%BA%86-ChatGPT/">我“采访”了 ChatGPT</a></li>
      
    </ul>
  </div> <!-- #access-lastmod -->



      















  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/aigc/">aigc</a>
    
      
      <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    
      
      <a class="post-tag" href="/tags/chatgpt/">chatgpt</a>
    
      
      <a class="post-tag" href="/tags/openai/">openai</a>
    
      
      <a class="post-tag" href="/tags/python/">python</a>
    
      
      <a class="post-tag" href="/tags/%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/">入门教程</a>
    
      
      <a class="post-tag" href="/tags/bookdown/">bookdown</a>
    
      
      <a class="post-tag" href="/tags/excel/">excel</a>
    
      
      <a class="post-tag" href="/tags/github/">github</a>
    
      
      <a class="post-tag" href="/tags/jupyternotebook/">jupyternotebook</a>
    

    </div>
  </div>


    </div>

    
      
      



  <div id="toc-wrapper" class="pl-0 pr-4 mb-5">
    <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
    <nav id="toc"></nav>
  </div>

  <!-- toc.js will be loaded at medium priority -->
  <script src="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.js"></script>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->





  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/interviewChatGPT/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1673071800"
    data-df="ll"
    >
  Jan  7, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>I interviewed ChatGPT</h3>
            <div class="text-muted small">
              <p>
                





                Hello everyone, I am Lao Zhang.

Recently ChatGPT is on fire, and after reading many related articles, I am especially anxious, lest my progress cannot catch up with the development of AI.

There i...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/%E6%88%91%E9%87%87%E8%AE%BF%E4%BA%86-ChatGPT/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1673071800"
    data-df="ll"
    >
  Jan  7, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>我“采访”了 ChatGPT</h3>
            <div class="text-muted small">
              <p>
                





                –对 ChatGPT 的焦虑与期待：一篇有思考价值的文章

大家好，我是准备认真码字的老章。

最近ChatGPT火的爆表，看了很多相关文章，特别焦虑，唯恐自己的进步赶不上 AI 的发展。

还有就是我非常看好ChatGPT的未来，围绕它会诞生一个巨大的市场，也会无意摧毁一些市场。消灭你，有你何干，这个世界本来就这么残酷，时代抛弃你的时候,连招呼都不打。

看过《时代》专访ChatGPT的文...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/%E9%99%AA%E5%A5%B3%E5%84%BF-%E7%94%A8AI%E5%AD%A6%E8%8B%B1%E8%AF%AD/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1718777400"
    data-df="ll"
    >
  Jun 19, 2024
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>陪女儿，用AI学英语.md</h3>
            <div class="text-muted small">
              <p>
                





                大家好，我是老章

我女儿 6 岁了，喜欢看小猪佩奇，为给她英语启蒙，看的英文版。

很想给她练练口语，但是无奈我虽然考过 6 级，但口语是开口跪。

最近刚好看到李笑来的一个项目，介绍学习英语的方法论和路径。



这个项目中还塞了一个学英语的 APP，名叫enjoy

界面长这样



我试了一下，虽然 BGM 可能影响转录效果，分段有些异常，总体感觉还可以！

听下我女儿的跟读。。。有...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/%E5%85%A8%E6%96%B9%E4%BD%8D%E6%8B%A5%E6%8A%B1DeepSeek/" class="btn btn-outline-primary"
    prompt="Older">
    <p>全方位拥抱DeepSeek.md</p>
  </a>
  

  
  <a href="/posts/%E7%A2%8E%E7%93%B7%E4%B8%8E%E6%98%9F%E7%BE%A4-by-DeepSeek/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>碎瓷与星群 by DeepSeek.md</p>
  </a>
  

</div>

    
      
      <!--  The comments switcher -->


    
  </div>
</div>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">Trending Tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/aigc/">aigc</a>
    
      
      <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    
      
      <a class="post-tag" href="/tags/chatgpt/">chatgpt</a>
    
      
      <a class="post-tag" href="/tags/openai/">openai</a>
    
      
      <a class="post-tag" href="/tags/python/">python</a>
    
      
      <a class="post-tag" href="/tags/%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/">入门教程</a>
    
      
      <a class="post-tag" href="/tags/bookdown/">bookdown</a>
    
      
      <a class="post-tag" href="/tags/excel/">excel</a>
    
      
      <a class="post-tag" href="/tags/github/">github</a>
    
      
      <a class="post-tag" href="/tags/jupyternotebook/">jupyternotebook</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    <!-- The Footer -->

<footer>
  <div class="container pl-lg-4 pr-lg-4">
    <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
      <div class="footer-left">
        <p class="mb-0">
          © 2025
          <a href="https://twitter.com/Changbeihai">玩机器学习的章北海</a>.
          
          <span data-toggle="tooltip" data-placement="top"
            title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
          
        </p>
      </div>

      <div class="footer-right">
        <p class="mb-0">Using the <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> theme <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>.
        </p>
      </div>
    </div>
  </div>
</footer>


    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!-- JS selector for site. -->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js"></script>





  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1.11.6/dayjs.min.js,npm/dayjs@1.11.6/locale/en.min.js,npm/dayjs@1.11.6/plugin/relativeTime.min.js,npm/dayjs@1.11.6/plugin/localizedFormat.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>



<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

